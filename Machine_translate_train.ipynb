{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyOIFXGS96HYxkheo5WDJYff"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"8095e0fa7f8f4c14af5eefb49f618acf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bbf916b0ee5b41f6a3be56e023967f02","IPY_MODEL_eda606a1a2d6448d90c838bc86d23c69","IPY_MODEL_35f75e517d7c4c769a9b56304c603375"],"layout":"IPY_MODEL_617e8c9117d64bf2990e16751859fd64"}},"bbf916b0ee5b41f6a3be56e023967f02":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e8022ecfc6a42919ccb5ad15f545bb9","placeholder":"​","style":"IPY_MODEL_cf598c772c5a4b6396e606ec1af46082","value":"tokenizer_config.json: 100%"}},"eda606a1a2d6448d90c838bc86d23c69":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1b5e98c4dbd4d72a426e8bc9596866e","max":49,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3170dd542fd54bc082db93021796b6cf","value":49}},"35f75e517d7c4c769a9b56304c603375":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0fdd523ff6d4b908616c905093399ea","placeholder":"​","style":"IPY_MODEL_7d1afb2837824ce3b38dc2002d756a2a","value":" 49.0/49.0 [00:00&lt;00:00, 3.61kB/s]"}},"617e8c9117d64bf2990e16751859fd64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e8022ecfc6a42919ccb5ad15f545bb9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf598c772c5a4b6396e606ec1af46082":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b1b5e98c4dbd4d72a426e8bc9596866e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3170dd542fd54bc082db93021796b6cf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b0fdd523ff6d4b908616c905093399ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d1afb2837824ce3b38dc2002d756a2a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4eff76ae8f3c4cabb37bea9e4ede2e40":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3b7f91a17a1c47a39c36c74fec6a966d","IPY_MODEL_d2f771513fcd4880b29c5eba64e7897a","IPY_MODEL_d484e8a9f6d04d788ee4b9d979eace07"],"layout":"IPY_MODEL_30cabe8677da4250af735a8e906fbd59"}},"3b7f91a17a1c47a39c36c74fec6a966d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d70483f5b3a4a6e8736aa4dad33400f","placeholder":"​","style":"IPY_MODEL_aa5e743c167449078113ab15658d3d95","value":"vocab.txt: 100%"}},"d2f771513fcd4880b29c5eba64e7897a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_108f65623f32448c92f9d0ccd6c74add","max":995526,"min":0,"orientation":"horizontal","style":"IPY_MODEL_df532d99bc064c76bac956a7f782b8fd","value":995526}},"d484e8a9f6d04d788ee4b9d979eace07":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_53ddc57cc9364cec9e0de216e337db84","placeholder":"​","style":"IPY_MODEL_3659b8ff47fa48249971e340a75491ab","value":" 996k/996k [00:00&lt;00:00, 1.20MB/s]"}},"30cabe8677da4250af735a8e906fbd59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d70483f5b3a4a6e8736aa4dad33400f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa5e743c167449078113ab15658d3d95":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"108f65623f32448c92f9d0ccd6c74add":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df532d99bc064c76bac956a7f782b8fd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"53ddc57cc9364cec9e0de216e337db84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3659b8ff47fa48249971e340a75491ab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3900c7f30daf4b9ab4928cab90a0d2a3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fc0eb443d9624163b4af4029fb76305c","IPY_MODEL_2b5615b3242c4d88a2a0d5e397fdc017","IPY_MODEL_287e61a0331b4d3994d3750b2a9d761f"],"layout":"IPY_MODEL_1234a2774b304f72b25fbbd42215e3b9"}},"fc0eb443d9624163b4af4029fb76305c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd705daad95e428fb4708f9f290df72e","placeholder":"​","style":"IPY_MODEL_d31186feff3a4545b61a19bf37f704fa","value":"tokenizer.json: 100%"}},"2b5615b3242c4d88a2a0d5e397fdc017":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5bc98ac56ba44a6983190b6c8dbc161","max":1961828,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8c04ce69b05e454ca235a060c27b183a","value":1961828}},"287e61a0331b4d3994d3750b2a9d761f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19d38e066b8843e2867125e00fce38dc","placeholder":"​","style":"IPY_MODEL_7bcea95a5c1b42189336c05599c73dc6","value":" 1.96M/1.96M [00:02&lt;00:00, 786kB/s]"}},"1234a2774b304f72b25fbbd42215e3b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd705daad95e428fb4708f9f290df72e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d31186feff3a4545b61a19bf37f704fa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c5bc98ac56ba44a6983190b6c8dbc161":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c04ce69b05e454ca235a060c27b183a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"19d38e066b8843e2867125e00fce38dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bcea95a5c1b42189336c05599c73dc6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"73ccdfc42f6747e29ab7653f778ddbec":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d45633ac3ca34bcb90caee3cb2155ce4","IPY_MODEL_b04d334395c94eee99d3f132a496c700","IPY_MODEL_fa8dc7fb583a46fdbc24b11e2b34c4fb"],"layout":"IPY_MODEL_d62a1b588c35475ab1bfe793f0f872b6"}},"d45633ac3ca34bcb90caee3cb2155ce4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3439c4865ec46dea77408e5afa6c175","placeholder":"​","style":"IPY_MODEL_cdbce26b182e4cf593eedfaeb374b970","value":"config.json: 100%"}},"b04d334395c94eee99d3f132a496c700":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c091aad7154846cc9b4b4ad659edfbb5","max":625,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7c0a1573d4a947c8bdb311ae953e8b10","value":625}},"fa8dc7fb583a46fdbc24b11e2b34c4fb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d65df435da7545f7a4feccabd63dd47c","placeholder":"​","style":"IPY_MODEL_c68e3a0012f441fb914f6145828c02ea","value":" 625/625 [00:00&lt;00:00, 40.3kB/s]"}},"d62a1b588c35475ab1bfe793f0f872b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3439c4865ec46dea77408e5afa6c175":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cdbce26b182e4cf593eedfaeb374b970":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c091aad7154846cc9b4b4ad659edfbb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c0a1573d4a947c8bdb311ae953e8b10":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d65df435da7545f7a4feccabd63dd47c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c68e3a0012f441fb914f6145828c02ea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"498999c6957b4d54a7ee84007db6185a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1e0b158a5629411ab3966ef6d1a6733e","IPY_MODEL_9e2dc71c135e49cb8a57413e32a6bf3a","IPY_MODEL_fc37a2b36b9242158198fc733a49ccc3"],"layout":"IPY_MODEL_62da5cd4e5b84e878a41eedd4d4af0a9"}},"1e0b158a5629411ab3966ef6d1a6733e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0203fd7c6864357afe14b8747bdc924","placeholder":"​","style":"IPY_MODEL_600319cb7c9a40f0ac6aeb9d4b8dc2b9","value":"README.md: 100%"}},"9e2dc71c135e49cb8a57413e32a6bf3a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e455cd09597c443ea6fdc592b9d2288f","max":538,"min":0,"orientation":"horizontal","style":"IPY_MODEL_15844cd1cc40408e9c59a5abbe5f686a","value":538}},"fc37a2b36b9242158198fc733a49ccc3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ddf34ad02aa54ada9c19f16a7a28bf01","placeholder":"​","style":"IPY_MODEL_38b9826e89b544e9b2321597a0e7472f","value":" 538/538 [00:00&lt;00:00, 45.8kB/s]"}},"62da5cd4e5b84e878a41eedd4d4af0a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0203fd7c6864357afe14b8747bdc924":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"600319cb7c9a40f0ac6aeb9d4b8dc2b9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e455cd09597c443ea6fdc592b9d2288f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15844cd1cc40408e9c59a5abbe5f686a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ddf34ad02aa54ada9c19f16a7a28bf01":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38b9826e89b544e9b2321597a0e7472f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"39f93114ee204b54b3ba1403d3f36205":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_482f09a1c0ff421ca3285a287f4f0620","IPY_MODEL_51f0c5b105644111ac9a8ad090af193c","IPY_MODEL_2f8c1e3044d5425fa4ab4ccfa6f6816e"],"layout":"IPY_MODEL_f0e3b42ead6c4326accfcdc537d24a09"}},"482f09a1c0ff421ca3285a287f4f0620":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_64a02e18edb84f778341352a90fabfaa","placeholder":"​","style":"IPY_MODEL_f6cd2314bbf447f0a8fe0d34d7b863d0","value":"(…)-00000-of-00001-32a2d2de76910062.parquet: 100%"}},"51f0c5b105644111ac9a8ad090af193c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd599f0b28c94b0381e86399fd804d9d","max":18401807,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f6f98cd412ba4f36a71825328dda7916","value":18401807}},"2f8c1e3044d5425fa4ab4ccfa6f6816e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d0a3c79d4e1486cbc2b7467e1364516","placeholder":"​","style":"IPY_MODEL_aee3230f58134abbad3b8b1c06bb323c","value":" 18.4M/18.4M [00:00&lt;00:00, 43.0MB/s]"}},"f0e3b42ead6c4326accfcdc537d24a09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64a02e18edb84f778341352a90fabfaa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6cd2314bbf447f0a8fe0d34d7b863d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dd599f0b28c94b0381e86399fd804d9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6f98cd412ba4f36a71825328dda7916":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5d0a3c79d4e1486cbc2b7467e1364516":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aee3230f58134abbad3b8b1c06bb323c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"080f875fab7d466f9cc56e3a7fc43f1b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e5ca9db4da234792acdf787457051ee0","IPY_MODEL_1265a269743441afae2db6f0daff34a0","IPY_MODEL_e3d512de63be4a28af2654a5157f62f5"],"layout":"IPY_MODEL_7cc92e4e4015423c906cb27cc51684cd"}},"e5ca9db4da234792acdf787457051ee0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0401f7cd4bb45789b5c32817c861505","placeholder":"​","style":"IPY_MODEL_1c09b5dfb423492fb19ba515d8538c09","value":"(…)-00000-of-00001-90850d7d3fd03986.parquet: 100%"}},"1265a269743441afae2db6f0daff34a0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_79137b8f6dc84450b01fc97396d48e61","max":188291,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d3642c5eb17d4687845ef4700ec5b2eb","value":188291}},"e3d512de63be4a28af2654a5157f62f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cfa4c31da7ec4253abf0372634a79612","placeholder":"​","style":"IPY_MODEL_b6deb1489f644affaa003d74b8e78534","value":" 188k/188k [00:00&lt;00:00, 10.5MB/s]"}},"7cc92e4e4015423c906cb27cc51684cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0401f7cd4bb45789b5c32817c861505":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c09b5dfb423492fb19ba515d8538c09":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"79137b8f6dc84450b01fc97396d48e61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3642c5eb17d4687845ef4700ec5b2eb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cfa4c31da7ec4253abf0372634a79612":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6deb1489f644affaa003d74b8e78534":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f83a12dcc37445178aedbcf91df90b91":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_042b015891474e0786f5347d4cb6c7eb","IPY_MODEL_81afe53a078c4cf4b7edd590295f7d40","IPY_MODEL_f072d4fbd28c4b25bf6668de6e06e201"],"layout":"IPY_MODEL_1bc53ca0f82e405db1af8942077a3000"}},"042b015891474e0786f5347d4cb6c7eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_acb7d4191c324bbbafc98ea7f18eaea0","placeholder":"​","style":"IPY_MODEL_fb0b7b046c6349dcb1591114a8ecaf72","value":"Generating train split: 100%"}},"81afe53a078c4cf4b7edd590295f7d40":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f139795bc44b46a39333af47570597fd","max":133166,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f181afed89ba4c7897813074f898b9b6","value":133166}},"f072d4fbd28c4b25bf6668de6e06e201":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_49bd5303a9154ac98d34481c8cd30e39","placeholder":"​","style":"IPY_MODEL_f18356d0bf9e43f2b13f54b7a2e17607","value":" 133166/133166 [00:00&lt;00:00, 587145.70 examples/s]"}},"1bc53ca0f82e405db1af8942077a3000":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"acb7d4191c324bbbafc98ea7f18eaea0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb0b7b046c6349dcb1591114a8ecaf72":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f139795bc44b46a39333af47570597fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f181afed89ba4c7897813074f898b9b6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"49bd5303a9154ac98d34481c8cd30e39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f18356d0bf9e43f2b13f54b7a2e17607":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4dcaeeb4c5e74b8a8e7f008a7c2af06d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_de94271a61a343afb18d343f3f287887","IPY_MODEL_9121d8bccd3642a98e23247d9dec5fca","IPY_MODEL_07f34c8ee15d439db05b0b84b5d1244d"],"layout":"IPY_MODEL_9a6b7f1dcf5b40d293d34c944a15be9d"}},"de94271a61a343afb18d343f3f287887":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e9915734aba4ea4835877bafb51f848","placeholder":"​","style":"IPY_MODEL_2a67385347714c8ea56c0b8c4b0cd0b7","value":"Generating test split: 100%"}},"9121d8bccd3642a98e23247d9dec5fca":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1374f87762c543e9b0380b514eb5cbb5","max":1268,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1c834547f55542c0ac39d47db3b57a21","value":1268}},"07f34c8ee15d439db05b0b84b5d1244d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb48a97adde14be4992a4ff5968afce2","placeholder":"​","style":"IPY_MODEL_121a1c7c978f4ed3b55101a17d7cdc98","value":" 1268/1268 [00:00&lt;00:00, 60755.07 examples/s]"}},"9a6b7f1dcf5b40d293d34c944a15be9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e9915734aba4ea4835877bafb51f848":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a67385347714c8ea56c0b8c4b0cd0b7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1374f87762c543e9b0380b514eb5cbb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c834547f55542c0ac39d47db3b57a21":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eb48a97adde14be4992a4ff5968afce2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"121a1c7c978f4ed3b55101a17d7cdc98":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"383b1c09355840e5ad736775e2abb84b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a9b63a14b52340789086e51e9cea53f7","IPY_MODEL_62c9656b93b546a7a97772bb95141446","IPY_MODEL_7c6c2f0b71024528891b245aed613186"],"layout":"IPY_MODEL_2a759d64a51147a7b4949c72c59a424c"}},"a9b63a14b52340789086e51e9cea53f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_facf8493faf6473c8ee330ef5118a974","placeholder":"​","style":"IPY_MODEL_420d19fa137b458c89ba935fa706d2e3","value":"model.safetensors: 100%"}},"62c9656b93b546a7a97772bb95141446":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_83aceb8947a249e0809fbd21c0e6a26f","max":714290682,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a5ed6d0b31fa473b95f4fa58fb4d19ad","value":714290682}},"7c6c2f0b71024528891b245aed613186":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d1e3fb4e6294d19a1a5b046ad2abb80","placeholder":"​","style":"IPY_MODEL_8608618bf7364b8799042f48bcbe589b","value":" 714M/714M [00:03&lt;00:00, 226MB/s]"}},"2a759d64a51147a7b4949c72c59a424c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"facf8493faf6473c8ee330ef5118a974":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"420d19fa137b458c89ba935fa706d2e3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"83aceb8947a249e0809fbd21c0e6a26f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5ed6d0b31fa473b95f4fa58fb4d19ad":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9d1e3fb4e6294d19a1a5b046ad2abb80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8608618bf7364b8799042f48bcbe589b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ab9a88cd38014e64b51ca99498639b0c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_439b02baffdb4c0e8d48b5e6e4543a06","IPY_MODEL_f5b9c0177988409182a7098b7420361b","IPY_MODEL_db309b776a764680a191200dd99169bb"],"layout":"IPY_MODEL_1856af12e82446c6b8e324690ec8d050"}},"439b02baffdb4c0e8d48b5e6e4543a06":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a333b2f92cca418bb4ed6f0f8b73fd2a","placeholder":"​","style":"IPY_MODEL_be26728bd76044e6a3b9d8ab61ad55d3","value":"Downloading builder script: 100%"}},"f5b9c0177988409182a7098b7420361b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1537385a2834f0ab18fe23028c987c1","max":8146,"min":0,"orientation":"horizontal","style":"IPY_MODEL_53d1dfeb65aa4feb9b101acd3e580415","value":8146}},"db309b776a764680a191200dd99169bb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_32fda8ea160c4b8a9dc10878b60fa88e","placeholder":"​","style":"IPY_MODEL_ba0f01720230486bb16bdfcfea575d44","value":" 8.15k/8.15k [00:00&lt;00:00, 684kB/s]"}},"1856af12e82446c6b8e324690ec8d050":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a333b2f92cca418bb4ed6f0f8b73fd2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be26728bd76044e6a3b9d8ab61ad55d3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f1537385a2834f0ab18fe23028c987c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53d1dfeb65aa4feb9b101acd3e580415":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"32fda8ea160c4b8a9dc10878b60fa88e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba0f01720230486bb16bdfcfea575d44":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h1j9MdmIX-H6","executionInfo":{"status":"ok","timestamp":1730036442339,"user_tz":-420,"elapsed":88998,"user":{"displayName":"Minh Trần Khánh","userId":"16846330008114299858"}},"outputId":"9554387a-f400-4fcd-cba2-b63a7d3ea662"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# prompt: Kết nối gg drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","source":["!pip install -q datasets sacrebleu accelerate evaluate"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JdoyIHRAYIsT","executionInfo":{"status":"ok","timestamp":1730023614782,"user_tz":-420,"elapsed":9438,"user":{"displayName":"Minh Trần Khánh","userId":"16846330008114299858"}},"outputId":"65eeee05-c30c-4255-f8ef-686d395c2fbe"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.7/472.7 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n","ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["import os\n","import torch\n","import torch.nn as nn\n","from transformers import *\n","import sacrebleu\n","from datasets import load_dataset\n","from torch.utils.data import Dataset\n","import numpy as np\n","import evaluate"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4kDETHL4YKOQ","executionInfo":{"status":"ok","timestamp":1730023634982,"user_tz":-420,"elapsed":20205,"user":{"displayName":"Minh Trần Khánh","userId":"16846330008114299858"}},"outputId":"36f95a49-ed6e-4ea3-f982-0c4d94a8c67a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/deepspeed.py:24: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","GroupViT models are not usable since `tensorflow_probability` can't be loaded. It seems you have `tensorflow_probability` installed with the wrong tensorflow version.Please try to reinstall it following the instructions here: https://github.com/tensorflow/probability.\n","TAPAS models are not usable since `tensorflow_probability` can't be loaded. It seems you have `tensorflow_probability` installed with the wrong tensorflow version. Please try to reinstall it following the instructions here: https://github.com/tensorflow/probability.\n"]}]},{"cell_type":"code","source":["data['translation']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ImU9mjApfEaf","executionInfo":{"status":"ok","timestamp":1730008484727,"user_tz":-420,"elapsed":1934,"user":{"displayName":"Minh Trần Khánh","userId":"16846330008114299858"}},"outputId":"8dae25aa-0ddf-4df8-d1f8-f3ef5eefcc9c"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'en': 'The science behind a climate headline',\n","  'vi': 'Khoa học đằng sau một tiêu đề về khí hậu'},\n"," {'en': 'In 4 minutes , atmospheric chemist Rachel Pike provides a glimpse of the massive scientific effort behind the bold headlines on climate change , with her team -- one of thousands who contributed -- taking a risky flight over the rainforest in pursuit of data on a key molecule .',\n","  'vi': 'Trong 4 phút , chuyên gia hoá học khí quyển Rachel Pike giới thiệu sơ lược về những nỗ lực khoa học miệt mài đằng sau những tiêu đề táo bạo về biến đổi khí hậu , cùng với đoàn nghiên cứu của mình -- hàng ngàn người đã cống hiến cho dự án này -- một chuyến bay mạo hiểm qua rừng già để tìm kiếm thông tin về một phân tử then chốt .'},\n"," {'en': \"I 'd like to talk to you today about the scale of the scientific effort that goes into making the headlines you see in the paper .\",\n","  'vi': 'Tôi muốn cho các bạn biết về sự to lớn của những nỗ lực khoa học đã góp phần làm nên các dòng tít bạn thường thấy trên báo .'},\n"," {'en': 'Headlines that look like this when they have to do with climate change , and headlines that look like this when they have to do with air quality or smog .',\n","  'vi': 'Có những dòng trông như thế này khi bàn về biến đổi khí hậu , và như thế này khi nói về chất lượng không khí hay khói bụi .'},\n"," {'en': 'They are both two branches of the same field of atmospheric science .',\n","  'vi': 'Cả hai đều là một nhánh của cùng một lĩnh vực trong ngành khoa học khí quyển .'},\n"," {'en': 'Recently the headlines looked like this when the Intergovernmental Panel on Climate Change , or IPCC , put out their report on the state of understanding of the atmospheric system .',\n","  'vi': 'Các tiêu đề gần đây trông như thế này khi Ban Điều hành Biến đổi khí hậu Liên chính phủ , gọi tắt là IPCC đưa ra bài nghiên cứu của họ về hệ thống khí quyển .'},\n"," {'en': 'That report was written by 620 scientists from 40 countries .',\n","  'vi': 'Nghiên cứu được viết bởi 620 nhà khoa học từ 40 quốc gia khác nhau .'},\n"," {'en': 'They wrote almost a thousand pages on the topic .',\n","  'vi': 'Họ viết gần 1000 trang về chủ đề này .'},\n"," {'en': 'And all of those pages were reviewed by another 400-plus scientists and reviewers , from 113 countries .',\n","  'vi': 'Và tất cả các trang đều được xem xét bởi 400 khoa học gia và nhà phê bình khác từ 113 quốc gia .'},\n"," {'en': \"It 's a big community . It 's such a big community , in fact , that our annual gathering is the largest scientific meeting in the world .\",\n","  'vi': 'Đó là cả một cộng đồng lớn , lớn đến nỗi trên thực tế cuộc tụ hội hằng năm của chúng tôi là hội nghị khoa học [ tự nhiên ] lớn nhất thế giới .'},\n"," {'en': 'Over 15,000 scientists go to San Francisco every year for that .',\n","  'vi': 'Mỗi năm , hơn 15,000 nhà khoa học đến San Francisco để tham dự hội nghị này .'},\n"," {'en': 'And every one of those scientists is in a research group , and every research group studies a wide variety of topics .',\n","  'vi': 'Mỗi một khoa học gia đều thuộc một nhóm nghiên cứu , và mỗi nhóm đều nghiên cứu rất nhiều đề tài đa dạng .'},\n"," {'en': \"For us at Cambridge , it 's as varied as the El Niño oscillation , which affects weather and climate , to the assimilation of satellite data , to emissions from crops that produce biofuels , which is what I happen to study .\",\n","  'vi': 'Với chúng tôi , tại Cambridge , các đề tài thay đổi từ sự dao động của El Niño , vốn có tác động đến thời tiết và khí hậu , sự đồng hoá thông tin từ vệ tinh , khí thải từ những cánh đồng nhiên liệu sinh học , tình cờ lại là đề tài tôi nghiên cứu .'},\n"," {'en': 'And in each one of these research areas , of which there are even more , there are PhD students , like me , and we study incredibly narrow topics , things as narrow as a few processes or a few molecules .',\n","  'vi': 'Mỗi lĩnh vực nghiên cứu lại chia ra những lĩnh vực nhỏ hơn , và những nghiên cứu sinh có bằng tiến sĩ , như tôi , phải nghiên cứu những đề tài vô cùng cụ thể , cụ thể như chỉ vài quy trình hay vài phân tử .'},\n"," {'en': \"And one of the molecules I study is called isoprene , which is here . It 's a small organic molecule . You 've probably never heard of it .\",\n","  'vi': 'Một trong số những phân tử tôi nghiên cứu tên là isoprene . Đây . Nó là một phân tử hữu cơ nhỏ . Có thể các bạn cũng chưa từng nghe tên .'},\n"," {'en': 'The weight of a paper clip is approximately equal to 900 zeta-illion -- 10 to the 21st -- molecules of isoprene .',\n","  'vi': 'Trọng lượng của một chiếc kẹp giấy vào khoảng 900 zeta-illion -- 10 mũ 21 -- phân tử isoprene .'},\n"," {'en': 'But despite its very small weight , enough of it is emitted into the atmosphere every year to equal the weight of all the people on the planet .',\n","  'vi': 'Dù trọng lượng phân tử rất nhỏ , thế nhưng lượng isoprene được thải vào khí quyển hàng năm ngang ngửa với tổng trọng lượng của dân số toàn cầu .'},\n"," {'en': \"It 's a huge amount of stuff . It 's equal to the weight of methane .\",\n","  'vi': 'Đó là một lượng khí thải khổng lồ , bằng tổng trọng lượng của mêtan .'},\n"," {'en': \"And because it 's so much stuff , it 's really important for the atmospheric system .\",\n","  'vi': 'Chính vì lượng khí thải rất lớn , nó có ý nghĩa quan trọng với hệ thống khí quyển .'},\n"," {'en': \"Because it 's important to the atmospheric system , we go to all lengths to study this thing .\",\n","  'vi': 'Chính vì nó có ý nghĩa quan trọng với hệ thống khí quyển , giá nào chúng tôi cũng theo đuổi nghiên cứu này đến cùng .'},\n"," {'en': 'We blow it up and look at the pieces .',\n","  'vi': 'Chúng tôi cho nó nổ và xem xét từng mảnh nhỏ .'},\n"," {'en': 'This is the EUPHORE Smog Chamber in Spain .',\n","  'vi': 'Đây là Phòng nghiên cứu khói bụi EUPHORE ở Tây Ban Nha .'},\n"," {'en': 'Atmospheric explosions , or full combustion , takes about 15,000 times longer than what happens in your car .',\n","  'vi': 'Nổ trong không khí hay cháy hoàn toàn diễn ra chậm hơn 15,000 lần so với những phản ứng trong động cơ xe .'},\n"," {'en': 'But still , we look at the pieces .',\n","  'vi': 'Dù vậy , chúng tôi vẫn xem xét từng mảnh nhỏ .'},\n"," {'en': 'We run enormous models on supercomputers ; this is what I happen to do .',\n","  'vi': 'Chúng tôi chạy những mô hình khổng lồ trên siêu máy tính ; đây là công việc của tôi .'},\n"," {'en': 'Our models have hundreds of thousands of grid boxes calculating hundreds of variables each , on minute timescales .',\n","  'vi': 'Mô hình của chúng tôi gồm hàng trăm ngàn thùng xếp chồng tính toán với hàng trăm biến số trong thời gian cực ngắn .'},\n"," {'en': 'And it takes weeks to perform our integrations .',\n","  'vi': 'Mà vẫn cần hàng tuần mới thực hiện xong các phép tích phân .'},\n"," {'en': \"And we perform dozens of integrations in order to understand what 's happening .\",\n","  'vi': 'Chúng tôi cần làm hàng tá phép tính như thế để hiểu được những gì đang xảy ra .'},\n"," {'en': 'We also fly all over the world looking for this thing .',\n","  'vi': 'Chúng tôi còn bay khắp thế giới để tìm phân tử này .'},\n"," {'en': 'I recently joined a field campaign in Malaysia . There are others .',\n","  'vi': 'Gần đây tôi tham gia một cuộc khảo sát thực địa ở Malaysia . Còn nhiều chuyến khác nữa .'},\n"," {'en': 'We found a global atmospheric watchtower there , in the middle of the rainforest , and hung hundreds of thousands of dollars worth of scientific equipment off this tower , to look for isoprene , and of course , other things while we were there .',\n","  'vi': 'Chúng tôi tìm thấy một tháp canh khí hậu toàn cầu ở đó , ngay giữa rừng sâu , và chúng tôi treo các thiết bị nghiên cứu trị giá hàng trăm ngàn đô la xa khỏi cái tháp để tìm isoprene , và tất nhiên là những thứ khác nữa trong suốt thời gian ở đó .'},\n"," {'en': 'This is the tower in the middle of the rainforest , from above .',\n","  'vi': 'Đây chính là cái tháp giữa rừng sâu , nhìn từ trên cao .'},\n"," {'en': 'And this is the tower from below .', 'vi': 'Và từ dưới đất .'},\n"," {'en': 'And on part of that field campaign we even brought an aircraft with us .',\n","  'vi': 'Có giai đoạn chúng tôi còn mang cả máy bay theo .'},\n"," {'en': 'And this plane , the model , BA146 , which was run by FAAM , normally flies 120 to 130 people .',\n","  'vi': 'Chiếc phi cơ này , mẫu BA146 do FAAM sở hữu thông thường có thể chở từ 120-130 người .'},\n"," {'en': 'So maybe you took a similar aircraft to get here today .',\n","  'vi': 'Rất có thể bạn đã ở trên một chiếc tương tự khi đến đây hôm nay .'},\n"," {'en': \"But we didn 't just fly it . We were flying at 100 meters above the top of the canopy to measure this molecule -- incredibly dangerous stuff .\",\n","  'vi': 'Chúng tôi không chỉ bay . Chúng tôi bay cách tầng vòm của rừng 100 mét để đo đạc phân tử này -- chuyện vô cùng nguy hiểm .'},\n"," {'en': 'We have to fly at a special incline in order to make the measurements .',\n","  'vi': 'Chúng tôi phải bay với độ nghiêng đặc biệt để thực hiện các phép đo .'},\n"," {'en': 'We hire military and test pilots to do the maneuvering .',\n","  'vi': 'Phải thuê quân đội và sát hạch phi cơ để điều khiển máy bay .'},\n"," {'en': 'We have to get special flight clearance .',\n","  'vi': 'Phải xin lệnh đặc biệt cho phép bay .'},\n"," {'en': 'And as you come around the banks in these valleys , the forces can get up to two Gs .',\n","  'vi': 'Khi bay quanh những bờ sông ở thung lũng , các lực tác động có thể lên tới 2G .'},\n"," {'en': \"And the scientists have to be completely harnessed in in order to make measurements while they 're on board .\",\n","  'vi': 'Các nhà khoa học phải được thắt chặt hoàn toàn vào ghế để có thể thực hiện đo đạc trên máy bay .'},\n"," {'en': \"So , as you can imagine , the inside of this aircraft doesn 't look like any plane you would take on vacation .\",\n","  'vi': 'Vì vậy , bạn có thể hình dung , bên trong đó hoàn toàn không giống với bất kỳ chiếc máy bay du lịch nào khác .'},\n"," {'en': \"It 's a flying laboratory that we took to make measurements in the region of this molecule .\",\n","  'vi': 'Đó là cả một phòng thí nghiệm di động để giúp chúng tôi thực hiện các phép đo .'},\n"," {'en': 'We do all of this to understand the chemistry of one molecule .',\n","  'vi': 'Chúng tôi làm tất cả chỉ để tìm hiểu tính chất hoá học của một phân tử .'},\n"," {'en': 'And when one student like me has some sort of inclination or understanding about that molecule , they write one scientific paper on the subject .',\n","  'vi': 'Khi nghiên cứu sinh như tôi có sở thích hay hiểu biết về phân tử đó , đại loại như thế , họ sẽ viết cả một bài nghiên cứu khoa học về đề tài đó .'},\n"," {'en': \"And out of that field campaign we 'll probably get a few dozen papers on a few dozen processes or molecules .\",\n","  'vi': 'Và ngoài cuộc khảo sát đó chúng tôi sẽ còn hàng tá bài nghiên cứu về hàng tá các quy trình hay phân tử .'},\n"," {'en': 'And as a body of knowledge builds up , it will form one subsection , or one sub-subsection of an assessment like the IPCC , although we have others .',\n","  'vi': 'Khi một phần kiến thức dần định hình , nó sẽ tạo thành một tiểu mục , hay một tiểu-tiểu mục trong một bản kiểm định như ở IPCC , mặc dù còn có nhiều bài khác .'},\n"," {'en': 'And each one of the 11 chapters of the IPCC has six to ten subsections .',\n","  'vi': 'Mỗi một chương trong 11 chương của IPCC có từ 6 đến 10 tiểu mục như thế .'},\n"," {'en': 'So you can imagine the scale of the effort .',\n","  'vi': 'Nói như thế để bạn hình dung được quy mô của những nỗ lực này .'},\n"," {'en': 'In each one of those assessments that we write , we always tag on a summary , and the summary is written for a non-scientific audience .',\n","  'vi': 'Trong mỗi bản đánh giá chúng tôi viết , chúng tôi luôn đính kèm một bản tóm lược , được viết cho những độc giả không chuyên về khoa học .'},\n"," {'en': 'And we hand that summary to journalists and policy makers , in order to make headlines like these .',\n","  'vi': 'Chúng tôi đưa bản tóm lược cho các nhà báo và nhà chính sách để có được những dòng tít như thế này .'},\n"," {'en': 'Thank you very much .', 'vi': 'Cám ơn rất nhiều .'},\n"," {'en': 'Christopher deCharms : A look inside the brain in real time',\n","  'vi': 'Christopher deCharms quét não bộ theo thời gian thực'},\n"," {'en': 'Neuroscientist and inventor Christopher deCharms demonstrates a new way to use fMRI to show brain activity -- thoughts , emotions , pain -- while it is happening . In other words , you can actually see how you feel .',\n","  'vi': 'Nhà thần kinh học và nhà sáng chế Christopher deCharms cho thấy cách sử dụng fMRI để ghi lại những hoạt động của não bộ -- suy nghĩ , cảm xúc , đau đớn-- ngay khi chúng xảy ra . Nói cách khác , bạn thực sự nhìn thấy những gì bạn cảm nhận .'},\n"," {'en': \"Hi . I 'm going to ask you to raise your arms and wave back , just the way I am -- kind of a royal wave .\",\n","  'vi': 'Xin chào . Tôi đề nghị các bạn giơ tay và vẫy về phía sau như tôi làm đây -- như cách vẫy hoàng gia .'},\n"," {'en': 'You can mimic what you can see .',\n","  'vi': 'Bắt chước những gì bạn nhìn thấy .'},\n"," {'en': 'You can program the hundreds of muscles in your arm .',\n","  'vi': 'Bạn có thể lập trình cho hàng trăm cơ bắp trong cánh tay .'},\n"," {'en': \"Soon , you 'll be able to look inside your brain and program , control the hundreds of brain areas that you see there .\",\n","  'vi': 'Bạn sẽ sớm nhìn được vào bên trong não bộ , điều khiển hàng trăm vùng trên não mà bạn thấy đó .'},\n"," {'en': \"I 'm going to tell you about that technology .\",\n","  'vi': 'Tôi sẽ cho bạn biết về công nghệ đó .'},\n"," {'en': 'People have wanted to look inside the human mind , the human brain , for thousands of years .',\n","  'vi': 'Con người muốn nhìn được vào bên trong ý nghĩ , não người , qua hàng ngàn năm nay ,'},\n"," {'en': 'Well , coming out of the research labs just now , for our generation , is the possibility to do that .',\n","  'vi': 'Vâng , bước ra khỏi phòng thì nghiệm có vẻ như là cách thế hệ chúng ta giải quyết việc đó .'},\n"," {'en': 'People envision this as being very difficult .',\n","  'vi': 'Con người tưởng tượng điều này sẽ rất khó .'},\n"," {'en': 'You had to take a spaceship , shrink it down , inject it into the bloodstream .',\n","  'vi': 'Bạn sẽ phải thu nhỏ một chiếc phi thuyền , đưa vào trong mạch máu .'},\n"," {'en': 'It was terribly dangerous .', 'vi': 'Điều này thực sự nguy hiểm .'},\n"," {'en': 'You could be attacked by white blood cells in the arteries .',\n","  'vi': 'bạn có thể bị các bạch cầu tấn công trong động mạch .'},\n"," {'en': 'But now , we have a real technology to do this .',\n","  'vi': 'Nhưng bây giờ , chúng ta có một công nghệ thực để làm việc này .'},\n"," {'en': \"We 're going to fly into my colleague Peter 's brain .\",\n","  'vi': 'Chúng ta sẽ bay vào trong não của đồng nghiệp của tôi , Peter .'},\n"," {'en': \"We 're going to do it non-invasively using MRI .\",\n","  'vi': 'Chúng ta sẽ làm điều này mà không xâm nhập bên trong , sử dụng MRI .'},\n"," {'en': \"We don 't have to inject anything . We don 't need radiation .\",\n","  'vi': 'Không cần bơm thứ gì vào . Không cần đến tia bức xạ .'},\n"," {'en': \"We will be able to fly into the anatomy of Peter 's brain -- literally , fly into his body -- but more importantly , we can look into his mind .\",\n","  'vi': 'Chúng ta sẽ có thể bay vào hộp sọ của não Peter -- theo nghĩa đen là bay vào cơ thể anh ta -- nhưng quan trọng hơn , ta có thể nhìn vào tâm trí của anh ta .'},\n"," {'en': \"When Peter moves his arm , that yellow spot you see there is the interface to the functioning of Peter 's mind taking place .\",\n","  'vi': 'Khi Peter di chuyển cánh tay , chấm màu vàng mà bạn thấy ở đó là bề mặt mà ý thức của Peter hoạt động'},\n"," {'en': \"Now you 've seen before that with electrodes you can control robotic arms , that brain imaging and scanners can show you the insides of brains .\",\n","  'vi': 'Trước đó bạn đã thấy là với các điện cực ta có thể điều khiển cánh tay robot , và ảnh chụp não bộ và máy quét có thể cho thấy bên trong của não .'},\n"," {'en': \"What 's new is that that process has typically taken days or months of analysis .\",\n","  'vi': 'Cái mới chính là quá trình đã từng chiếm nhiều ngày hoặc nhiều tháng để phân tích .'},\n"," {'en': \"We 've collapsed that through technology to milliseconds , and that allows us to let Peter to look at his brain in real time as he 's inside the scanner .\",\n","  'vi': 'Chúng ta đã đạt được điều này qua công nghệ đến mức mili-giây. và điều này cho phép Peter nhìn thấy não bộ anh ấy dưới thời gian thực khi anh ta ở trong máy quét .'},\n"," {'en': 'He can look at these 65,000 points of activation per second .',\n","  'vi': 'Anh ta có thể thấy 65000 điểm kích hoạt trên 1 giây .'},\n"," {'en': 'If he can see this pattern in his own brain , he can learn how to control it .',\n","  'vi': 'Nếu thấy được mẫu này của não bộ , anh ta có thể học cách điều khiển nó .'},\n"," {'en': \"There have been three ways to try to impact the brain : the therapist 's couch , pills and the knife .\",\n","  'vi': 'Có ba cách để làm ảnh hưởng đến não : giường của nhà trị liệu học , thuốc viên và con dao .'},\n"," {'en': 'This is a fourth alternative that you are soon going to have .',\n","  'vi': 'Đây là lụa chọn thứ tư mà bạn sẽ nhanh chóng có .'},\n"," {'en': 'We all know that as we form thoughts , they form deep channels in our minds and in our brains .',\n","  'vi': 'Ta đều biết rằng khi suy nghĩ , ta đã tạo ra những kênh nằm sâu trong tâm trí và trong não .'},\n"," {'en': 'Chronic pain is an example . If you burn yourself , you pull your hand away .',\n","  'vi': 'Đau kinh niên là một ví dụ . Nếu bạn phỏng , bạn sẽ giật tay ra xa .'},\n"," {'en': \"But if you 're still in pain in six months ' or six years ' time , it 's because these circuits are producing pain that 's no longer helping you .\",\n","  'vi': 'Nhưng nếu trong sáu tháng , hay sáu năm , cơn đau vẫn không dứt , đó là vì những vòng tuần hoàn này đang sản xuất ra cơn đau chống lại bạn .'},\n"," {'en': \"If we can look at the activation in the brain that 's producing the pain , we can form 3D models and watch in real time the brain process information , and then we can select the areas that produce the pain .\",\n","  'vi': 'Nếu ta có thể nhìn vào các xung kích hoạt của não sản xuất ra cơn đau , ta có thể lập ra các mô hình 3 chiều và nhìn thấy các thông tin quá trình của não theo thời gian thực , chúng ta có thể lựa chọn vùng sản xuất cơn đau .'},\n"," {'en': 'So put your arms back up and flex your bicep .',\n","  'vi': 'Vâng , hãy giơ tay lên và cong cơ cánh tay lại .'},\n"," {'en': 'Now imagine that you will soon be able to look inside your brain and select brain areas to do that same thing .',\n","  'vi': 'Bây giờ hãy tưởng tượng bạn sớm được nhìn vào bên trong não mình và được chọn vùng trên não để làm cùng một việc đó .'},\n"," {'en': \"What you 're seeing here is , we 've selected the pathways in the brain of a chronic pain patient .\",\n","  'vi': 'Và điều bạn thấy là , Chúng ta đã chọn đường đi trong não bộ của một bệnh nhân đau kinh niên .'},\n"," {'en': \"This may shock you , but we 're literally reading this person 's brain in real time .\",\n","  'vi': 'Điều này có thể làm bạn shock , nhưng thực sự chúng ta đã đọc được não bộ của người này theo thời gian thực .'},\n"," {'en': \"They 're watching their own brain activation , and they 're controlling the pathway that produces their pain .\",\n","  'vi': 'Họ đang theo dõi hoạt động não bộ của chính họ , và điều khiển con đường gây nên cơn đau .'},\n"," {'en': \"They 're learning to flex this system that releases their own endogenous opiates .\",\n","  'vi': 'Họ tập co dãn hệ thống tiết ra chất xoa dịu từ bên trong .'},\n"," {'en': \"As they do it , in the upper left is a display that 's yoked to their brain activation of their own pain being controlled .\",\n","  'vi': 'Khi họ làm vậy , ở góc trên bên trái ta thấy được thứ đã kết nối kích hoạt não bộ của cơn đau đang được điều khiển của họ .'},\n"," {'en': 'When they control their brain , they can control their pain .',\n","  'vi': 'Khi họ điều khiển não bộ , họ điều khiển cơn đau của mình .'},\n"," {'en': \"This is an investigational technology , but , in clinical trials , we 're seeing a 44 to 64 percent decrease in chronic pain patients .\",\n","  'vi': 'Đây là một phương pháp thử nghiệm , nhưng trong các phép thử chúng ta đã thấy lượng bệnh nhân đau kinh niên giảm 44-64 % .'},\n"," {'en': 'This is not \" The Matrix . \" You can only do this to yourself . You take control .',\n","  'vi': 'Đây không phải là \" Ma trận . \" Bạn chỉ có thể làm điều này với chính bản thân mình . Bạn tự làm chủ .'},\n"," {'en': \"I 've seen inside my brain . You will too , soon .\",\n","  'vi': 'Tôi đã nhìn vào trong não mình . Bạn cũng sớm làm như vậy thôi .'},\n"," {'en': 'When you do , what do you want to control ?',\n","  'vi': 'Khi bạn làm được , bạn muốn điều khiển cái gì ?'},\n"," {'en': 'You will be able to look at all the aspects that make you yourself , all your experiences .',\n","  'vi': 'Bạn có thể nhìn vào mọi phương diện khiến bạn là chính mình , tất cả những kí ức .'},\n"," {'en': \"These are some of the areas we 're working on today that I don 't have time to go into in detail .\",\n","  'vi': 'Đây là một trong số những vấn đề chúng ta nói đến hôm nay mà tôi không có thời gian để đi vào chi tiết .'},\n"," {'en': 'But I want to leave with you the big question .',\n","  'vi': 'Nhưng tôi có một câu hỏi lớn dành cho bạn .'},\n"," {'en': \"We are the first generation that 's going to be able to enter into , using this technology , the human mind and brain .\",\n","  'vi': 'Chúng ta là thế hệ đầu tiên có thể bước vào , sử dụng công nghệ này , trí tuệ con người và não bộ ,'},\n"," {'en': 'Where will we take it ?', 'vi': 'Chúng ta sẽ đưa nó đến đâu ?'},\n"," {'en': 'Beeban Kidron : The shared wonder of film',\n","  'vi': 'Beeban Kidron : Đìều kì diệu của điện ảnh'},\n"," {'en': 'Movies have the power to create a shared narrative experience and to shape memories and worldviews . British film director Beeban Kidron invokes iconic film scenes -- from & lt ; em & gt ; Miracle in Milan & lt ; / em & gt ; to & lt ; em & gt ; Boyz n the Hood & lt ; / em & gt ; -- as she shows how her group FILMCLUB shares great films with kids .',\n","  'vi': 'Những bộ phim có sức mạnh tạo nên những kinh nghiệm tường thuật được chia sẻ và định hình những kí ức và những cách nhìn thế giới . Nhà đạo diễn phim người Anh - Beeban Kidron dẫn chứng bằng những cảnh phim hình tượng -- từ \" Phép màu ở Milan \" đến \" Những câu bé và khu dân cư \" -- khi bà kể cách mà nhóm FILMCLUB của bà chia sẻ những thước phim vĩ đại với lũ trẻ .'},\n"," {'en': 'Evidence suggests that humans in all ages and from all cultures create their identity in some kind of narrative form .',\n","  'vi': 'Bằng chứng cho thấy rằng con người ở mọi lứa tuổi và từ mọi nền văn hoá tạo ra danh tính của họ theo một dạng tường thuật nào đó .'},\n"," {'en': 'From mother to daughter , preacher to congregant , teacher to pupil , storyteller to audience .',\n","  'vi': 'Từ mẹ đến con gái , người thuyết giáo đến người theo hội , giáo viên đến học sinh , người kể chuyện đến khán thính giả .'},\n"," {'en': 'Whether in cave paintings or the latest uses of the Internet , human beings have always told their histories and truths through parable and fable .',\n","  'vi': 'Bất kể ở các hình vẽ trong hang động hay các cách dùng mới nhất của Internet , con người luôn kể câu chuyện lịch sử và về những sự thật qua dụ ngôn và chuyện tưởng tượng'},\n"," {'en': 'We are inveterate storytellers .',\n","  'vi': 'Chúng ta là những người kể chuyện bản năng .'},\n"," {'en': 'But where , in our increasingly secular and fragmented world , do we offer communality of experience , unmediated by our own furious consumerism ?',\n","  'vi': 'Nhưng ở đâu , trong thế giới già nhanh chóng già cỗi và chia nhỏ của chúng ta , chúng ta trao tặng những kinh nghiệm mang tính cộng đồng , không qua trung gian bởi quyền lợi tiêu dùng kịch liệt của chính chúng ta ?'},\n"," {'en': 'And what narrative , what history , what identity , what moral code are we imparting to our young ?',\n","  'vi': 'Và chuyện tường thuật nào , lịch sử nào , bản sắc nào , qui tắc đạo đức nào mà chúng ta đang truyền đạt lại cho thế hệ trẻ của chúng ta ?'},\n"," {'en': \"Cinema is arguably the 20th century 's most influential art form .\",\n","  'vi': 'Điện ảnh đáng được tranh cãi là dạng nghệ thuật ảnh hưởng nhất trong thế kỉ 20 .'},\n"," {'en': 'Its artists told stories across national boundaries , in as many languages , genres and philosophies as one can imagine .',\n","  'vi': 'Nó là những câu chuyện kể của các nghệ sĩ vượt qua các ranh giới quốc gia , dưới vô vàn ngôn ngữ , thể loại và triết lý mà một người có thể tưởng tượng ra được .'},\n"," {'en': 'Indeed , it is hard to find a subject that film has yet to tackle .',\n","  'vi': 'Thực sự là , thật khó để tìm một chủ đề mà điện ảnh chưa động đến .'},\n"," {'en': \"During the last decade we 've seen a vast integration of global media , now dominated by a culture of the Hollywood blockbuster .\",\n","  'vi': 'Trong suốt thập kỉ qua chúng ta đang chứng kiến sự hội nhập rộng lớn của phương tiện truyền thông toàn cầu , giờ bị thống trị bởi văn hoá phim bom tấn Hollywood .'},\n"," {'en': 'We are increasingly offered a diet in which sensation , not story , is king .',\n","  'vi': 'Chúng ta đang được phục vụ một chế độ \" ăn kiêng \" mà sự cảm giác là chủ chốt , chứ không phải nội dung .'},\n"," {'en': 'What was common to us all 40 years ago -- the telling of stories between generations -- is now rarified .',\n","  'vi': 'Điều gì đã quen thuộc với tất cả chúng ta 40 năm trước -- việc kể các câu chuyện giữa các thế hệ-- bây giờ rất hiếm hoi .'},\n"," {'en': 'As a filmmaker , it worried me .',\n","  'vi': 'Là một nhà làm phim , điều đó làm tôi lo ngại .'},\n"," {'en': 'As a human being , it puts the fear of God in me .',\n","  'vi': 'Là một con người , nó reo sự sợ hãi của Chúa vào tôi .'},\n"," {'en': \"What future could the young build with so little grasp of where they 've come from and so few narratives of what 's possible ?\",\n","  'vi': 'Tương lai nào những con người trẻ có thể xây dựng với những nắm bắt quá nhỏ bé về nơi họ sinh ra và quá ít những câu chuyện tường thuật về chuyện gì là có thể ?'},\n"," {'en': 'The irony is palpable ; technical access has never been greater , cultural access never weaker .',\n","  'vi': 'Thật quá mỉa mai ; cơ hội nắm bắt kĩ thuật chưa bao giờ lớn hơn thế , cơ hội nắm bắt văn hoá chưa bao giờ yếu hơn thế .'},\n"," {'en': 'And so in 2006 we set up FILMCLUB , an organization that ran weekly film screenings in schools followed by discussions .',\n","  'vi': 'Và vì vậy vào năm 2006 chúng tôi lập FILMCLUB , một tổ chức định kì hàng tuần chiếu phim trong các trường học và sau đó là các cuộc thảo luận .'},\n"," {'en': 'If we could raid the annals of 100 years of film , maybe we could build a narrative that would deliver meaning to the fragmented and restless world of the young .',\n","  'vi': 'Nếu chúng ta có thể tra soát biên niên sử 100 năm của phim , có lẽ chúng ta có thể xây dựng một chuyện tường thuật mang ý nghĩa đến thế giới phân mảnh và không ngừng nghỉ của thế hệ trẻ .'},\n"," {'en': 'Given the access to technology , even a school in a tiny rural hamlet could project a DVD onto a white board .',\n","  'vi': 'Được tiếp xúc với công nghệ , ngay cả trường học ở một thôn ngoại thành nhỏ bé có thể chiếu một DVD lên một bảng trắng .'},\n"," {'en': 'In the first nine months we ran 25 clubs across the U.K. , with kids in age groups between five and 18 watching a film uninterrupted for 90 minutes .',\n","  'vi': 'Trong 9 tháng đầu tiên chúng tôi cho chạy 25 câu lạc bộ dọc nước Anh , cho những nhóm trẻ em từ 5 đến 18 tuổi xem một bộ phim không bị ngắt quãng trong 90 phút .'},\n"," {'en': 'The films were curated and contextualized .',\n","  'vi': 'Những bộ phim được biên đạo và bối cảnh hoá .'},\n"," {'en': 'But the choice was theirs , and our audience quickly grew to choose the richest and most varied diet that we could provide .',\n","  'vi': 'Nhưng sự lựa chọn thuộc về chúng , và khán thính giả của chúng tôi tăng lên nhanh chóng để chọn những món \" ăn kiêng \" giàu nhất và đa dạng nhất mà chúng tôi có thể cung cấp .'},\n"," {'en': 'The outcome , immediate .', 'vi': 'Có kết quả ngay lập tức .'},\n"," {'en': 'It was an education of the most profound and transformative kind .',\n","  'vi': 'Đó là cách giáo dục thâm tuý và có khả năng truyền tải nhất .'},\n"," {'en': 'In groups as large as 150 and as small as three , these young people discovered new places , new thoughts , new perspectives .',\n","  'vi': 'Một nhóm có tối đa 150 và tối thiểu 3 người , những bạn trẻ này khám phá những nơi mới , những suy nghĩ mới , những góc nhìn mới .'},\n"," {'en': 'By the time the pilot had finished , we had the names of a thousand schools that wished to join .',\n","  'vi': 'Ngay khi thử nghiệm kết thúc , chúng ta đã có tên của hàng ngàn trường học mong muốn được tham gia .'},\n"," {'en': 'The film that changed my life is a 1951 film by Vittorio De Sica , \" Miracle in Milan . \"',\n","  'vi': 'Bộ phim đã thay đổi cuộc đời của tôi là bộ phim năm 1951 của Vittorio De Sica , \" Phép màu ở Milan \" .'},\n"," {'en': \"It 's a remarkable comment on slums , poverty and aspiration .\",\n","  'vi': 'Đó là một lời nhận xét đáng chú ý trong những khu ổ chuột , nghèo đói và khát vọng .'},\n"," {'en': \"I had seen the film on the occasion of my father 's 50th birthday .\",\n","  'vi': 'Tôi đã xem bộ phim vào dịp sinh nhật lần thứ 50 của bố tôi .'},\n"," {'en': 'Technology then meant we had to hire a viewing cinema , find and pay for the print and the projectionist .',\n","  'vi': 'Công nghệ lúc đó đã khiến chúng ta phải thuê một rạp để xem , tìm và trả cho việc in tráng và người chiếu phim .'},\n"," {'en': 'But for my father , the emotional and artistic importance of De Sica \\'s vision was so great that he chose to celebrate his half-century with his three teenage children and 30 of their friends , \" In order , \" he said , \" to pass the baton of concern and hope on to the next generation . \"',\n","  'vi': 'Nhưng với cha của tôi , Sự quan trọng của cảm xúc và tính nghệ thuật trong cách nhìn của De Sica là rất lớn đến nỗi ông chọn nó để ăn mừng sinh nhật thứ 50 của mình với ba đứa con tuổi teen và 30 người bạn của chúng , \" Để , \" ông nói , truyền sự quan tâm và niềm hy vọng cho thế hệ tiếp theo . \"'},\n"," {'en': 'In the last shot of \" Miracle in Milan , \" slum-dwellers float skyward on flying brooms .',\n","  'vi': 'Trong cảnh cuối của \" Phép màu ở Milan \" những người trong khu ổ chuột đã nổi lên bầu trời trên những cây chổi bay .'},\n"," {'en': 'Sixty years after the film was made and 30 years after I first saw it , I see young faces tilt up in awe , their incredulity matching mine .',\n","  'vi': 'Sáu mươi năm sau khi bộ phim được làm ra và 30 năm sau lần đầu tiên tôi xem nó , tôi thấy những gương mặt trẻ nghiêng lên trong sự kinh ngạc nỗi nghi ngờ của chúng hợp với nỗi nghi ngờ của tôi .'},\n"," {'en': 'And the speed with which they associate it with \" Slumdog Millionaire \" or the favelas in Rio speaks to the enduring nature .',\n","  'vi': 'Và tốc độ mà chúng liên hệ nó với \" Triệu phú khu ổ chuột \" hay những khu phố \" favela \" ở Rio nói lên bản chất bền vững đó .'},\n"," {'en': 'In a FILMCLUB season about democracy and government , we screened \" Mr. Smith Goes to Washington . \"',\n","  'vi': 'Trong mùa chiếu của Câu lạc bộ phim về dân chủ và chính quyền , chúng tôi đã chiếu \" Ông Smith đến Washington . \"'},\n"," {'en': \"Made in 1939 , the film is older than most of our members ' grandparents .\",\n","  'vi': 'Được làm vào năm 1939 , bộ phim có tuổi già hơn tuổi của hầu hết ông bà của các thành viên'},\n"," {'en': \"Frank Capra 's classic values independence and propriety .\",\n","  'vi': 'Sự cổ điển của Frank Capra có giá trị ở tính độc lập và sự thích nghi .'},\n"," {'en': 'It shows how to do right , how to be heroically awkward .',\n","  'vi': 'Bộ phim chỉ ra làm thế nào để làm đúng , làm thế nào để trở nên kì lạ phi thường .'},\n"," {'en': 'It is also an expression of faith in the political machine as a force of honor .',\n","  'vi': 'Nó cũng là cách diễn tả về lòng tin coi bộ máy chính trị như nguồn gốc danh dự .'},\n"," {'en': 'Shortly after \" Mr. Smith \" became a FILMCLUB classic , there was a week of all-night filibustering in the House of Lords .',\n","  'vi': 'Không lâu sau đó \" Ông Smith \" trở thành bộ phim kinh điển của Câu lạc bộ phim , Có một tuần tất cả các buổi tối \" cản trở lại các luật lệ \" ở Toà nhà Nhà cầm quyền .'},\n"," {'en': 'And it was with great delight that we found young people up and down the country explaining with authority what filibustering was and why the Lords might defy their bedtime on a point of principle .',\n","  'vi': 'và thật vui vô cùng khi chúng tôi thấy những bạn trẻ trên khắp đất nước giải thích với nhà cầm quyền rằng cản trở các đạo luật là gì và tại sao các nhà cầm quyền có thể định giờ ngủ của họ theo một nguyên tắc nào đó .'},\n"," {'en': 'After all , Jimmy Stewart filibustered for two entire reels .',\n","  'vi': 'Nói chung thi Jimmy Stewart đã cản trở các đạo luật trong toàn bộ 2 bộ phim cơ mà .'},\n"," {'en': 'In choosing \" Hotel Rwanda , \" they explored genocide of the most brutal kind .',\n","  'vi': 'Bằng cách chọn \" Khách sạn Rwanda \" bọn trẻ đã khám phá về tôi diệt chủng ở dạng thú tính nhất .'},\n"," {'en': 'It provoked tears as well as incisive questions about unarmed peace-keeping forces and the double-dealing of a Western society that picks its moral fights with commodities in mind .',\n","  'vi': 'Nó gây ra những giọt nước mắt và khơi gợi những câu hỏi thâm thuý về những đội quân bảo vệ hoà bình không vũ khí và sự lừa gạt của xã hội phương tây khi đối diện với cuộc đấu tranh đạo đức với những tiện nghi thực dụng trong đầu'},\n"," {'en': 'And when \" Schindler \\'s List \" demanded that they never forget , one child , full of the pain of consciousness , remarked , \" We already forgot , otherwise how did \\' Hotel Rwanda \\' happen ? \"',\n","  'vi': 'Và khi \" Bản danh sách của Schindler \" khiến bọn trẻ không bao giờ quên , một đứa trẻ , với đầy sự đau đớn tỉnh táo , nhận xét rằng , \" Chúng ta đã quên mất rồi , nếu không thì làm thế nào mà \" Khách sạn Rwanda \" lại xảy ra ? \"'},\n"," {'en': 'As they watch more films their lives got palpably richer .',\n","  'vi': 'Khi bọn trẻ xem nhiều phim hơn , cuộc sống của chúng phong phú hơn .'},\n"," {'en': '\" Pickpocket \" started a debate about criminality disenfranchisement .',\n","  'vi': '\" Kẻ móc túi \" bắt đầu một cuộc tranh cãi về việc tước quyền công dân của tội phạm .'},\n"," {'en': '\" To Sir , with Love \" ignited its teen audience .',\n","  'vi': '\" Gửi ngài , với sự yêu mến \" đốt cháy khán giả tuổi thành niên của bộ phim .'},\n"," {'en': \"They celebrated a change in attitude towards non-white Britons , but railed against our restless school system that does not value collective identity , unlike that offered by Sidney Poitier 's careful tutelage .\",\n","  'vi': 'Chúng ăn mừng sự thay đổi về thái độ đối với những người Briton không phải da trắng , nhưng chửi rủa hệ thống trường học không ngơi nghỉ của họ không có giá trị bản sắc cộng đồng , không giống như sự giám hộ cẩn trọng của Sidney Potier mang lại .'},\n"," {'en': 'By now , these thoughtful , opinionated , curious young people thought nothing of tackling films of all forms -- black and white , subtitled , documentary , non-narrative , fantasy -- and thought nothing of writing detailed reviews that competed to favor one film over another in passionate and increasingly sophisticated prose .',\n","  'vi': 'giờ đây , những đứa trẻ sâu sắc , có chính kiến và tò mò này không nghĩ gì ngoài việc nắm lấy những bộ phim -- đen trắng , phụ đề , tài liệu , phi tường thuật hay tưởng tượng -- và không nghĩ gì về viết những bài nhân xét chi tiết tranh đua nói về những bộ phim yêu thích bằng những bài văn xuôi đam mê và càng ngày càng triết lý .'},\n"," {'en': 'Six thousand reviews each school week vying for the honor of being review of the week .',\n","  'vi': '6000 bản nhận xét mỗi tuần ở từng trường ganh đua cho sự vinh dự được thành bài nhận xét của tuần .'},\n"," {'en': 'From 25 clubs , we became hundreds , then thousands , until we were nearly a quarter of a million kids in 7,000 clubs right across the country .',\n","  'vi': 'Từ 25 câu lạc bộ , chúng tôi đã có hàng trăm , rồi hàng ngàn , cho đến khi chúng tôi có gần một phần tư triệu đứa trẻ trong 7,000 câu lạc bộ dọc đất nước .'},\n"," {'en': 'And although the numbers were , and continue to be , extraordinary , what became more extraordinary was how the experience of critical and curious questioning translated into life .',\n","  'vi': 'Mặc dù những con số đó đã , và tiếp tục tăng một cách đáng kinh ngạc , điều đã trở nên kinh ngạc hơn nữa là làm thế nào sự trải nghiệm về những câu hỏi phê bình tò mò được chuyển tải vào cuộc sống .'},\n"," {'en': 'Some of our kids started talking with their parents , others with their teachers , or with their friends .',\n","  'vi': 'Một vài đứa trẻ của chúng tôi đã bắt đầu nói chuyện với bố mẹ chúng , một số nói với giáo viên , hoặc bạn bè của chúng .'},\n"," {'en': 'And those without friends started making them .',\n","  'vi': 'Và với những em không có bạn , bắt đầu kết bạn .'},\n"," {'en': 'The films provided communality across all manner of divide .',\n","  'vi': 'Những bộ phim đem lại sự liên kết ở tất cả những dạng bị chia cắt .'},\n"," {'en': 'And the stories they held provided a shared experience .',\n","  'vi': 'Và các câu chuyện , chúng đã giúp cung cấp những kinh nghiệm mang tính chia sẻ .'},\n"," {'en': '\" Persepolis \" brought a daughter closer to her Iranian mother , and \" Jaws \" became the way in which one young boy was able to articulate the fear he \\'d experienced in flight from violence that killed first his father then his mother , the latter thrown overboard on a boat journey .',\n","  'vi': '\" Persepolis \" mang một bé gái đến gần hơn với người mẹ Iran của mình và \" Hàm cá mập \" trở thành cách mà một câu bé nhỏ tuổi có thể nói lên nỗi sợ mà cậu đã trải qua về bạo lực trong một chuyến bay đã giết chết đầu tiên là bố rồi đến cả mẹ của cậu , mẹ cậu đã bị ném qua mạn tàu trong một chuyến đi tàu'},\n"," {'en': 'Who was right , who wrong ?', 'vi': 'Ai đã đúng , ai sai ?'},\n"," {'en': 'What would they do under the same conditions ?',\n","  'vi': 'Họ sẽ làm gì nếu bị đặt dưới tình trạng tương tự ?'},\n"," {'en': 'Was the tale told well ?', 'vi': 'Câu chuyện kể có hay không ?'},\n"," {'en': 'Was there a hidden message ?',\n","  'vi': 'Có thông điệp ẩn dấu nào trong đó ?'},\n"," {'en': 'How has the world changed ? How could it be different ?',\n","  'vi': 'Làm thế nào thế giới thay đổi ? Làm thế nào nó có thể khác đi ?'},\n"," {'en': \"A tsunami of questions flew out of the mouths of children who the world didn 't think were interested .\",\n","  'vi': 'Cơn bão các câu hỏi đã được bay tới tấp từ miệng của những đứa trẻ những người mà thế giới từng nghĩ sẽ chẳng quan tâm'},\n"," {'en': 'And they themselves had not known they cared .',\n","  'vi': 'Và chúng không tự biết rằng chúng quan tâm .'},\n"," {'en': 'And as they wrote and debated , rather than seeing the films as artifacts , they began to see themselves .',\n","  'vi': 'Và khi chúng viết và tranh luận , hơn là thấy những bộ phim như là những tạo tác , chúng bắt đầu nhìn thấy bản thân .'},\n"," {'en': 'I have an aunt who is a wonderful storyteller .',\n","  'vi': 'Tôi có một người cô là một người kể chuyện tuyệt vời .'},\n"," {'en': 'In a moment she can invoke images of running barefoot on Table Mountain and playing cops and robbers .',\n","  'vi': 'Trong một lúc cô có thể đánh thức những hình ảnh như chạy chân trần trên núi Bàn và chơi trò cảnh sát và kẻ cướp .'},\n"," {'en': 'Quite recently she told me that in 1948 , two of her sisters and my father traveled on a boat to Israel without my grandparents .',\n","  'vi': 'Khá gần đây cô có bảo tôi rằng vào năm 1948 , hai trong số người chị em của cô và bố tôi đã du lịch trên một chiếc thuyền đến Israel mà không có ông bà tôi .'},\n"," {'en': 'When the sailors mutinied at sea in a demand for humane conditions , it was these teenagers that fed the crew .',\n","  'vi': 'Khi đoàn thuỷ thủ nổi loạn trên biển vì nhu cầu thiết yếu của con người chính là những thiếu niên này đã cho đoàn thuỷ thủ ăn .'},\n"," {'en': 'I was past 40 when my father died .',\n","  'vi': 'Tôi đã hơn 40 khi bố tôi mất .'},\n"," {'en': 'He never mentioned that journey .',\n","  'vi': 'Ông không bao giờ đề cập đến chuyến đi đó .'},\n"," {'en': \"My mother 's mother left Europe in a hurry without her husband , but with her three-year-old daughter and diamonds sewn into the hem of her skirt .\",\n","  'vi': 'Mẹ của mẹ tôi đã rời khỏi châu Âu trong một nạn đói mà không có chồng của bà , nhưng với đứa con gái 3 tuổi và kim cương khâu viền trên váy .'},\n"," {'en': 'After two years in hiding , my grandfather appeared in London .',\n","  'vi': 'Sau 2 năm lẩn trốn , ông tôi xuất hiện ở Luân Đôn .'},\n"," {'en': 'He was never right again .', 'vi': 'Ông đã không bao giờ đúng nữa .'},\n"," {'en': 'And his story was hushed as he assimilated .',\n","  'vi': 'Và câu chuyện của ông đi vào im lặng khi ông bị đồng hoá .'},\n"," {'en': 'My story started in England with a clean slate and the silence of immigrant parents .',\n","  'vi': 'Câu chuyện của tôi bắt đầu ở nước Anh với lý lịch tạm trong sạch và sự im lặng của bố mẹ là người nhập cư .'},\n"," {'en': 'I had \" Anne Frank , \" \" The Great Escape , \" \" Shoah , \" \" Triumph of the Will . \"',\n","  'vi': 'Tôi có \" Anne Frank \" , \" Sự trốn thoát vĩ đại \" , \" Shoah \" , \" Chiến thắng của nhà Will \"'},\n"," {'en': 'It was Leni Riefenstahl in her elegant Nazi propaganda who gave context to what the family had to endure .',\n","  'vi': 'Đó là Leni Riefenstahl trong ngôi chùa Nazi tao nhã tạo ra bối cảnh mà gia đình đó phải chịu đựng .'},\n"," {'en': \"These films held what was too hurtful to say out loud , and they became more useful to me than the whispers of survivors and the occasional glimpse of a tattoo on a maiden aunt 's wrist .\",\n","  'vi': 'Những bộ phim này mang đến nỗi đau quá lớn đến không nói nổi thành lời và chúng trở nên hữu ích cho tôi hơn hàng ngàn lời thì thầm của những người sống sót và cái nhìn thoáng qua không thường xuyên vào hình xăm trên cánh tay người cô'},\n"," {'en': 'Purists may feel that fiction dissipates the quest of real human understanding , that film is too crude to tell a complex and detailed history , or that filmmakers always serve drama over truth .',\n","  'vi': 'Người theo chủ nghĩa thuần tuý có lẽ cảm thấy rằng sự giả tưởng xua tan nhu cầu hiểu thật sự của con người rằng phim quá thô thiển để nói về những câu chuyện phức tạp và chi tiết , hay những nhà làm phim luôn phục vụ sự cường điệu hơn là sự thật .'},\n"," {'en': 'But within the reels lie purpose and meaning .',\n","  'vi': 'Nhưng trong những cuộn phim là mục đích và ý nghĩa'},\n"," {'en': 'As one 12-year-old said after watching \" Wizard of Oz , \" \" Every person should watch this , because unless you do you may not know that you too have a heart . \"',\n","  'vi': 'Như một đứa trẻ 12 tuổi nói sau khi xem \" Phù thuỷ xứ Oz \" \" Mọi người nên xem phim này , bới vì nếu không xem mọi người sẽ có thể không biết mình cũng có trái tim \"'},\n"," {'en': 'We honor reading , why not honor watching with the same passion ?',\n","  'vi': 'Chúng ta xem trọng việc đọc sách , tại sao không xem trọng việc xem phim với niềm đam mê ?'},\n"," {'en': 'Consider \" Citizen Kane \" as valuable as Jane Austen .',\n","  'vi': 'Hãy xem \" Công dân Kane \" có giá trị như Jane Austen .'},\n"," {'en': 'Agree that \" Boyz n the Hood , \" like Tennyson , offers an emotional landscape and a heightened understanding that work together .',\n","  'vi': 'Hãy đồng ý rằng \" Những cậu bé và khu dân cư \" giống như Tennyson , đem lại khung cảnh xúc động và sự thấu hiểu cao độ rằng chúng phối hợp được với nhau .'},\n"," {'en': 'Each a piece of memorable art , each a brick in the wall of who we are .',\n","  'vi': 'mỗi một mảnh của nghệ thuật đáng nhớ , mỗi một viên gạch của bức tường về chúng ta là ai .'},\n"," {'en': \"And it 's okay if we remember Tom Hanks better than astronaut Jim Lovell or have Ben Kingsley 's face superimposed onto that of Gandhi 's .\",\n","  'vi': 'Và được thôi nếu chúng ta nhớ Tom Hanks hơn nhà du hành vũ trụ Jim Lovell hay đặt khuôn mặt của Ben Kíngléy chồng lên mặt của Gandhi'},\n"," {'en': 'And though not real , Eve Harrington , Howard Beale , Mildred Pierce are an opportunity to discover what it is to be human , and no less helpful to understanding our life and times as Shakespeare is in illuminating the world of Elizabethan England .',\n","  'vi': 'Và dù không có thật , Eve Harrington , Howard Beale , Mildred Pierce là cơ hội để khám phá là con người thì như thế nào và không hề bớt hữu ích khi hiểu về cuộc sống và thời gian của chúng ta như Shakespeare rọi sáng thế giới của Elizabeth nước Anh .'},\n"," {'en': 'We guessed that film , whose stories are a meeting place of drama , music , literature and human experience , would engage and inspire the young people participating in FILMCLUB .',\n","  'vi': 'Chúng ta đoán rằng phim , nơi những câu chuyện là nơi hội tụ của kịch tích , âm nhạc , văn học , kinh nghiệm con người , có thể tham gia truyền nguồn cảm hứng cho những đứa trẻ tham gia trong FILMCLUB ,'},\n"," {'en': 'What we could not have foreseen was the measurable improvements in behavior , confidence and academic achievement .',\n","  'vi': 'Cái mà chúng tôi không nhìn thấy trước được là sự phát triển có thể đo đạc được trong hành vi , sự tự tin và kết quả học tập .'},\n"," {'en': \"Once-reluctant students now race to school , talk to their teachers , fight , not on the playground , but to choose next week 's film -- young people who have found self-definition , ambition and an appetite for education and social engagement from the stories they have witnessed .\",\n","  'vi': 'Những học sinh từng miễn cưỡng giờ đây đến trường , nói chuyện với giáo viên của họ , đánh nhau , không phải ở sân chơi , mà là để chọn bộ phim chiếu vào tuần tới -- những đứa trẻ tìm thấy được định nghĩa bản thân , sự tham vọng và muốn học và tham gia vào cộng đồng từ những câu chuyện chúng xem .'},\n"," {'en': 'Our members defy the binary description of how we so often describe our young .',\n","  'vi': 'Thành viên của chúng tôi thách thức sự mô tả nhị phân về cách mà chúng ta thường mô tả những đứa trẻ của chúng ta .'},\n"," {'en': 'They are neither feral nor myopically self-absorbed .',\n","  'vi': 'Chúng không hoang dã hay tập trung quá nhiều vào bản thân .'},\n"," {'en': 'They are , like other young people , negotiating a world with infinite choice , but little culture of how to find meaningful experience .',\n","  'vi': 'Chúng như những đứa trẻ khác , đang thương lượng với thế giới về sự lựa chọn vô cùng , nhưng lại là một văn hoá bé nhỏ về cách để có một trải nghiệm có ý nghĩa'},\n"," {'en': 'We appeared surprised at the behaviors of those who define themselves by the size of the tick on their shoes , yet acquisition has been the narrative we have offered .',\n","  'vi': 'Chúng tôi ngạc nhiên trước những hành vi của những đứa trẻ tự định nghĩa mình bằng cỡ nấc giày , những gì thu nhận được có tính chất tường thuật mà chúng tôi đem lại .'},\n"," {'en': \"If we want different values we have to tell a different story , a story that understands that an individual narrative is an essential component of a person 's identity , that a collective narrative is an essential component of a cultural identity , and without it it is impossible to imagine yourself as part of a group .\",\n","  'vi': 'Nếu chúng ta muốn những giá trị khác chúng ta phải kể một câu chuỵện khác , một câu chuyện hiểu được rằng một dạng tường thuật cá nhân là một thành phần cần thiết của một cá thể con người , và một dạng tường thuật tập thể là cần thành phần thiết cho một bản sắc văn hoá , và không có nó thì thật không thể tưởng tượng được bản thân là một phần của tập thể .'},\n"," {'en': 'Because when these people get home after a screening of \" Rear Window \" and raise their gaze to the building next door , they have the tools to wonder who , apart from them , is out there and what is their story .',\n","  'vi': 'Bởi khi những đứa trẻ này về nhà sau khi xem xong \" Cửa sổ kì lạ \" và đưa ánh nhìn của chúng vào toà nhà bên cạnh , chúng có những công cụ để tự hỏi , ngoài chúng ta có ai ngoài kia và câu chuyện của họ là gì .'},\n"," {'en': 'Thank you .', 'vi': 'Cảm ơn các bạn .'},\n"," {'en': 'Ellen Jorgensen : Biohacking -- you can do it , too',\n","  'vi': 'Ellen Jorgensen : Hack sinh học -- bạn cũng có thể làm được việc đó .'},\n"," {'en': \"We have personal computing , why not personal biotech ? That 's the question biologist Ellen Jorgensen and her colleagues asked themselves before opening Genspace , a nonprofit DIYbio lab in Brooklyn devoted to citizen science , where amateurs can go and tinker with biotechnology . Far from being a sinister Frankenstein 's lab , Genspace offers a long list of fun , creative and practical uses for DIYbio .\",\n","  'vi': 'Chúng ta đã có máy tính cá nhân , tại sao không phải là công nghệ sinh học cá nhân ? Đó là điều mà nhà sinh vật học Ellen Jorgensen và cộng sự của bà tự hỏi khi lập ra Genspace , một phòng thí nghiệm sinh học phi lợi nhuận ở Brooklyn dành cho khoa học cộng đồng , nơi mà những người nghiệp dư có thể đến với công nghệ sinh học . Khác xa so với phòng thí nghiệm xấu xa của Frankenstein , Genspace cung cấp một danh sách dài những lợi ích vui nhộn , sáng tạo và thiết thực của DIYbio .'},\n"," {'en': \"It 's a great time to be a molecular biologist .\",\n","  'vi': 'Thời đại này rất tuyệt để làm một nhà sinh học phân tử .'},\n"," {'en': 'Reading and writing DNA code is getting easier and cheaper .',\n","  'vi': 'Việc đọc và viết trình tự DNA đang trở nên dễ dàng hơn và rẻ hơn .'},\n"," {'en': \"By the end of this year , we 'll be able to sequence the three million bits of information in your genome in less than a day and for less than 1,000 euros .\",\n","  'vi': 'Đến cuối năm nay , chúng ta sẽ có thể giải trình tự của 3 triệu mã thông tin từ bộ gen của mình trong vòng một ngày với giá ít hơn 1 ngàn euro .'},\n"," {'en': 'Biotech is probably the most powerful and the fastest-growing technology sector .',\n","  'vi': 'Công nghệ sinh học có lẽ là ngành công nghệ mạnh nhất và phát triển nhanh nhất .'},\n"," {'en': 'It has the power , potentially , to replace our fossil fuels , to revolutionize medicine , and to touch every aspect of our daily lives .',\n","  'vi': 'Nó có tiềm năng để thay thế nhiên liệu hoá thạch , cách mạng hoá y học , và ảnh hưởng đến mọi khía cạnh của cuộc sống hằng ngày của chúng ta .'},\n"," {'en': 'So who gets to do it ?', 'vi': 'Vậy ai là người sẽ thực hiện nó ?'},\n"," {'en': \"I think we 'd all be pretty comfortable with this guy doing it .\",\n","  'vi': 'Tôi nghĩ tất cả chúng ta đều khá yên tâm khi người này làm việc đó .'},\n"," {'en': 'But what about that guy ?', 'vi': 'Nhưng còn người này thì sao ?'},\n"," {'en': 'In 2009 , I first heard about DIYbio .',\n","  'vi': 'Vào năm 2009 , tôi lần đầu tiên biết đến DIYbio .'},\n"," {'en': \"It 's a movement that -- it advocates making biotechnology accessible to everyone , not just scientists and people in government labs .\",\n","  'vi': 'Đó là một phong trào khuyến khích đưa công nghệ sinh học đến với tất cả mọi người , không chỉ với các nhà khoa học và những người trong phòng thí nghiệm của chính phủ .'},\n"," {'en': 'The idea is that if you open up the science and you allow diverse groups to participate , it could really stimulate innovation .',\n","  'vi': 'Ý tưởng ở đây là nếu chúng ta mở rộng cánh cửa khoa học và cho phép nhiều nhóm người khác nhau tham gia , nó sẽ thúc đẩy sự sáng tạo .'},\n"," {'en': \"Putting technology in the hands of the end user is usually a good idea because they 've got the best idea of what their needs are .\",\n","  'vi': 'Đưa công nghệ vào tay những người sử dụng thường là một ý tưởng tốt vì họ biết rõ nhất về nhu cầu của chính họ .'},\n"," {'en': \"And here 's this really sophisticated technology coming down the road , all these associated social , moral , ethical questions , and we scientists are just lousy at explaining to the public just exactly what it is we 're doing in those labs .\",\n","  'vi': 'Đây là một công nghệ tinh vi đi cùng với nó là những câu hỏi về mặt xã hội , đạo đức và đạo lý , và các nhà khoa học thì rất dở trong việc giải thích với công chúng một cách chính xác họ đang làm gì trong phòng thí nghiệm .'},\n"," {'en': \"So wouldn 't it be nice if there was a place in your local neighborhood where you could go and learn about this stuff , do it hands-on ?\",\n","  'vi': 'Do đó , phải chăng sẽ tốt hơn nếu có một nơi gần nhà mà bạn có thể đến và tìm hiểu về những điều này , và tự tay làm ?'},\n"," {'en': 'I thought so .', 'vi': 'Tôi nghĩ là tốt .'},\n"," {'en': 'So , three years ago , I got together with some friends of mine who had similar aspirations and we founded Genspace .',\n","  'vi': 'Nên 3 năm trước , tôi cùng với vài người bạn cùng chung lý tưởng lập nên Genspace .'},\n"," {'en': \"It 's a nonprofit , a community biotech lab in Brooklyn , New York , and the idea was people could come , they could take classes and putter around in the lab in a very open , friendly atmosphere .\",\n","  'vi': 'Đó là một phòng thí nghiệm công nghệ sinh học cho cộng đồng và phi lợi nhuận , tại Brooklyn , New York , với ý tưởng là mọi người có thể đến , để tham dự những lớp học và \" vọc \" trong phòng thí nghiệm trong một môi trường cởi mở và thân thiện .'},\n"," {'en': 'None of my previous experience prepared me for what came next . Can you guess ?',\n","  'vi': 'Không một kinh nghiệm nào trước đây có thể giúp tôi chuẩn bị cho những gì xảy ra sau đó . Bạn có thể đoán được không ?'},\n"," {'en': 'The press started calling us .',\n","  'vi': 'Báo giới bắt đầu gọi chúng tôi .'},\n"," {'en': 'And the more we talked about how great it was to increase science literacy , the more they wanted to talk about us creating the next Frankenstein , and as a result , for the next six months , when you Googled my name , instead of getting my scientific papers , you got this .',\n","  'vi': 'Và chúng tôi càng nói về lợi ích của việc tăng sự hiểu biết về khoa học , thì họ lại càng muốn nói về việc chúng tôi đang tạo ra một Frankenstein mới , và kết quả là , trong vòng 6 tháng sau đó , khi bạn google tên tôi , thay vì tìm thấy những bài báo khoa học của tôi , bạn tìm được :'},\n"," {'en': '[ \" Am I a biohazard ? \" ] It was pretty depressing .',\n","  'vi': '[ Tôi có phải là hiểm hoạ sinh học ? ] Việc đó thật đáng buồn .'},\n"," {'en': 'The only thing that got us through that period was that we knew that all over the world , there were other people that were trying to do the same thing that we were .',\n","  'vi': 'Điều duy nhất giúp chúng tôi vượt qua giai đoạn đó là chúng tôi biết rằng trên toàn thế giới , có nhiều người cũng đang cố gắng làm cùng việc mà chúng tôi đang làm .'},\n"," {'en': 'They were opening biohacker spaces , and some of them were facing much greater challenges than we did , more regulations , less resources .',\n","  'vi': 'Họ cũng mở những nơi dành cho hacker sinh học , và một số còn phải đối mặt với những thử thách lớn hơn chúng tôi , nhiều quy định hơn và ít tài nguyên hơn .'},\n"," {'en': \"But now , three years later , here 's where we stand .\",\n","  'vi': 'Nhưng giờ đây , ba năm sau , đây là thành quả của chúng tôi .'},\n"," {'en': \"It 's a vibrant , global community of hackerspaces , and this is just the beginning .\",\n","  'vi': 'Một không gian sôi động dành cho cộng đồng hacker sinh học toàn thế giới , và đây chỉ là bước đầu .'},\n"," {'en': 'These are some of the biggest ones , and there are others opening every day .',\n","  'vi': 'Đây là một trong những cộng đồng lớn nhất , và có nhiều nơi khác đang mở cửa hằng ngày .'},\n"," {'en': \"There 's one probably going to open up in Moscow , one in South Korea , and the cool thing is they each have their own individual flavor that grew out of the community they came out of .\",\n","  'vi': 'Có một chỗ có lẽ sắp mở cửa ở Moscow , một ở Hàn Quốc , và điều thú vị là mỗi nơi đều có đặc điểm riêng của mình được phát triển dựa trên cộng đồng của họ .'},\n"," {'en': 'Let me take you on a little tour .',\n","  'vi': 'Hãy để tôi đưa các bạn thăm quan một chút .'},\n"," {'en': 'Biohackers work alone .',\n","  'vi': 'Những hacker sinh học làm việc đơn lẻ .'},\n"," {'en': 'We work in groups , in big cities — — and in small villages .',\n","  'vi': 'Chúng tôi làm việc theo nhóm , trong những thành phố lớn - - và trong những ngôi làng nhỏ .'},\n"," {'en': 'We reverse engineer lab equipment .',\n","  'vi': 'Chúng tôi tự chế dụng cụ phòng thí nghiệm .'},\n"," {'en': 'We genetically engineer bacteria .',\n","  'vi': 'Chúng tôi áp dụng kỹ thuật di truyền trên vi khuẩn .'},\n"," {'en': 'We hack hardware , software , wetware , and , of course , the code of life .',\n","  'vi': 'Chúng tôi hack phần cứng , phần mềm , phần ướt , và dĩ nhiên hack luôn mã sinh học .'},\n"," {'en': 'We like to build things .',\n","  'vi': 'Chúng tôi thích xây dựng mọi thứ .'},\n"," {'en': 'Then we like to take things apart .',\n","  'vi': 'Sau đó chúng tôi lại thích tháo rời mọi thứ ra .'},\n"," {'en': 'We make things grow .',\n","  'vi': 'Chúng tôi làm cho nhiều thứ phát triển .'},\n"," {'en': 'We make things glow .',\n","  'vi': 'Chúng tôi làm cho nhiều thứ phát sáng .'},\n"," {'en': 'And we make cells dance .',\n","  'vi': 'Và chúng tôi còn làm cho tế bào nhảy múa .'},\n"," {'en': \"The spirit of these labs , it 's open , it 's positive , but , you know , sometimes when people think of us , the first thing that comes to mind is bio-safety , bio-security , all the dark side stuff .\",\n","  'vi': 'Tinh thần của những phòng thí nghiệm này là cởi mở và tích cực , nhưng đôi lúc khi người ta nghĩ đến chúng tôi , thì điều đầu tiên họ nghĩ đến là an toàn sinh học , an ninh sinh học và những điều đen tối khác .'},\n"," {'en': \"I 'm not going to minimize those concerns .\",\n","  'vi': 'Tôi sẽ không coi thường những quan ngại này .'},\n"," {'en': 'Any powerful technology is inherently dual use , and , you know , you get something like synthetic biology , nanobiotechnology , it really compels you , you have to look at both the amateur groups but also the professional groups , because they have better infrastructure , they have better facilities , and they have access to pathogens .',\n","  'vi': 'Bất kì kỹ thuật nào cũng như con dao hai lưỡi , và , bạn biết rằng , khi bạn có những thứ như sinh học tổng hợp , công nghệ sinh học nano , bạn buộc phải nhìn vào không chỉ những nhóm nghiệp dư mà cả những nhóm chuyên nghiệp , vì họ có cơ sở hạ tầng tốt hơn , họ có điều kiện thuận lợi hơn , và họ có thể tiếp cận các tác nhân gây bệnh .'},\n"," {'en': 'So the United Nations did just that , and they recently issued a report on this whole area , and what they concluded was the power of this technology for positive was much greater than the risk for negative , and they even looked specifically at the DIYbio community , and they noted , not surprisingly , that the press had a tendency to consistently overestimate our capabilities and underestimate our ethics .',\n","  'vi': 'Vậy Liên Hiệp Quốc đã làm đúng như vậy , và gần đây họ làm một báo cáo trên toàn lĩnh vực này , và điều họ kết luận là sức mạnh tích cực của công nghệ này lớn hơn nhiều những sự mạo hiểm tiêu cực , và họ thậm chí còn đặc biệt xem xét cộng đồng DIYbio , và họ ghi chú rằng , không đáng ngạc nhiên lắm , báo chí có xu hướng đánh giá cao khả năng của chúng ta và đánh giá thấp đạo đức của chúng ta .'},\n"," {'en': 'As a matter of fact , DIY people from all over the world , America , Europe , got together last year , and we hammered out a common code of ethics .',\n","  'vi': 'Sự thật là , thành viên DYI từ khắp thế giới , Mỹ , Châu Âu , tụ tập lại vào năm ngoái , và chúng tôi đặt ra một bộ luật đạo đức chung .'},\n"," {'en': \"That 's a lot more than conventional science has done .\",\n","  'vi': 'Và nó nhiều hơn rất nhiều những gì khoa học thông thường đã làm được .'},\n"," {'en': 'Now , we follow state and local regulations .',\n","  'vi': 'Giờ đây , chúng tôi tuân thủ luật pháp của bang và luật địa phương .'},\n"," {'en': \"We dispose of our waste properly , we follow safety procedures , we don 't work with pathogens .\",\n","  'vi': 'Chúng tôi xử lí rác thải một cách hợp lí , chúng tôi tuân thủ các quy trình an toàn , chúng tôi không làm việc với những tác nhân gây bệnh .'},\n"," {'en': \"You know , if you 're working with a pathogen , you 're not part of the biohacker community , you 're part of the bioterrorist community , I 'm sorry .\",\n","  'vi': 'Bạn thấy đấy , nếu bạn đang làm việc với tác nhân gây bệnh , thì bạn không nằm trong cộng đồng của chúng tôi , bạn nằm trong cộng đồng khủng bố sinh học , tôi xin lỗi .'},\n"," {'en': 'And sometimes people ask me , \" Well , what about an accident ? \"',\n","  'vi': 'Và đôi khi có người hỏi tôi , \" Vậy nếu có tai nạn thì sao ? \"'},\n"," {'en': \"Well , working with the safe organisms that we normally work with , the chance of an accident happening with somebody accidentally creating , like , some sort of superbug , that 's literally about as probable as a snowstorm in the middle of the Sahara Desert .\",\n","  'vi': 'À , làm việc với những sinh vật an toàn như chúng tôi thường tiếp xúc thì khả năng xảy ra tai nạn , ví dụ như người nào đó vô tình tạo ra một loại siêu bọ , khả năng này cũng tương đương như khả năng một trận bão tuyết xảy ra giữa sa mạc Sahara .'},\n"," {'en': \"Now , it could happen , but I 'm not going to plan my life around it .\",\n","  'vi': 'Nó có thể xảy ra , nhưng tôi không có ý định để đời tôi phụ thuộc vào khả năng đó .'},\n"," {'en': \"I 've actually chosen to take a different kind of risk .\",\n","  'vi': 'Thật ra tôi đã chọn một loại mạo hiểm khác .'},\n"," {'en': 'I signed up for something called the Personal Genome Project .',\n","  'vi': 'Tôi đăng kí một chương trình gọi là Dự Án Gen Cá Nhân .'},\n"," {'en': \"It 's a study at Harvard where , at the end of the study , they 're going to take my entire genomic sequence , all of my medical information , and my identity , and they 're going to post it online for everyone to see .\",\n","  'vi': 'Đó là một nghiên cứu ở Havard mà khi kết thúc , họ sẽ lấy toàn bộ trình tự gen của tôi , toàn bộ thông tin y học của tôi , và nhận dạng của tôi , và họ sẽ đăng nó lên mạng cho mọi người thấy .'},\n"," {'en': 'There were a lot of risks involved that they talked about during the informed consent portion .',\n","  'vi': 'Có rất nhiều nguy cơ liên quan mà họ nói đến trong phần thông báo sự chấp thuận .'},\n"," {'en': 'The one I liked the best is , someone could download my sequence , go back to the lab , synthesize some fake Ellen DNA , and plant it at a crime scene .',\n","  'vi': 'Điều mà tôi thích nhất là , ai đó có thể tải trình tự gen của tôi xuống , trở lại phòng thí nghiệm , tổng hợp một số ADN giả và đặt nó tại hiện trường một vụ án .'},\n"," {'en': 'But like DIYbio , the positive outcomes and the potential for good for a study like that far outweighs the risk .',\n","  'vi': 'Nhưng giống như DIYbio , kết quả tích cực và tiềm năng tốt của một nghiên cứu như vậy lớn hơn sự mạo hiểm rất nhiều .'},\n"," {'en': 'Now , you might be asking yourself , \" Well , you know , what would I do in a biolab ? \"',\n","  'vi': 'Bây giờ , có thể bạn đang tự hỏi , \" Bạn biết không , tôi sẽ làm gì trong một phòng thí nghiệm sinh học ? \"'},\n"," {'en': 'Well , it wasn \\'t that long ago we were asking , \" Well , what would anyone do with a personal computer ? \"',\n","  'vi': 'À , không lâu trước đây chúng ta từng tự hỏi , \" Nào , ai sẽ làm được gì với một chiếc máy tính cá nhân chứ ? \" .'},\n"," {'en': 'So this stuff is just beginning .',\n","  'vi': 'Vậy đây chỉ mới là sự bắt đầu .'},\n"," {'en': \"We 're only seeing just the tip of the DNA iceberg .\",\n","  'vi': 'Chúng ta chỉ mới thấy đỉnh của tảng băng DNA .'},\n"," {'en': 'Let me show you what you could do right now .',\n","  'vi': 'Để tôi cho bạn thấy bạn có thể làm gì ngay bây giờ .'},\n"," {'en': 'A biohacker in Germany , a journalist , wanted to know whose dog was leaving little presents on his street ?',\n","  'vi': 'Một nhà biohacker người Đức , một nhà báo , muốn biết chó của ai đã để lại những \" món quà \" nho nhỏ trên đường ?'},\n"," {'en': 'Yep , you guessed it . He threw tennis balls to all the neighborhood dogs , analyzed the saliva , identified the dog , and confronted the dog owner .',\n","  'vi': 'Phải , bạn đã đoán ra . Ông ta quăng quả banh quần vợt vào tất cả các con chó trong khu phố , phân tích nước bọt , xác định con chó , và đối chất với chủ của con chó .'},\n"," {'en': 'I discovered an invasive species in my own backyard .',\n","  'vi': 'Tôi phát hiện ra một loài sinh vật đã xâm lược sân sau nhà tôi .'},\n"," {'en': 'Looked like a ladybug , right ?',\n","  'vi': 'Trông như một con bọ hung nhỉ ?'},\n"," {'en': 'It actually is a Japanese beetle .',\n","  'vi': 'Thật ra nó là một con bọ cánh cứng Nhật Bản .'},\n"," {'en': \"And the same kind of technology -- it 's called DNA barcoding , it 's really cool -- You can use it to check if your caviar is really beluga , if that sushi is really tuna , or if that goat cheese that you paid so much for is really goat 's .\",\n","  'vi': 'Và cũng loại công nghệ đó -- được gọi là mã vạch ADN , nó thật sự tuyệt vời -- Bạn có thể dùng nó để kiểm tra xem trứng cá muối của bạn có thật là từ cá tầm không , xem miếng sushi đó có thật là cá ngừ không , hoặc pho mát dê mà bạn mua rất đắt đó có thật là từ dê không .'},\n"," {'en': 'In a biohacker space , you can analyze your genome for mutations .',\n","  'vi': 'Trong không gian của một nhà biohacker , bạn có thể phân tích gen của bạn để tìm đột biến .'},\n"," {'en': \"You can analyze your breakfast cereal for GMO 's , and you can explore your ancestry .\",\n","  'vi': 'Bạn có thể phân tích ngũ cốc của bạn để tìm thực phẩm biến đổi gen , và bạn có thể khám phá tổ tiên của mình .'},\n"," {'en': \"You can send weather balloons up into the stratosphere , collect microbes , see what 's up there .\",\n","  'vi': 'Bạn có thể thả khí cầu thời tiết lên tầng tĩnh khí , thu thập vi khuẩn , xem điều gì đang xảy ra trên đó .'},\n"," {'en': 'You can make a biocensor out of yeast to detect pollutants in water .',\n","  'vi': 'Bạn có thể làm ra một dụng cụ kiểm duyệt sinh học từ men để phát hiện chất gây ô nhiễm trong nước .'},\n"," {'en': 'You can make some sort of a biofuel cell .',\n","  'vi': 'Bạn có thể làm ra một loại pin nhiên liệu sinh học .'},\n"," {'en': 'You can do a lot of things .',\n","  'vi': 'Bạn có thể làm rất nhiều thứ .'},\n"," {'en': 'You can also do an art science project . Some of these are really spectacular , and they look at social , ecological problems from a completely different perspective .',\n","  'vi': 'Bạn còn có thể thực hiện các dự án khoa học nghệ thuật . Một vài trong số đó thật sự rất ngoạn mục , và chúng nhìn nhận các vấn đề xã hội và sinh thái từ một góc nhìn hoàn toàn khác biệt .'},\n"," {'en': \"It 's really cool .\", 'vi': 'Điều đó thật sự rất tuyệt .'},\n"," {'en': 'Some people ask me , well , why am I involved ?',\n","  'vi': 'Vài người hỏi tôi , à , tại sao tôi lại tham gia vào việc này ?'},\n"," {'en': 'I could have a perfectly good career in mainstream science .',\n","  'vi': 'Tôi có thể có một sự nghiệp hoàn hảo trong các ngành khoa học chính .'},\n"," {'en': \"The thing is , there 's something in these labs that they have to offer society that you can 't find anywhere else .\",\n","  'vi': 'Vấn đề là , có một điều gì đó trong các phòng thí nghiệm này mà bạn không thể tìm thấy ở bất cứ nơi nào khác .'},\n"," {'en': \"There 's something sacred about a space where you can work on a project , and you don 't have to justify to anyone that it 's going to make a lot of money , that it 's going to save mankind , or even that it 's feasible .\",\n","  'vi': 'Có một điều gì đó thiêng liêng về nơi mà bạn có thể thực hiện một dự án , và bạn không phải biện minh với bất kì ai rằng nó sẽ đem về rất nhiều tiền , rằng nó sẽ cứu nhân loại , hoặc thậm chí là nó có thể thực hiện được .'},\n"," {'en': 'It just has to follow safety guidelines .',\n","  'vi': 'Nó chỉ cần tuân thủ những quy tắc an toàn .'},\n"," {'en': \"If you had spaces like this all over the world , it could really change the perception of who 's allowed to do biotech .\",\n","  'vi': 'Nếu bạn có những không gian như thế này trên toàn thế giới , nó sẽ thật sự thay đổi nhận định về việc ai được phép làm công nghệ sinh học .'},\n"," {'en': \"It 's spaces like these that spawned personal computing .\",\n","  'vi': 'Chính những nơi như thế này đã sản sinh ra máy tính cá nhân .'},\n"," {'en': 'Why not personal biotech ?',\n","  'vi': 'Vậy sao không phải là công nghệ sinh học cá nhân ?'},\n"," {'en': 'If everyone in this room got involved , who knows what we could do ?',\n","  'vi': 'Nếu mọi người trong phòng này đều tham gia , ai mà biết được chúng ta có thể làm những gì ?'},\n"," {'en': \"This is such a new area , and as we say back in Brooklyn , you ain 't seen nothin ' yet .\",\n","  'vi': 'Đây là một lĩnh vực rất mới , và như chúng tôi nói ở Brooklyn , bạn còn chưa thấy gì cả đâu . .'},\n"," {'en': \"Geert Chatrou : A whistleblower you haven 't heard\",\n","  'vi': 'Một người huýt gió bạn chưa từng biết đến'},\n"," {'en': 'In this engaging talk , world champion whistler Geert Chatrou performs the whimsical \" Eleonora \" by A. Honhoff , and his own \" Fête de la Belle . \" In a fascinating interlude , he talks about what brought him to the craft . & lt ; em & gt ; & lt ; / em & gt ;',\n","  'vi': 'Tại TEDxRotterdam , nhà quán quân thổi sáo thế giới Geert Chatrou biểu diễn bài \" Eleonora \" của A.Honhoff , và bài \" Fête de la Belle \" do ông tự sáng tác . Trong , ông ấy trò chuyện về cái mà đã thôi thúc ông đến với thổi sáo .'},\n"," {'en': 'Thank you very much .', 'vi': 'Cám ơn rất nhiều'},\n"," {'en': 'That was whistling .', 'vi': 'Đó là huýt sáo'},\n"," {'en': \"I 'm trying to do this in English .\",\n","  'vi': 'Tôi đang cố huyết sáo bằng tiếng Anh'},\n"," {'en': 'What is a chubby , curly-haired guy from Holland -- why is he whistling ?',\n","  'vi': 'Người đàn ông tròn trịa , tóc xoăn đến từ Hà Lan này là ai -- tại sao ông ấy lại huýt sáo ?'},\n"," {'en': \"Well actually , I 've [ been ] whistling since the age of four , about four .\",\n","  'vi': 'Thực ra , tôi huýt gió kể từ khi tôi bốn tuổi -- khoảng tầm bốn tuổi'},\n"," {'en': \"My dad was always whistling around the house , and I just thought that 's part of communication in my family .\",\n","  'vi': 'Bố tôi từng lúc nào cũng huýt gió khắp nơi trong nhà and tôi cứ ngỡ đó là một phần trong cách giao tiếp của gia đình tôi .'},\n"," {'en': 'So I whistled along with him .',\n","  'vi': 'Vì vậy tôi huýt gió cùng với ông ấy .'},\n"," {'en': 'And actually , till I was 34 , I always annoyed and irritated people with whistling , because , to be honest , my whistling is a kind of deviant behavior .',\n","  'vi': 'Và thậm chí cho đến khi tôi 34 tuổi , lúc nào tôi cũng quấy rầy và khiến mọi người khó chịu với việc huýt sáo của mình . Bởi vì , thành thật mà nói , huýt gió có thể coi là một tật xấu của tôi .'},\n"," {'en': 'I whistled alone . I whistled in the classroom .',\n","  'vi': 'Tôi huýt gió một mình , tôi huýt gió trong lớp học ,'},\n"," {'en': 'I whistled on [ my ] bike . I whistled everywhere .',\n","  'vi': 'tôi huýt gió lúc đang đi xe đạp , tôi huýt gió ở mọi nơi .'},\n"," {'en': 'And I also whistled at a Christmas Eve party with my family-in-law .',\n","  'vi': 'Và tôi huýt gió ở một buổi tiệc đón giáng sinh nữa với gia đình thông gia của tôi .'},\n"," {'en': 'And they had some , in my opinion , terrible Christmas music .',\n","  'vi': 'Và tôi nghĩ , họ có những bài nhạc giáng sinh thật tệ .'},\n"," {'en': \"And when I hear music that I don 't like , I try to make it better .\",\n","  'vi': 'Và một khi tôi nghe nhạc mà tôi không thích , tôi cố để làm cho nó hay hơn .'},\n"," {'en': 'So \" Rudolph the Red-Nosed Reindeer \" -- you know it ?',\n","  'vi': 'Bài \" Con tuần lộc mũi đỏ Rudolph \" -- bạn biết bài đó chứ ?'},\n"," {'en': 'But it can also sound like this .',\n","  'vi': 'Nhưng nó còn có thể biến tấu như thế này .'},\n"," {'en': \"But during a Christmas party -- at dinner actually -- it 's very annoying .\",\n","  'vi': 'Nhưng trong một buổi tiệc giáng sinh kia -- thật ra là một bữa tối -- bữa ấy làm tôi rất khó chịu .'},\n"," {'en': 'So my sister-in-law asked me a few times , \" Please stop whistling . \"',\n","  'vi': 'Chị dâu tôi nhắc tôi một vài lần , \" Làm ơn đừng huýt gió nữa . \"'},\n"," {'en': \"And I just couldn 't .\", 'vi': 'Nhưng tôi cứ không thể dừng được .'},\n"," {'en': 'And at one point -- and I had some wine , I have to admit that -- at one point I said , \" If there was a contest , I would join . \"',\n","  'vi': 'Và tại một thời điểm -- và lúc đó tôi đã uống một ít rượu , tôi phải thừa điều đó -- tại thời điểm đó tôi nói , \" Nếu có một cuộc thi , em sẽ tham gia . \"'},\n"," {'en': 'And two weeks later I received a text message : \" You \\'re going to America . \"',\n","  'vi': 'và hai tuần sau Tôi nhận được một tin nhắn : \" Em sẽ đi Mỹ đó . \"'},\n"," {'en': \"So , okay , I 'm going to America .\",\n","  'vi': 'Đựoc thôi , tôi chuẩn bị được đi Mỹ .'},\n"," {'en': 'I would love to , but why ?',\n","  'vi': 'Tôi rất thích , nhưng tại sao ?'},\n"," {'en': 'So I immediately called her up , of course .',\n","  'vi': 'Vì vậy tất nhiên tôi gọi chị ấy ngay lập tức .'},\n"," {'en': 'She Googled , and she found this World Whistling Championship in America , of course .',\n","  'vi': 'chị ấy tìm trên google , và chị ấy tìm thấy cuộc thi huýt sáo thế giới ở Mỹ , tất nhiên .'},\n"," {'en': \"She didn 't expect me to go there .\",\n","  'vi': 'Chị ấy khồng nghĩ tôi sẽ đi .'},\n"," {'en': 'And I would have lost my face .', 'vi': 'Và tôi sẽ mất mặt lắm .'},\n"," {'en': \"I don 't know if that 's correct English .\",\n","  'vi': 'Tôi không biết câu đó có đúng ngữ pháp tiếng Anh không .'},\n"," {'en': 'But the Dutch people here will understand what I mean .',\n","  'vi': 'Nhưng những người nói tiếng Hà Lan ở đây sẽ hiểu ý tôi muốn nói gì .'},\n"," {'en': 'I lost my face .', 'vi': 'Tôi đã rất mất mặt'},\n"," {'en': 'And she thought , \" He will never go there . \"',\n","  'vi': 'Và cô ấy nghĩ , \" Anh ta chắc sẽ khồng bao giờ đi đâu .'},\n"," {'en': 'But actually I did .', 'vi': 'Nhưng thật ra tôi đã đi .'},\n"," {'en': 'So I went to Louisburg , North Carolina , southeast United States , and I entered the world of whistling .',\n","  'vi': 'Tôi đến Louisburg ở miền bắc Carolina , phí đông nam nước Mỹ. và tôi bước vào thế giới huýt sáo'},\n"," {'en': 'And I also entered the world championship , and I won there in 2004 .',\n","  'vi': 'và tôi cũng tham gia cuộc thi huýt gió thế giới và tôi đã chiến thằng ở đó năm 2004 .'},\n"," {'en': 'That was great fun , of course .',\n","  'vi': 'Điều đó -- Điều đó thật tuyệt , tất nhiên .'},\n"," {'en': \"And to defend my title -- like judokas do and sportsmen -- I thought , well let 's go back in 2005 , and I won again .\",\n","  'vi': 'Và để bảo về danh hiệu của mình -- như judokas do và những vận động viên thể thao -- Tôi nghĩ , năm 2005 hãy quay trở lại đó xem sao , và tôi tiếp tục giành giải quán quân .'},\n"," {'en': \"Then I couldn 't participate for a few years .\",\n","  'vi': 'Sau đó tôi không thể tham dự cuộc thi trong vòng vài năm .'},\n"," {'en': 'And in 2008 I entered again in Japan , Tokyo , and I won again .',\n","  'vi': 'Và năm 2008 tôi tham gia một lần nữa ở Nhật , thành phố Tokyo , và tôi lại giành giải quán quân .'},\n"," {'en': \"So what happened now is I 'm standing here in Rotterdam , in the beautiful city , on a big stage , and I 'm talking about whistling .\",\n","  'vi': 'Và chuyện mới xảy ra ở đây là tôi đứng ở đây , ở Rotterdam , ở một thành phố xinh đẹp , đứng trên một sân khấu lớn , và nói về chuyện huýt gió .'},\n"," {'en': 'And actually I earn my money whistling at the moment .',\n","  'vi': 'Và trên thực tế tôi kiếm tiền từ huýt gió , tại thời điểm này .'},\n"," {'en': 'So I quit my day job as a nurse .',\n","  'vi': 'Vì vậy tôi bỏ việc làm của tôi là làm y tá .'},\n"," {'en': 'And I try to live my dream -- well , actually , it was never my dream , but it sounds so good .',\n","  'vi': 'Và tôi cố sống giấc mơ của tôi -- nhưng thực ra , đó chưa bao giờ là giấc mơ của tôi , nhưng điều đó nghe thật tuyệt .'},\n"," {'en': \"Okay , I 'm not the only one whistling here .\",\n","  'vi': 'Okay , tôi không phải là người huýt gió duy nhất ở đây .'},\n"," {'en': 'You say , \" Huh , what do you mean ? \"',\n","  'vi': 'bạn nghĩ , \" Hả , ý bạn là gì ? \"'},\n"," {'en': 'Well actually , you are going to whistle along .',\n","  'vi': 'Thật ra , bạn sẽ huýt gió cùng tôi'},\n"," {'en': 'And then always the same thing happens : people are watching each other and think , \" Oh , my God .',\n","  'vi': 'Và sau đó như thường lệ : mọi người nhìn nhau và nghĩ , \" Trời đất ơi \"'},\n"," {'en': 'Why ? Can I go away ? \"',\n","  'vi': 'Tại sao ? Tôi có thể đi về được không ? \"'},\n"," {'en': \"No , you can 't .\", 'vi': 'Không , bạn không thể'},\n"," {'en': \"Actually it 's very simple .\",\n","  'vi': 'Thật ra huýt gió rất đơn giản .'},\n"," {'en': 'The track that I will whistle is called \" Fête de la Belle . \"',\n","  'vi': 'Bản nhạt mà tôi sẽ huýt theo được gọi là \" Fête de la Belle . \"'},\n"," {'en': \"It 's about 80 minutes long .\",\n","  'vi': 'Bản nhạc này dài khoàng 80 phút .'},\n"," {'en': \"No , no , no . It 's four minutes long .\",\n","  'vi': 'Không không không . Nó chỉ dài bốn phút thôi .'},\n"," {'en': 'And I want to first rehearse with you your whistling .',\n","  'vi': 'Và tôi muốn luyện tập cho bạn cách huýt gió trước .'},\n"," {'en': 'So I whistle the tone .',\n","  'vi': 'Vậy thì tôi sẽ huýt tông của bài nhạc nhé .'},\n"," {'en': 'Sorry . I forgot one thing .',\n","  'vi': 'Xin lỗi . Tôi quên mất một điều .'},\n"," {'en': 'You whistle the same tone as me .',\n","  'vi': 'Bạn huýt với cái tông giống tôi .'},\n"," {'en': 'I heard a wide variety of tones .',\n","  'vi': 'Tôi đã từng nhiều giọng khác nhau ,'},\n"," {'en': 'This is very promising .',\n","  'vi': 'Đây thật sự là một điều rất hứa hẹn .'},\n"," {'en': 'This is very promising .',\n","  'vi': 'Đây thật sự là một điều rất hứa hẹn ,'},\n"," {'en': \"I 'll ask the technicians to start the music .\",\n","  'vi': 'Tôi sẽ hỏi những người ở phía sau cánh gà mở nhạc lên .'},\n"," {'en': \"And if it 's started , I just point where you whistle along , and we will see what happens .\",\n","  'vi': 'Và nếu nhạc bắt đầu , tôi sẽ chỉ chỗ nào để bạn huýt gió theo. và chúng ta sẽ thấy điều gì sẽ xảy ra ,'},\n"," {'en': 'Oh , hah .', 'vi': 'Oh , hah .'},\n"," {'en': \"I 'm so sorry , technicians .\",\n","  'vi': 'Tôi thật sự xin lỗi các bạn kĩ sự ở sau cánh gà .'},\n"," {'en': \"I 'm so used to that .\", 'vi': 'Tôi đã quen với việc đó rồi .'},\n"," {'en': 'I start it myself .', 'vi': 'Tôi sẽ tự bắt đầu'},\n"," {'en': 'Okay , here it is .', 'vi': 'Được rồi , chuẩn bị .'},\n"," {'en': 'Okay .', 'vi': 'Được rồi .'},\n"," {'en': \"It 's easy , isn 't it ?\", 'vi': 'Rất dễ phải không ?'},\n"," {'en': 'Now comes the solo . I propose I do that myself .',\n","  'vi': 'Phần sô lô chuẩn bị đến . Tôi nghĩ tôi nên làm phần đó .'},\n"," {'en': 'Max Westerman : Geert Chatrou , the World Champion [ of ] Whistling .',\n","  'vi': 'Max Westerman : Geert Chartrou , nhà vô địch thổi sáo thế giới .'},\n"," {'en': 'Geert Chatrou : Thank you . Thank you .',\n","  'vi': 'Geert Chatrou : Cám ơn . Cám ơn .'},\n"," {'en': \"Roberto D 'Angelo + Francesca Fedeli : In our baby 's illness , a life lesson\",\n","  'vi': \"Roberto D 'Angelo + Francesca Fedeli : Bài học cuộc đời từ căn bệnh của con trai tôi .\"},\n"," {'en': 'Roberto D \\'Angelo and Francesca Fedeli thought their baby boy Mario was healthy -- until at 10 days old , they discovered he \\'d had a perinatal stroke . With Mario unable to control the left side of his body , they grappled with tough questions : Would he be \" normal ? \" Could he live a full life ? The poignant story of parents facing their fears -- and how they turned them around .',\n","  'vi': 'Roberto D \\'Angelo và Francesca Fedeli từng nghĩ con trai Mario của họ khoẻ mạnh -- cho đến khi bé được 10 ngày tuổi , họ phát hiện bé bị đột quỵ sơ sinh . Với Mario không thể điều khiển phần cơ thể bên trái , họ vật lộn với những băn khoăn : Bé có \" bình thường \" trở lại ? Bé có sống trọn vẹn một đời không ? Một câu chuyện thấm thía về việc cha mẹ đối diện với sự sợ hãi -- và cách họ xoay chuyển chúng .'},\n"," {'en': 'Francesca Fedeli : Ciao .', 'vi': 'Francesca Fedeli : Xin chào .'},\n"," {'en': \"So he 's Mario . He 's our son .\",\n","  'vi': 'Đây là Mario . Con trai chúng tôi .'},\n"," {'en': 'He was born two and a half years ago , and I had a pretty tough pregnancy because I had to stay still in a bed for , like , eight months .',\n","  'vi': 'Bé mới được 2 tuổi rưỡi , tôi đã có khoảng thời gian mang bầu thật khó khăn vì phải nằm trên giường gần 8 tháng .'},\n"," {'en': 'But in the end everything seemed to be under control .',\n","  'vi': 'Nhưng cuối cùng thì mọi việc dường như đã ổn .'},\n"," {'en': 'So he got the right weight at birth .',\n","  'vi': 'Nên bé sinh ra được đủ cân nặng .'},\n"," {'en': 'He got the right Apgar index .', 'vi': 'Bé có chỉ số Apgar tốt .'},\n"," {'en': 'So we were pretty reassured by this .',\n","  'vi': 'Nên chúng tôi khá an tâm .'},\n"," {'en': 'But at the end , 10 days later after he was born , we discovered that he had a stroke .',\n","  'vi': 'Nhưng cuối cùng , 10 ngày sau khi sinh , chúng tôi phát hiện bé bị đột quỵ .'},\n"," {'en': 'As you might know , a stroke is a brain injury .',\n","  'vi': 'Như bạn biết đấy , đột quỵ là một sự tổn thương não .'},\n"," {'en': 'A perinatal stroke could be something that can happen during the nine months of pregnancy or just suddenly after the birth , and in his case , as you can see , the right part of his brain has gone .',\n","  'vi': 'Đột quỵ sơ sinh là một chuyện có thể xảy ra trong 9 tháng mang thai hoặc bất ngờ ngay sau khi sinh , trong trường hợp của bé , như bạn thấy , phần não phải của bé đã không còn .'},\n"," {'en': \"So the effect that this stroke could have on Mario 's body could be the fact that he couldn 't be able to control the left side of his body .\",\n","  'vi': 'Hậu quả của cú đột quỵ đối với cơ thể của Mario có thể tệ đến mức Mario sẽ không còn có thể sử dụng được phần cơ thể bên trái nữa .'},\n"," {'en': \"Just imagine , if you have a computer and a printer and you want to transmit , to input to print out a document , but the printer doesn 't have the right drives , so the same is for Mario .\",\n","  'vi': 'Hãy tưởng tượng , nếu bạn có một máy tính và một máy in và bạn muốn gửi , muốn in ra một tài liệu , nhưng máy in không có những ổ đĩa phù hợp , Mario cũng vậy .'},\n"," {'en': \"It 's just like , he would like to move his left side of his body , but he 's not able to transmit the right input to move his left arm and left leg .\",\n","  'vi': 'Giống như , bé muốn di chuyển phần cơ thể bên trái nhưng không thể chuyển giao tín hiệu để chuyển động tay và chân trái .'},\n"," {'en': 'So life had to change .',\n","  'vi': 'Vậy là cuộc sống đã phải thay đổi .'},\n"," {'en': 'We needed to change our schedule .',\n","  'vi': 'Chúng tôi phải thay đổi kế hoạch của mình .'},\n"," {'en': 'We needed to change the impact that this birth had on our life .',\n","  'vi': 'Chúng tôi phải thay đổi những ảnh hưởng của việc sinh nở này với đời mình .'},\n"," {'en': 'As you may imagine , unfortunately , we were not ready .',\n","  'vi': 'Như bạn tưởng tượng , không may là chúng tôi chưa sẵn sàng .'},\n"," {'en': 'Nobody taught us how to deal with such kinds of disabilities , and as many questions as possible started to come to our minds .',\n","  'vi': 'Không ai dạy chúng tôi xử lý những khuyết tật như vậy thế nào , và ngày càng có nhiều băn khoăn bắt đầu chiếm lấy tâm trí chúng tôi .'},\n"," {'en': 'And that has been really a tough time .',\n","  'vi': 'Đó thực sự là quãng thời gian khó khăn .'},\n"," {'en': 'Questions , some basics , like , you know , why did this happen to us ?',\n","  'vi': 'Những băn khoăn , những điều cơ bản như , bạn biết đấy , tại sao chuyện này xảy đến với chúng tôi ?'},\n"," {'en': 'And what went wrong ?', 'vi': 'Vấn đề ở chỗ nào ?'},\n"," {'en': \"Some more tough , like , really , what will be the impact on Mario 's life ?\",\n","  'vi': 'Một số băn khoăn nặng nề hơn , như là cuộc sống của Mario sẽ bị ảnh hưởng thế nào ?'},\n"," {'en': 'I mean , at the end , will he be able to work ?',\n","  'vi': 'Ý tôi là , rồi bé sẽ có thể làm việc không ?'},\n"," {'en': 'Will he be able to be normal ?',\n","  'vi': 'Bé sẽ có thể bình thường trở lại ?'},\n"," {'en': 'And , you know , as a parent , especially for the first time , why is he not going to be better than us ?',\n","  'vi': 'Và , như bạn biết , là cha mẹ , nhất là lần đầu tiên , tại sao bé sẽ không trở nên tốt hơn so với chúng tôi ?'},\n"," {'en': 'And this , indeed , really is tough to say , but a few months later , we realized that we were really feeling like a failure .',\n","  'vi': 'Và điều này , thật ra là , thực sự rất khó nói ra , nhưng vài tháng sau , chúng tôi nhận ra chúng tôi thực sự cảm thấy như mình thất bại .'},\n"," {'en': 'I mean , the only real product of our life , at the end , was a failure .',\n","  'vi': 'Ý tôi là thành quả thực tế duy nhất của đời mình , cuối cùng , lại là một thất bại .'},\n"," {'en': 'And you know , it was not a failure for ourselves in itself , but it was a failure that will impact his full life .',\n","  'vi': 'Và bạn biết đó , nó không phải là thất bại với chính bản thân chúng tôi mà là thất bại sẽ ảnh hưởng đến suốt đời Mario .'},\n"," {'en': 'Honestly , we went down .',\n","  'vi': 'Thành thật mà nói , chúng tôi thất vọng .'},\n"," {'en': 'I mean we went really down , but at the end , we started to look at him , and we said , we have to react .',\n","  'vi': 'Ý tôi là thực sự thất vọng , nhưng cuối cùng , chúng tôi nhìn lại bé , và cùng nói , chúng ta phải hành động .'},\n"," {'en': 'So immediately , as Francesca said , we changed our life .',\n","  'vi': 'Ngay lập tức , như Francesca đã nói , chúng tôi thay đổi đời mình .'},\n"," {'en': 'We started physiotherapy , we started the rehabilitation , and one of the paths that we were following in terms of rehabilitation is the mirror neurons pilot .',\n","  'vi': 'Chúng tôi bắt đầu liệu pháp phục hồi chức năng và vật lí trị liệu. và một trong những hướng mà chúng tôi đang theo đuổi trong vật lí trị liệu là hướng dẫn neuron đối chiếu .'},\n"," {'en': 'Basically , we spent months doing this with Mario .',\n","  'vi': 'Về cơ bản , chúng tôi làm việc này cùng Mario trong nhiều tháng .'},\n"," {'en': 'You have an object , and we showed him how to grab the object .',\n","  'vi': 'Bạn có một đồ vật , chúng tôi chỉ cách cho bé làm thế nào để nắm lấy các đồ vật đó .'},\n"," {'en': 'Now , the theory of mirror neurons simply says that in your brains , exactly now , as you watch me doing this , you are activating exactly the same neurons as if you do the actions .',\n","  'vi': 'Vâng , lý thuyết neuron đối chiếu nói một cách đơn giản rằng trong não bạn , chính xác như bây giờ , khi bạn thấy tôi làm thế này , bạn kích hoạt đúng những neuron như tôi giống như chính bạn đang làm vậy .'},\n"," {'en': 'It looks like this is the leading edge in terms of rehabilitation .',\n","  'vi': 'Có vẻ như đây là một sự đột phá trong vật lí trị liệu .'},\n"," {'en': 'But one day we found that Mario was not looking at our hand .',\n","  'vi': 'Nhưng một hôm , chúng tôi phát hiện ra Mario không nhìn vào tay chúng tôi .'},\n"," {'en': 'He was looking at us .', 'vi': 'Bé nhìn vào chúng tôi .'},\n"," {'en': 'We were his mirror .', 'vi': 'Chúng tôi là tấm gương của bé .'},\n"," {'en': 'And the problem , as you might feel , is that we were down , we were depressed , we were looking at him as a problem , not as a son , not from a positive perspective .',\n","  'vi': 'Và vấn đề , như có thể bạn thấy , rằng chúng tôi thất vọng , chúng tôi suy sụp , chúng tôi đã coi bé như một vấn đề chứ không phải là một bé trai , không từ một nhận thức tích cực .'},\n"," {'en': 'And that day really changed our perspective .',\n","  'vi': 'Ngày hôm đó thực sự thay đổi nhận thức của chúng tôi .'},\n"," {'en': 'We realized that we had to become a better mirror for Mario .',\n","  'vi': 'Chúng tôi nhận ra mình phải trở thành một tấm gương tốt hơn cho Mario .'},\n"," {'en': 'We restarted from our strengths , and at the same time we restarted from his strengths .',\n","  'vi': 'Chúng tôi bắt đầu lại từ nghị lực , đồng thời , bắt đầu lại từ khả năng của bé .'},\n"," {'en': 'We stopped looking at him as a problem , and we started to look at him as an opportunity to improve .',\n","  'vi': 'Chúng tôi không còn coi bé là một vấn đề nữa , và chúng tôi bắt đầu coi bé như một cơ hội để trở nên tốt hơn .'},\n"," {'en': 'And really , this was the change , and from our side , we said , \" What are our strengths that we really can bring to Mario ? \"',\n","  'vi': 'Và thực sự , điều này đã thay đổi , từ phía chúng tôi , chúng tôi nói , \" Chúng ta có khả năng gì để trao cho Mario ? \"'},\n"," {'en': 'And we started from our passions .',\n","  'vi': 'Và chúng tôi bắt đầu từ mong muốn của mình .'},\n"," {'en': 'I mean , at the end , my wife and myself are quite different , but we have many things in common .',\n","  'vi': 'Ý tôi là , cuối cùng , vợ tôi và tôi cũng khá khác nhau , nhưng chúng tôi có nhiều điểm chung .'},\n"," {'en': 'We love to travel , we love music , we love to be in places like this , and we started to bring Mario with us just to show to him the best things that we can show to him .',\n","  'vi': 'Chúng tôi thích du lịch , yêu âm nhạc , thích ở những nơi thế này , và bắt đầu đưa Mario đi cùng chỉ để cho cháu thấy những gì tốt nhất chúng tôi có thể chỉ cho cháu .'},\n"," {'en': 'This short video is from last week .',\n","  'vi': 'Video này được quay từ tuần trước .'},\n"," {'en': \"I am not saying -- — I am not saying it 's a miracle . That 's not the message , because we are just at the beginning of the path .\",\n","  'vi': 'Tôi không nói rằng -- -- Tôi không nói đó là phép màu . Đó không phải là thông điệp , vì chúng tôi mới chỉ bắt đầu chặng đường .'},\n"," {'en': 'But we want to share what was the key learning , the key learning that Mario drove to us , and it is to consider what you have as a gift and not only what you miss , and to consider what you miss just as an opportunity .',\n","  'vi': 'Nhưng chúng tôi muốn chia sẻ nhận thức cốt yếu , nhận thức cốt yếu mà Mario đã đưa chúng tôi tới , rằng hãy coi những gì bạn có một như món quà chứ không phải là những gì bạn đã bỏ lỡ , và coi những gì bạn đã bỏ lỡ chỉ như một cơ hội .'},\n"," {'en': 'And this is the message that we want to share with you .',\n","  'vi': 'Và đây là thông điệp mà chúng tôi muốn chia sẻ với các bạn .'},\n"," {'en': 'This is why we are here .',\n","  'vi': 'Đây là lí do tại sao chúng tôi tới đây .'},\n"," {'en': 'Mario !', 'vi': 'Mario !'},\n"," {'en': 'And this is why -- — And this is why we decided to share the best mirror in the world with him .',\n","  'vi': 'Và đây là lí do -- -- Và đây là lí do chúng tôi quyết định chia sẻ tấm gương tốt nhất trên đời với bé .'},\n"," {'en': 'And we thank you so much , all of you .',\n","  'vi': 'Cảm ơn các bạn rất nhiều , tất cả các bạn .'},\n"," {'en': 'Thank you . Thank you . Bye .',\n","  'vi': 'Xin cảm ơn . Cảm ơn . Tạm biệt .'},\n"," {'en': 'Thank you .', 'vi': 'Cảm ơn .'},\n"," {'en': 'Mark Shaw : One very dry demo',\n","  'vi': 'Mark Shaw : Bài biểu diễn rất khô'},\n"," {'en': 'Mark Shaw demos Ultra-Ever Dry , a liquid-repellent coating that acts as an astonishingly powerful shield against water and water-based materials . At the nano level , the spray covers a surface with an umbrella of air so that water bounces right off . Watch for an exciting two-minute kicker .',\n","  'vi': 'Mark Shaw giới thiệu chất Cực Khô , một dạng chất lỏng phủ bề ngoài có thể chống thấm nước và những chất có chứa nước . Ở mức độ phân từ nano , chất này bao phủ bề mặt vật liệu bởi lớp không khí bảo vệ , vì vậy nước không thấm được . Bạn hãy xem một màn biểu diễn tuyệt vời trong vòng hai phút nhé .'},\n"," {'en': \"I 'm here to show you how something you can 't see can be so much fun to look at .\",\n","  'vi': 'Hôm nay tôi đến đây để chỉ cho các bạn Những thứ bạn không thể thấy được nhưng rất thú vị khi nhìn vào đó'},\n"," {'en': \"You 're about to experience a new , available and exciting technology that 's going to make us rethink how we waterproof our lives .\",\n","  'vi': 'Các bạn sắp sửa thử một loại kĩ thuật mới và rất thú vị , làm cho chúng ta suy nghĩ lại chúng ta chống thấm nước như thế nào'},\n"," {'en': \"What I have here is a cinder block that we 've coated half with a nanotechnology spray that can be applied to almost any material .\",\n","  'vi': 'Tôi có một khối đá xỉ ở đây một nửa đã được phủ lớp xịt vi phân tử - kĩ thuật nano có thể áp dụng cho hầu hết các loại vật liệu .'},\n"," {'en': \"It 's called Ultra-Ever Dry , and when you apply it to any material , it turns into a superhydrophobic shield .\",\n","  'vi': 'Đó gọi là chất Cực Khô và khi bạn bôi vào vật liệu nó sẽ hình thành lớp màng chống thấm nước'},\n"," {'en': \"So this is a cinder block , uncoated , and you can see that it 's porous , it absorbs water .\",\n","  'vi': 'Đây là khối đá xỉ , trơn và bạn thấy nó rỗng , có thể hút nước .'},\n"," {'en': 'Not anymore .', 'vi': 'Đây thì không .'},\n"," {'en': 'Porous , nonporous .', 'vi': 'Rỗng , không rỗng .'},\n"," {'en': \"So what 's superhydrophobic ?\",\n","  'vi': 'Vậy tính chống thấm nước là như thế nào ?'},\n"," {'en': 'Superhydrophobic is how we measure a drop of water on a surface .',\n","  'vi': 'Đô chống thấm là khả năng đo một giọt nước trên bề mặt .'},\n"," {'en': \"The rounder it is , the more hydrophobic it is , and if it 's really round , it 's superhydrophobic .\",\n","  'vi': 'Giọt nước càng tròn , độ chống thấm càng cao , và nếu như rất tròn , nó chống thấm cực tốt .'},\n"," {'en': 'A freshly waxed car , the water molecules slump to about 90 degrees .',\n","  'vi': 'Một xe vừa bôi sáp , những phân tử nước sụt xuống gần ̣ 90 độ .'},\n"," {'en': 'A windshield coating is going to give you about 110 degrees .',\n","  'vi': 'Một lớp kinh chắn gió cho ta khoảng 110 độ .'},\n"," {'en': \"But what you 're seeing here is 160 to 175 degrees , and anything over 150 is superhydrophobic .\",\n","  'vi': 'Chúng ta đang nhìn thấy đây là 160 - 175 độ , và từ 150 độ trở đi là chống thấm cực tốt rồi .'},\n"," {'en': \"So as part of the demonstration , what I have is a pair of gloves , and we 've coated one of the gloves with the nanotechnology coating , and let 's see if you can tell which one , and I 'll give you a hint .\",\n","  'vi': 'Một phần của buổi thuyết trình , tôi có một đôi găng tay và chỉ phủ một chiếc với lớp chống thấm vi phân tử hãy xem xem chiếc găng nào nhé , tôi sẽ gợi ý'},\n"," {'en': 'Did you guess the one that was dry ?',\n","  'vi': 'Bạn đoán ra chiếc nào khô rồi chứ ?'},\n"," {'en': \"When you have nanotechnology and nanoscience , what 's occurred is that we 're able to now look at atoms and molecules and actually control them for great benefits .\",\n","  'vi': 'Khi chúng ta có kĩ thuật vi phân tử và khoa học vi phân tử chúng ta có thể nhìn thấy nguyên tử và phân tử và có thể điều khiển chúng để đem lại nhiều lợi ích'},\n"," {'en': \"And we 're talking really small here .\",\n","  'vi': 'Chúng ta nói đến \" rất nhỏ \" ở đây'},\n"," {'en': \"The way you measure nanotechnology is in nanometers , and one nanometer is a billionth of a meter , and to put some scale to that , if you had a nanoparticle that was one nanometer thick , and you put it side by side , and you had 50,000 of them , you 'd be the width of a human hair .\",\n","  'vi': 'Khoa học vi phân tử có kích thước nanomét một nano mét bằng một phần tỉ mét , để đo chúng , nếu bạn có một phân tử nano , kích thước một nano mét , nếu đặt 50,000 hạt với nhau , sẽ bằng bề dày của sợi tóc .'},\n"," {'en': 'So very small , but very useful .',\n","  'vi': 'Vậy thì rất nhỏ , nhưng rất hữu dụng .'},\n"," {'en': \"And it 's not just water that this works with .\",\n","  'vi': 'Không chỉ có nước'},\n"," {'en': \"It 's a lot of water-based materials like concrete , water-based paint , mud , and also some refined oils as well .\",\n","  'vi': 'còn rất nhiều chất có nước như bê tông , sơn có chứa nước , bùn , và một số loại dầu tinh chế nữa .'},\n"," {'en': 'You can see the difference .',\n","  'vi': 'Bạn có thể thấy sự khác biệt .'},\n"," {'en': \"Moving onto the next demonstration , we 've taken a pane of glass and we 've coated the outside of it , we 've framed it with the nanotechnology coating , and we 're going to pour this green-tinted water inside the middle , and you 're going to see , it 's going to spread out on glass like you 'd normally think it would , except when it hits the coating , it stops , and I can 't even coax it to leave .\",\n","  'vi': 'Phần kế tiếp , chúng ta có tấm kính ô vuông này , và đã được phủ lớp chống thấm ở rìa bao phủ lớp chống thấm vi phân tử , và ta sẽ nhỏ thứ nước nhuộm xanh này vào chính giữa , bạn sẽ thấy , nó sẽ tràn ra ngoài tấm kính như bạn thường thấy , ngoại trừ phần đã được phủ và tôi không thể làm cho nó tràn ra .'},\n"," {'en': \"It 's that afraid of the water .\", 'vi': 'Đó là tính sợ nước .'},\n"," {'en': \"So what 's going on here ? What 's happening ?\",\n","  'vi': 'Vậy thì chuyện gì đã xảy ra vậy ?'},\n"," {'en': 'Well , the surface of the spray coating is actually filled with nanoparticles that form a very rough and craggly surface .',\n","  'vi': 'Bề mặt của lớp phủ chứa những phân tử nano hình thành lớp bề mặt rất thô .'},\n"," {'en': \"You 'd think it 'd be smooth , but it 's actually not .\",\n","  'vi': 'Bạn có thể nghĩ là nó trơn , nhưng không phải vậy .'},\n"," {'en': 'And it has billions of interstitial spaces , and those spaces , along with the nanoparticles , reach up and grab the air molecules , and cover the surface with air .',\n","  'vi': 'Và có hàng tỉ khe hở giữa chúng , những kẽ hở này , và những phân tử nano chiếm lấy những phân tử không khí và bao phủ lớp ngoài bởi không khí .'},\n"," {'en': \"It 's an umbrella of air all across it , and that layer of air is what the water hits , the mud hits , the concrete hits , and it glides right off .\",\n","  'vi': 'Đó hình thành lớp ô bảo vệ vậy là nước tác động vào lớp không khí bùn , bê tông , đều trượt đi hết .'},\n"," {'en': \"So if I put this inside this water here , you can see a silver reflective coating around it , and that silver reflective coating is the layer of air that 's protecting the water from touching the paddle , and it 's dry .\",\n","  'vi': 'Nếu tôi cho tấm ván này vào nước , bạn thấy lớp bạc óng ánh xung quanh nó , và lớp bạc này chính là lớp không khí bảo vệ để nước khỏi chạm vào tấm ván , và nó hoàn toàn khô .'},\n"," {'en': 'So what are the applications ?',\n","  'vi': 'Vậy thì ứng dụng ở đây là gì ?'},\n"," {'en': 'I mean , many of you right now are probably going through your head .',\n","  'vi': 'Có thể các bạn đang suy nghĩ trong đầu'},\n"," {'en': 'Everyone that sees this gets excited , and says , \" Oh , I could use it for this and this and this . \"',\n","  'vi': 'Mọi người có thể rất phấn khởi , cho rằng , \" Ồ , tôi có thể sử dụng vào việc này , việc nọ . \"'},\n"," {'en': \"The applications in a general sense could be anything that 's anti-wetting .\",\n","  'vi': 'Những ứng dụng thường thấy là những chất chống ẩm .'},\n"," {'en': \"We 've certainly seen that today .\",\n","  'vi': 'Ngày nay chúng ta đã thấy'},\n"," {'en': \"It could be anything that 's anti-icing , because if you don 't have water , you don 't have ice .\",\n","  'vi': 'những chất chống đóng băng , vì bạn không có nước , bạn không có băng .'},\n"," {'en': 'It could be anti-corrosion .',\n","  'vi': 'Đó có thể là chất chống rỉ sét .'},\n"," {'en': 'No water , no corrosion .',\n","  'vi': 'Không có nước , không có rỉ sét .'},\n"," {'en': 'It could be anti-bacterial .', 'vi': 'Có thể là chống vi khuẩn .'},\n"," {'en': \"Without water , the bacteria won 't survive .\",\n","  'vi': 'Không có nước , vi khuẩn không kí sinh được .'},\n"," {'en': 'And it could be things that need to be self-cleaning as well .',\n","  'vi': 'Và tất cả những chất tự rửa'},\n"," {'en': 'So imagine how something like this could help revolutionize your field of work .',\n","  'vi': 'Thử tưởng tượng những ứng dụng này có thể cải tiến lĩnh vực bạn đang làm .'},\n"," {'en': \"And I 'm going to leave you with one last demonstration , but before I do that , I would like to say thank you , and think small .\",\n","  'vi': 'Sau đây là bài biểu diễn cuối cùng của tôi , nhưng trước đó , tôi muốn cảm ơn tất cả các bạn , và nghĩ ít thôi nhé .'},\n"," {'en': \"It 's going to happen . Wait for it . Wait for it .\",\n","  'vi': 'Sẽ được thôi . Từ từ .'},\n"," {'en': \"You guys didn 't hear about us cutting out the Design from TED ?\",\n","  'vi': 'Bạn biết chúng tôi cắt biển hiệu của chương trình TED chứ ?'},\n"," {'en': '[ Two minutes later ... ] He ran into all sorts of problems in terms of managing the medical research part .',\n","  'vi': '[ Hai phút sau ... ] Ông ấy có rất nhiều nghiên cứu y học .'},\n"," {'en': \"It 's happening !\", 'vi': 'Được rồi !'},\n"," {'en': 'Dan Ariely : Our buggy moral code',\n","  'vi': 'Dan Ariely bàn về đoạn mã đạo đức bị lỗi của con người'},\n"," {'en': \"Behavioral economist Dan Ariely studies the bugs in our moral code : the hidden reasons we think it 's OK to cheat or steal . Clever studies help make his point that we 're predictably irrational -- and can be influenced in ways we can 't grasp .\",\n","  'vi': 'Nhà kinh tế học hành vi Dan Ariely nghiên cứu các lỗi trong đoạn mã phẩm chất đạo đức của chúng ta : lý do tiềm ẩn khiến chúng ta nghĩ sẽ chẳng sao nếu gian lận hoặc trộm đồ . Các nghiên cứu khéo léo giúp làm rõ ý tưởng của ông về việc chúng ta cư xử vô lý - và có thể bị ảnh hưởng theo những cách chúng ta không hiểu hết .'},\n"," {'en': 'I want to talk to you today a little bit about predictable irrationality .',\n","  'vi': 'Hôm nay , tôi muốn nói 1 chút về tính phi lý có thể lường trước được'},\n"," {'en': 'And my interest in irrational behavior started many years ago in the hospital .',\n","  'vi': 'Niềm đam mê của tôi về lĩnh vực này bắt đầu cách đây nhiều năm trong bệnh viện .'},\n"," {'en': 'I was burned very badly .', 'vi': 'Khi ấy tôi bị bỏng nặng .'},\n"," {'en': \"And if you spend a lot of time in hospital , you 'll see a lot of types of irrationalities .\",\n","  'vi': 'Nếu chẳng may bạn phải dành nhiều thời gian ở bệnh viện , bạn sẽ bắt gặp nhiều dạng phi lý'},\n"," {'en': 'And the one that particularly bothered me in the burn department was the process by which the nurses took the bandage off me .',\n","  'vi': 'Một điều đặc biệt gây khó khăn cho tôi tại khoa điều trị bỏng là quá trình các y tá tháo băng cho tôi .'},\n"," {'en': \"Now , you must have all taken a Band-Aid off at some point , and you must have wondered what 's the right approach .\",\n","  'vi': 'Bây giờ , bạn phải tháo băng y tế tại 1 số vị trí , bạn phải cẩn thận xem xét đâu là cách làm đúng'},\n"," {'en': 'Do you rip it off quickly -- short duration but high intensity -- or do you take your Band-Aid off slowly -- you take a long time , but each second is not as painful -- which one of those is the right approach ?',\n","  'vi': 'Cách 1 : bóc nó ra nhanh - thời gian ngắn nhưng phải khá mạnh tay hoặc cách 2 : bạn tháo băng từ từ-- mất khá nhiều thời gian- nhưng từng giây qua đi bớt đau đớn hơn-- Vậy cách nào là đúng ?'},\n"," {'en': 'The nurses in my department thought that the right approach was the ripping one , so they would grab hold and they would rip , and they would grab hold and they would rip .',\n","  'vi': 'Các y tá trong khoa tôi nằm cho rằng phương pháp đúng nhất là cách 1 , họ giữ 1 đầu và bắt đầu bóc và giữ 1 đầu rồi bóc .'},\n"," {'en': 'And because I had 70 percent of my body burned , it would take about an hour .',\n","  'vi': 'Vì tôi bị bỏng 70 % cơ thể nên mất khoảng 1 tiếng tháo băng .'},\n"," {'en': 'And as you can imagine , I hated that moment of ripping with incredible intensity .',\n","  'vi': 'Như bạn có thể tưởng tượng tôi căm ghét cái khoảnh khắc bóc toạc với 1 sức mạnh kinh hồn .'},\n"," {'en': 'And I would try to reason with them and say , \" Why don \\'t we try something else ?',\n","  'vi': 'Và tôi sẽ cố gắng lý sự với họ \" Tại sao chúng ta không thử cách khác ? \"'},\n"," {'en': 'Why don \\'t we take it a little longer -- maybe two hours instead of an hour -- and have less of this intensity ? \"',\n","  'vi': '\" Tại sao chúng ta không làm lâu hơn 1 chút 2 tiếng thay vì 1 tiếng , và nhẹ tay hơn ? \"'},\n"," {'en': 'And the nurses told me two things .',\n","  'vi': 'Và các y tá nói với tôi 2 điều .'},\n"," {'en': \"They told me that they had the right model of the patient -- that they knew what was the right thing to do to minimize my pain -- and they also told me that the word patient doesn 't mean to make suggestions or to interfere or ...\",\n","  'vi': 'Họ nói rằng mẫu bệnh nhân đúng mực là những người tin tưởng vào các y tá luôn thao tác đúng để giảm đau tối đa và họ cũng nói rằng bệnh nhân không nên gợi ý hay can thiệp , hoặc ...'},\n"," {'en': 'This is not just in Hebrew , by the way .',\n","  'vi': 'Đây không phải bằng chữ Hebrew'},\n"," {'en': \"It 's in every language I 've had experience with so far .\",\n","  'vi': 'Nó bằng mọi thứ ngôn ngữ tôi từng biết'},\n"," {'en': \"And , you know , there 's not much -- there wasn 't much I could do , and they kept on doing what they were doing .\",\n","  'vi': 'Và , bạn biết đấy , không có nhiều nhiều thứ tôi có thể làm và họ tiếp tục làm công việc của mình .'},\n"," {'en': 'And about three years later , when I left the hospital , I started studying at the university .',\n","  'vi': 'Và khoảng 3 năm sau , khi tôi ra viện , tôi đã bắt đầu học đại học'},\n"," {'en': 'And one of the most interesting lessons I learned was that there is an experimental method that if you have a question you can create a replica of this question in some abstract way , and you can try to examine this question , maybe learn something about the world .',\n","  'vi': 'Và 1 trong số các bài học thú vị nhất tôi đã học là phương pháp thử nghiệm nghĩa là nếu bạn nghi vấn điều gì , bạn có thể tạo 1 bản mô phỏng nghi vấn một cách trừu tượng , bạn có thể cố gắng kiểm tra nghi vấn , có thể học được chút gì về thế giới .'},\n"," {'en': \"So that 's what I did .\", 'vi': 'Đó là những gì tôi đã làm .'},\n"," {'en': 'I was still interested in this question of how do you take bandages off burn patients .',\n","  'vi': 'Tôi vẫn rất quan tâm đến câu hỏi làm cách nào để tháo băng y tế cho bệnh nhân bỏng .'},\n"," {'en': \"So originally I didn 't have much money , so I went to a hardware store and I bought a carpenter 's vice .\",\n","  'vi': 'Ban đầu tôi không có nhiều tiền , vì thế tôi đã đến cửa hàng kim khí và mua 1 cái bàn kẹp thợ mộc .'},\n"," {'en': 'And I would bring people to the lab and I would put their finger in it , and I would crunch it a little bit .',\n","  'vi': 'Sau đó tôi mang mọi người tới phòng thí nhiệm , đặt ngón tay họ vào đó , và tôi kẹp họ 1 chút .'},\n"," {'en': 'And I would crunch it for long periods and short periods , and pain that went up and pain that went down , and with breaks and without breaks -- all kinds of versions of pain .',\n","  'vi': 'Và tôi kẹp trong 1 khoảng thời gian dài và ngắn , cơn đau lúc tăng lúc giảm , có lúc nghỉ ngơi và có lúc không- tất cả các mức độ đau đớn .'},\n"," {'en': 'And when I finished hurting people a little bit , I would ask them , so , how painful was this ? Or , how painful was this ?',\n","  'vi': 'Sau khi thôi không làm đau mọi người nữa , tôi sẽ hỏi họ Bạn có đau không ? Đau như thế nào ?'},\n"," {'en': 'Or , if you had to choose between the last two , which one would you choose ?',\n","  'vi': 'Hoặc nếu được chọn giữa 2 kiểu đau cuối , bạn sẽ chọn cái nào ?'},\n"," {'en': 'I kept on doing this for a while .',\n","  'vi': 'Tôi tiếp tục làm thí nghiệm này 1 thời gian'},\n"," {'en': 'And then , like all good academic projects , I got more funding .',\n","  'vi': 'Và sau đó , giống các đề tài nghiên cứu hay khác , tôi nhận thêm nguồn tài trợ .'},\n"," {'en': 'I moved to sounds , electrical shocks -- I even had a pain suit that I could get people to feel much more pain .',\n","  'vi': 'Tôi thử nghiệm dùng âm thanh và shock điện thậm chí tôi có cả bộ quần áo gây đau khiến mọi người thấy đau hơn .'},\n"," {'en': 'But at the end of this process , what I learned was that the nurses were wrong .',\n","  'vi': 'Nhưng khi kết thúc dự án , cái tôi rút ra được là các y tá đã sai .'},\n"," {'en': 'Here were wonderful people with good intentions and plenty of experience , and nevertheless they were getting things wrong predictably all the time .',\n","  'vi': 'Đây là những con người tuyệt vời với sự chuẩn bị tốt nhiều kinh nghiệm , tuy nhiên họ luôn không lường trước hết được sự đau đớn .'},\n"," {'en': \"It turns out that because we don 't encode duration in the way that we encode intensity , I would have had less pain if the duration would have been longer and the intensity was lower .\",\n","  'vi': 'Hoá ra là vì chúng ta không mã hoá thời lượng theo cách mã hoá cường độ , Lẽ ra tôi sẽ bớt đau nếu thời gian chịu đựng kéo dài hơn và độ mạnh thấp hơn'},\n"," {'en': 'It turns out it would have been better to start with my face , which was much more painful , and move toward my legs , giving me a trend of improvement over time -- that would have been also less painful .',\n","  'vi': 'Hoá ra chúng ta nên bắt đầu với vùng mặt là vùng đau đớn hơn , rồi chuyển đến chân tạo 1 xu hướng cải thiện theo thời gian-- như thế sẽ đỡ đau hơn .'},\n"," {'en': 'And it also turns out that it would have been good to give me breaks in the middle to kind of recuperate from the pain .',\n","  'vi': 'Và cũng hoá ra họ nên cho tôi nghỉ vào giữa quá trình để hồi phục khỏi cơn đau .'},\n"," {'en': 'All of these would have been great things to do , and my nurses had no idea .',\n","  'vi': 'Tất cả những điều này đều rất hữu ích nhưng các y tá của tôi lại chẳng biết gì .'},\n"," {'en': 'And from that point on I started thinking , are the nurses the only people in the world who get things wrong in this particular decision , or is it a more general case ?',\n","  'vi': 'Từ điểm này , tôi bắt đầu suy nghĩ liệu các y tá đó là nhũng người duy nhất trên thế giới này làm mọi việc tồi tệ hơn vì 1 quyết định này , hay đây là trường hợp phổ biến ?'},\n"," {'en': \"And it turns out it 's a more general case -- there 's a lot of mistakes we do .\",\n","  'vi': 'Và hoá ra đó là tình trạng chung thôi . Chúng ta mắc rất nhiều lỗi .'},\n"," {'en': 'And I want to give you one example of one of these irrationalities , and I want to talk to you about cheating .',\n","  'vi': 'Và tôi muốn nói về 1 ví dụ điển hình của sự phi lý Tôi muốn nói về hành vi gian lận .'},\n"," {'en': \"And the reason I picked cheating is because it 's interesting , but also it tells us something , I think , about the stock market situation we 're in .\",\n","  'vi': 'Lý do tôi chọn gian lận là vì nó rất thú vị và vì nó sẽ cho chúng ta biết điều gì đó về tình tình của thị trường chứng khoán chúng ta tham gia .'},\n"," {'en': 'So , my interest in cheating started when Enron came on the scene , exploded all of a sudden , and I started thinking about what is happening here .',\n","  'vi': 'Tôi bắt đầu quan tâm đến sự gian lận khi vụ tai tiếng Enron đến và thình lình bùng nổ , và tôi bắt đầu nghĩ chuyện gì đang xảy ra ở đây .'},\n"," {'en': 'Is it the case that there was kind of a few apples who are capable of doing these things , or are we talking a more endemic situation , that many people are actually capable of behaving this way ?',\n","  'vi': 'Liệu đây chỉ là trường hợp con sâu bỏ rầu nồi canh hay chúng ta đang nói về 1 bệnh dịch mà nhiều người đều có thể hành xử theo cách này ?'},\n"," {'en': 'So , like we usually do , I decided to do a simple experiment .',\n","  'vi': 'Vì vậy , như chúng tôi vẫn thường làm , tôi quyết định làm 1 thí nghiệm đơn giản .'},\n"," {'en': \"And here 's how it went .\", 'vi': 'Nó như thế này ...'},\n"," {'en': \"If you were in the experiment , I would pass you a sheet of paper with 20 simple math problems that everybody could solve , but I wouldn 't give you enough time .\",\n","  'vi': 'Nếu bạn tham gia thí nghiệm , tôi sẽ đưa cho bạn 1 tờ giấy với 20 phép tính đơn giản mà ai cũng có thể làm được nhưng tôi sẽ không cho bạn đủ thời gian .'},\n"," {'en': 'When the five minutes were over , I would say , \" Pass me the sheets of paper , and I \\'ll pay you a dollar per question . \"',\n","  'vi': 'Sau 5 phút , tôi sẽ nói \" Đưa tôi tờ giấy , tôi sẽ trả bạn $ 1 cho 1 câu hỏi \"'},\n"," {'en': 'People did this . I would pay people four dollars for their task -- on average people would solve four problems .',\n","  'vi': 'Tôi phải trả 4 $ cho công việc của họ vì trung bình mỗi người giải được 4 phép tính .'},\n"," {'en': 'Other people I would tempt to cheat .',\n","  'vi': 'Với những người khác , tôi tạo cơ hội cho họ gian lận .'},\n"," {'en': 'I would pass their sheet of paper .',\n","  'vi': 'Tôi đưa đề bài cho họ .'},\n"," {'en': 'When the five minutes were over , I would say , \" Please shred the piece of paper .',\n","  'vi': 'Sau 5 phút , tôi nói \" Bạn hãy xé tờ giấy đó đi .'},\n"," {'en': 'Put the little pieces in your pocket or in your backpack , and tell me how many questions you got correctly . \"',\n","  'vi': 'Nhét các mảnh vụn vào túi quần hoặc ba lô , và nói cho tôi biết bạn trả lời đúng bao nhiêu câu hỏi . \"'},\n"," {'en': 'People now solved seven questions on average .',\n","  'vi': 'Mọi người bây giờ trung bình \" trả lời đúng \" 7 câu .'},\n"," {'en': \"Now , it wasn 't as if there was a few bad apples -- a few people cheated a lot .\",\n","  'vi': 'Bây giờ , việc đó không phải như thể có 1 vài con sâu-- nghĩa là 1 vài người gian lận nhiều .'},\n"," {'en': 'Instead , what we saw is a lot of people who cheat a little bit .',\n","  'vi': 'Mà những gì chúng tôi quan sát được là rất nhiều người gian lận 1 chút .'},\n"," {'en': 'Now , in economic theory , cheating is a very simple cost-benefit analysis .',\n","  'vi': 'Xét trên lý thuyết kinh tế , gian lận là sự phân tích lợi nhuận rất đơn giản .'},\n"," {'en': \"You say , what 's the probability of being caught ?\",\n","  'vi': 'Vậy , có bao nhiêu khả năng bị bắt quả tang ?'},\n"," {'en': 'How much do I stand to gain from cheating ?',\n","  'vi': 'Tôi sẽ kiếm được bao nhiêu nếu gian lận ?'},\n"," {'en': 'And how much punishment would I get if I get caught ?',\n","  'vi': 'tôi sẽ bị phạt bao nhiêu tiền nếu bị phát hiện ?'},\n"," {'en': \"And you weigh these options out -- you do the simple cost-benefit analysis , and you decide whether it 's worthwhile to commit the crime or not .\",\n","  'vi': 'Và bạn cân nhắc những lựa chọn đó-- bạn đang phân tích lợi nhuận 1 cách đơn giản , và bạn quyết định liệu nó có xứng đáng để phạm tội hay không .'},\n"," {'en': 'So , we try to test this .',\n","  'vi': 'Chúng tôi cố gắng kiểm tra điều này'},\n"," {'en': 'For some people , we varied how much money they could get away with -- how much money they could steal .',\n","  'vi': 'Với 1 số người , chúng tôi thay đổi số tiền họ có thể kiếm được số tiền họ có thể lấy trộm'},\n"," {'en': 'We paid them 10 cents per correct question , 50 cents , a dollar , five dollars , 10 dollars per correct question .',\n","  'vi': 'chúng tôi trả họ 10 cent cho 1 câu trả lời đúng , 50 cent , $ 1 , $ 5 , $ 10 cho 1 câu trả lời đúng .'},\n"," {'en': \"You would expect that as the amount of money on the table increases , people would cheat more , but in fact it wasn 't the case .\",\n","  'vi': 'Bạn sẽ nghĩ rằng khi số tiền trên bàn tăng lên mọi người sẽ gian lận nhiều hơn , nhưng thực tế không phải vậy'},\n"," {'en': 'We got a lot of people cheating by stealing by a little bit .',\n","  'vi': 'Có nhiều người gian lận bằng cách ăn gian 1 chút .'},\n"," {'en': 'What about the probability of being caught ?',\n","  'vi': 'Thế còn về khả năng bị phát hiện ?'},\n"," {'en': 'Some people shredded half the sheet of paper , so there was some evidence left .',\n","  'vi': 'Một số người xé đôi tờ giấy vì thế bằng chứng vẫn còn .'},\n"," {'en': 'Some people shredded the whole sheet of paper .',\n","  'vi': 'Một số xé toàn bộ tờ giấy .'},\n"," {'en': 'Some people shredded everything , went out of the room , and paid themselves from the bowl of money that had over 100 dollars .',\n","  'vi': 'Một số xé tất cả , đi ra khỏi phòng , lấy tiền từ hộp đựng hơn 100 $'},\n"," {'en': 'You would expect that as the probability of being caught goes down , people would cheat more , but again , this was not the case .',\n","  'vi': 'Bạn sẽ nghĩ rằng khi khả năng bị phát hiện giảm xuống mọi người sẽ gian lận nhiều hơn , nhưng 1 lần nữa , đây không phải trường hợp đó .'},\n"," {'en': 'Again , a lot of people cheated by just by a little bit , and they were insensitive to these economic incentives .',\n","  'vi': '1 lần nữa , nhiều người gian lận 1 chút và họ thiếu nhạy cảm với các ưu đãi kinh tế đó .'},\n"," {'en': 'So we said , \" If people are not sensitive to the economic rational theory explanations , to these forces , what could be going on ? \"',\n","  'vi': 'Do vậy chúng ta nói \" Nếu mọi người không nhạy cảm với các giải thích về lý thuyết phù hợp kinh tế , với các lực đó chuyện gì sẽ tiếp tục xảy ra ? \"'},\n"," {'en': 'And we thought maybe what is happening is that there are two forces .',\n","  'vi': 'Và chúng tôi nghĩ có thể có 2 lực đang diễn ra'},\n"," {'en': \"At one hand , we all want to look at ourselves in the mirror and feel good about ourselves , so we don 't want to cheat .\",\n","  'vi': 'một mặt , chúng ta luôn muốn tự soi bản thân trong gương và cảm giác tốt về bản thân , do vậy chúng ta không muốn gian lận'},\n"," {'en': 'On the other hand , we can cheat a little bit , and still feel good about ourselves .',\n","  'vi': 'Mặt khác , chúng ta có thể gian lận 1 chút và vẫn cảm thấy tốt đẹp về bản thân'},\n"," {'en': \"So , maybe what is happening is that there 's a level of cheating we can 't go over , but we can still benefit from cheating at a low degree , as long as it doesn 't change our impressions about ourselves .\",\n","  'vi': 'Vậy , có thể vấn đề ở đây là 1 mức độ gian lận chúng ta không thể vượt qua nhưng chúng ta vẫn có lợi từ việc gian lận ở mức độ thấp miễn là nó không làm thay đổi ấn tượng của chúng ta về chính bản thân mình .'},\n"," {'en': 'We call this like a personal fudge factor .',\n","  'vi': 'Chúng ta gọi đó là yếu tố gian lận cá nhân .'},\n"," {'en': 'Now , how would you test a personal fudge factor ?',\n","  'vi': 'Vậy , làm thế nào để kiểm tra yếu tố gian lận cá nhân ?'},\n"," {'en': 'Initially we said , what can we do to shrink the fudge factor ?',\n","  'vi': 'Ban đầu chúng tôi nói , chúng tôi có thể làm gì để giảm yếu tố này ?'},\n"," {'en': 'So , we got people to the lab , and we said , \" We have two tasks for you today . \"',\n","  'vi': 'Chúng tôi mang mọi người đến phòng thí nghiệm và nói \" Hôm nay chúng tôi có 2 nhiệm vụ cho các bạn'},\n"," {'en': 'First , we asked half the people to recall either 10 books they read in high school , or to recall The Ten Commandments , and then we tempted them with cheating .',\n","  'vi': 'Đầu tiên , chúng tôi yêu cầu 1 nửa số người tham gia hồi tưởng 10 cuốn sách họ đã đọc ở cấp 3 hoặc nhớ lại 10 Điều Răn của Chúa và sau đó chúng tôi tạo cơ hội cho họ gian lận'},\n"," {'en': 'Turns out the people who tried to recall The Ten Commandments -- and in our sample nobody could recall all of The Ten Commandments -- but those people who tried to recall The Ten Commandments , given the opportunity to cheat , did not cheat at all .',\n","  'vi': 'Kết quả là những người cố gắng nhớ lại 10 Điều Răn của Chúa -và trong mẫu của chúng tôi , không ai nhớ hết cả 10 Điều Răn nhưng những người cố gắng nhớ 10 Điều Răn được tạo cơ hội để gian lận , lại không gian lận chút nào .'},\n"," {'en': \"It wasn 't that the more religious people -- the people who remembered more of the Commandments -- cheated less , and the less religious people -- the people who couldn 't remember almost any Commandments -- cheated more .\",\n","  'vi': 'Họ không phải những người nặng tín ngưỡng hơn những người nhớ được nhiều điều răn hơn thì gian lận ít hơn và những người ít tôn giáo là những người không thể nhớ được hầu hết bất kỳ điều răn nào thì gian lận nhiều hơn .'},\n"," {'en': 'The moment people thought about trying to recall The Ten Commandments , they stopped cheating .',\n","  'vi': 'Khoảnh khắc mọi người nghĩ về việc cố gắng nhớ lại 10 Điều Răn họ đã thôi gian lận'},\n"," {'en': \"In fact , even when we gave self-declared atheists the task of swearing on the Bible and we give them a chance to cheat , they don 't cheat at all .\",\n","  'vi': 'Thực tế , thậm chí khi chúng tôi yêu cầu những người tự cho là theo thuyết vô thần thề trên Kinh Thánh và chúng tôi cho họ cơ hội để gian lận nhưng họ không gian lận chút nào .'},\n"," {'en': 'Now , Ten Commandments is something that is hard to bring into the education system , so we said , \" Why don \\'t we get people to sign the honor code ? \"',\n","  'vi': '10 Điều Răn rất khó để đưa vào hệ thống giáo dục , vì thế chúng tôi nói \" Tại sao chúng ta không yêu cầu mọi người ký mật mã danh dự ? \"'},\n"," {'en': 'So , we got people to sign , \" I understand that this short survey falls under the MIT Honor Code . \"',\n","  'vi': 'Sau đó , chúng tôi đã yêu cầu mọi người làm như thế \" Tôi hiểu rằng cuộc điều tra ngắn này nằm dưới Mã Danh Dự MIT \"'},\n"," {'en': 'Then they shredded it . No cheating whatsoever .',\n","  'vi': 'Sau đó họ xé nó đi . Không có bất kỳ gian lận nào'},\n"," {'en': \"And this is particularly interesting , because MIT doesn 't have an honor code .\",\n","  'vi': 'Và thú vị ở chỗ MIT không có bất kỳ mã danh dự nào .'},\n"," {'en': 'So , all this was about decreasing the fudge factor .',\n","  'vi': 'Vậy , tất cả điều trên là về việc giảm yếu tố gian lận cá nhân'},\n"," {'en': 'What about increasing the fudge factor ?',\n","  'vi': 'Thế còn về tăng yếu tố gian lận ?'},\n"," {'en': 'The first experiment -- I walked around MIT and I distributed six-packs of Cokes in the refrigerators -- these were common refrigerators for the undergrads .',\n","  'vi': 'Thí nhiệm đầu tiên- tôi đi xung quanh MIT và đặt 6 hộp Coke vào tủ lạnh loại tủ lạnh thông thường cho sinh viên chưa tốt nghiệp'},\n"," {'en': 'And I came back to measure what we technically call the half-lifetime of Coke -- how long does it last in the refrigerators ?',\n","  'vi': 'Và tôi quay lại để đo cái mà chúng tôi gọi là nửa cuộc đời của Coke- nó tồn tại được bao lâu trong tủ lạnh ?'},\n"," {'en': \"As you can expect it doesn 't last very long ; people take it .\",\n","  'vi': 'Như bạn có thể đoán nó không \" sống \" được lâu . Mọi người đã uống chúng .'},\n"," {'en': 'In contrast , I took a plate with six one-dollar bills , and I left those plates in the same refrigerators .',\n","  'vi': 'Ngược lại , tôi đặt $ 6 vào đĩa và bỏ các đĩa đó trong cùng cái tủ lạnh đó'},\n"," {'en': 'No bill ever disappeared .', 'vi': 'Không đồng đô la nào bị mất cả'},\n"," {'en': 'Now , this is not a good social science experiment , so to do it better I did the same experiment as I described to you before .',\n","  'vi': 'Đây không phải là 1 thí nghiệm khoa học xã hội tốt nên để làm tốt hơn , tôi đã làm 1 thí nhiệm y như tôi đã mô tả cho các bạn lúc trước'},\n"," {'en': 'A third of the people we passed the sheet , they gave it back to us .',\n","  'vi': '1 / 3 người tham gia nhận tờ giấy chúng tôi phát , họ trả lại cho chúng tôi'},\n"," {'en': 'A third of the people we passed it to , they shredded it , they came to us and said , \" Mr. Experimenter , I solved X problems . Give me X dollars . \"',\n","  'vi': '1 / 3 người nhận giấy , họ xé nó đi và nói với chúng tôi \" tôi giải được X phép tính . Hãy đưa cho tôi X đô la . \"'},\n"," {'en': 'A third of the people , when they finished shredding the piece of paper , they came to us and said , \" Mr Experimenter , I solved X problems . Give me X tokens . \"',\n","  'vi': '1 / 3 người tham gia , sau khi xé giấy họ nói với chúng tôi \" Tôi giải được X phép tính . Hãy đưa cho tôi X phiếu đổi tiền . \"'},\n"," {'en': 'We did not pay them with dollars ; we paid them with something else .',\n","  'vi': 'Chúng tôi không trả họ bằng đô la mà bằng 1 thứ khác'},\n"," {'en': 'And then they took the something else , they walked 12 feet to the side , and exchanged it for dollars .',\n","  'vi': 'Sau đó họ thấy thứ đó , đi 12 ft đến nơi đổi nó lấy một ít tiền mặt .'},\n"," {'en': 'Think about the following intuition .',\n","  'vi': 'Hãy nghĩ tới trực giác sau :'},\n"," {'en': 'How bad would you feel about taking a pencil from work home , compared to how bad would you feel about taking 10 cents from a petty cash box ?',\n","  'vi': 'Bạn sẽ thấy tồi tệ ra sao nếu lấy cái bút chì ở cơ quan về nhà so với cảm giác lấy 10 cent từ hộp tiền lẻ'},\n"," {'en': 'These things feel very differently .',\n","  'vi': 'những điều này tạo cảm giác rất khác nhau'},\n"," {'en': 'Would being a step removed from cash for a few seconds by being paid by token make a difference ?',\n","  'vi': 'Liệu được trả bằng tiền mặt hay bằng phiếu đổi tiền có tạo nên sự khác biệt ?'},\n"," {'en': 'Our subjects doubled their cheating .',\n","  'vi': 'Các đối tượng nghiên cứu nhân đôi sự gian lận của họ .'},\n"," {'en': \"I 'll tell you what I think about this and the stock market in a minute .\",\n","  'vi': 'Tôi sẽ nói với bạn điều tôi nghĩ về điều này và về thị trường chứng khoán trong 1 phút tới'},\n"," {'en': \"But this did not solve the big problem I had with Enron yet , because in Enron , there 's also a social element .\",\n","  'vi': 'Nhưng điiều này không giải quyết vấn đề lớn giữa tôi và Enron vì trong Enron có 1 yếu tố xã hội'},\n"," {'en': 'People see each other behaving .',\n","  'vi': 'Mọi người thấy cách cư xử của nhau'},\n"," {'en': 'In fact , every day when we open the news we see examples of people cheating .',\n","  'vi': 'Thực tế thì hàng ngày chúng ta xem tin tức thấy các ví dụ gian lận của mọi người'},\n"," {'en': 'What does this cause us ?',\n","  'vi': 'Điều này gây ra cái gì cho chúng ta ?'},\n"," {'en': 'So , we did another experiment .',\n","  'vi': 'Chúng tôi làm 1 thí nghiệm khác'},\n"," {'en': 'We got a big group of students to be in the experiment , and we prepaid them .',\n","  'vi': 'Chúng tôi có 1 nhóm lớn các sinh viên tham gia thí nghiệm và chúng tôi đã trả trước cho họ'},\n"," {'en': \"So everybody got an envelope with all the money for the experiment , and we told them that at the end , we asked them to pay us back the money they didn 't make . OK ?\",\n","  'vi': 'Vì vậy mỗi người đều có 1 phong bao tiền cho cuộc thí nghiệm chúng tôi nói với họ rằng đến lúc cuối , chúng tôi yêu cầu họ trả lại số tiền họ không làm ra . Có được không ?'},\n"," {'en': 'The same thing happens .', 'vi': 'Điều tương tự xảy ra .'},\n"," {'en': 'When we give people the opportunity to cheat , they cheat .',\n","  'vi': 'Khi chúng tôi tạo cơ hội cho họ gian lận , họ gian lận'},\n"," {'en': 'They cheat just by a little bit , all the same .',\n","  'vi': 'chỉ 1 chút , nhưng tất cả đều như vậy .'},\n"," {'en': 'But in this experiment we also hired an acting student .',\n","  'vi': 'Nhưng trong thí nghiệm này , chúng tôi đã thuê 1 sinh viên điện ảnh'},\n"," {'en': 'This acting student stood up after 30 seconds , and said , \" I solved everything . What do I do now ? \"',\n","  'vi': 'Sinh viên này đứng lên sau 30 giây và nói , \" Tôi đã giải xong mọi thứ . Bây giờ tôi phải làm gì nữa ? \"'},\n"," {'en': 'And the experimenter said , \" If you \\'ve finished everything , go home .',\n","  'vi': 'và người điều hành nói , \" Nếu bạn làm xong mọi việc thì về nhà được rồi . \"'},\n"," {'en': 'That \\'s it . The task is finished . \"',\n","  'vi': 'Nhiệm vụ hoàn thành như thế đấy .'},\n"," {'en': 'So , now we had a student -- an acting student -- that was a part of the group .',\n","  'vi': 'Chúng tôi có 1 sinh viên - 1 sinh viên diễn xuất là 1 phần trong nhóm .'},\n"," {'en': 'Nobody knew it was an actor .',\n","  'vi': 'Không ai biết đó là 1 diễn viên'},\n"," {'en': 'And they clearly cheated in a very , very serious way .',\n","  'vi': 'Và họ gian lận rõ ràng và nghiêm trọng'},\n"," {'en': 'What would happen to the other people in the group ?',\n","  'vi': 'Chuyện gì sẽ diễn ra với những sinh viên còn lại trong nhóm ?'},\n"," {'en': 'Will they cheat more , or will they cheat less ?',\n","  'vi': 'Họ sẽ gian lận ít hơn , hay nhiều hơn ?'},\n"," {'en': 'Here is what happens .', 'vi': 'Đây là những gì đã diễn ra .'},\n"," {'en': \"It turns out it depends on what kind of sweatshirt they 're wearing .\",\n","  'vi': 'Kết quả là nó phụ thuộc vào loại áo nào họ đang mặc'},\n"," {'en': 'Here is the thing .', 'vi': 'Đây là nó .'},\n"," {'en': 'We ran this at Carnegie Mellon and Pittsburgh .',\n","  'vi': 'Chúng tôi đã cho thử nghiệm cái này tại Carnegie Mellon và Pittsburgh'},\n"," {'en': 'And at Pittsburgh there are two big universities , Carnegie Mellon and University of Pittsburgh .',\n","  'vi': 'Tại Pittsburgh có 2 trường đại học lớn Carnegie Mellon và đại học Pittsburgh'},\n"," {'en': 'All of the subjects sitting in the experiment were Carnegie Mellon students .',\n","  'vi': 'Tất cả đối tượng tham gia thí nghiệm là sinh viên ở Carnegie Mellon'},\n"," {'en': 'When the actor who was getting up was a Carnegie Mellon student -- he was actually a Carnegie Mellon student -- but he was a part of their group , cheating went up .',\n","  'vi': 'Khi người diễn viên đứng lên anh thực sự là sinh viên của Carnegie Mellon nhưng anh ta thuộc nhóm của họ , và gian lận tăng lên'},\n"," {'en': 'But when he actually had a University of Pittsburgh sweatshirt , cheating went down .',\n","  'vi': 'Nhưng khi anh ta mặc 1 cái áo của đại học Pittsburgh gian lận giảm xuống'},\n"," {'en': 'Now , this is important , because remember , when the moment the student stood up , it made it clear to everybody that they could get away with cheating , because the experimenter said , \" You \\'ve finished everything . Go home , \" and they went with the money .',\n","  'vi': 'Điều này rất quan trọng , vì hãy nhớ khi người sinh viên đó đứng lên , mọi người thấy rõ họ có thể an toàn với gian lận vì người điều hành nói \" Bạn đã hoàn thành công việc.Về nhà được rồi \" và họ đã ra về với 1 số tiền'},\n"," {'en': \"So it wasn 't so much about the probability of being caught again .\",\n","  'vi': 'Vì thế không có nhiều khả năng bị phát hiện'},\n"," {'en': 'It was about the norms for cheating .',\n","  'vi': 'Nó liên quan đến các quy tắc của gian lận'},\n"," {'en': \"If somebody from our in-group cheats and we see them cheating , we feel it 's more appropriate , as a group , to behave this way .\",\n","  'vi': 'Nếu ai đó từ nhóm chúng tôi gian lận và chúng tôi thấy rõ là họ gian lận chúng tôi thấy với tư cách 1 nhóm , sẽ là phù hợp hơn để hành xử theo cách đó'},\n"," {'en': \"But if it 's somebody from another group , these terrible people -- I mean , not terrible in this -- but somebody we don 't want to associate ourselves with , from another university , another group , all of a sudden people 's awareness of honesty goes up -- a little bit like The Ten Commandments experiment -- and people cheat even less .\",\n","  'vi': 'Nhưng nếu ai đó từ 1 nhóm khác , những người tồi tệ đó Ý tôi là không phải tồi tệ theo cách-- nhưng ai đó từ 1 trường khác , 1 nhóm khác mà chúng tôi không muốn hợp tác cùng 1 cách đột ngột , ý thức của mọi người về tính trung thực tăng lên 1 chút giống như thí nghiệm 10 Điều Răn của Chúa và mọi người thậm chí gian lận ít hơn .'},\n"," {'en': 'So , what have we learned from this about cheating ?',\n","  'vi': 'Vậy , chúng tôi đã học được gì từ thí nghiệm này ?'},\n"," {'en': \"We 've learned that a lot of people can cheat .\",\n","  'vi': 'Chúng tôi rút ra rằng nhiều người có thể gian lận'},\n"," {'en': 'They cheat just by a little bit .',\n","  'vi': 'Họ gian lận chỉ 1 chút thôi'},\n"," {'en': 'When we remind people about their morality , they cheat less .',\n","  'vi': 'Khi chúng tôi gợi cho họ về phẩm chất đạo đức , họ gian lận ít đi'},\n"," {'en': 'When we get bigger distance from cheating , from the object of money , for example , people cheat more .',\n","  'vi': 'Khi chúng tôi tạo 1 khoảng cách lớn hơn khỏi gian lận khỏi tiền bạc , họ gian lận nhiều hơn .'},\n"," {'en': \"And when we see cheating around us , particularly if it 's a part of our in-group , cheating goes up .\",\n","  'vi': 'Và khi chúng tôi thấy hành vi gian lận quanh chúng tôi đặc biệt nếu nó là 1 phần trong cùng nhóm ấy , gian lận tăng lên'},\n"," {'en': 'Now , if we think about this in terms of the stock market , think about what happens .',\n","  'vi': 'Bây giờ , nếu chúng ta nghĩ đến thị trường chứng khoán nghĩ đến những gì đang diễn ra'},\n"," {'en': 'What happens in a situation when you create something where you pay people a lot of money to see reality in a slightly distorted way ?',\n","  'vi': 'Chuyện gì sẽ xảy ra trong 1 tình huống khi bạn tạo ra cái gì đó nơi mà bạn trả mọi người nhiều tiền để thấy hiện thực theo 1 cách méo mó 1 chút ?'},\n"," {'en': 'Would they not be able to see it this way ?',\n","  'vi': 'Liệu họ không thể nhìn thấy điều đó theo cách này ?'},\n"," {'en': 'Of course they would .', 'vi': 'Tất nhiên họ có thể'},\n"," {'en': 'What happens when you do other things , like you remove things from money ?',\n","  'vi': 'Chuyện gì sẽ xay ra khi bạn làm những việc khác như là tách rời mọi thứ khỏi tiền ?'},\n"," {'en': 'You call them stock , or stock options , derivatives , mortgage-backed securities .',\n","  'vi': 'Bạn gọi đó là chứng khoán , hay các quyền chọn chứng khoán , các chứng khoán phái sinh , chứng khoán nợ .'},\n"," {'en': \"Could it be that with those more distant things , it 's not a token for one second , it 's something that is many steps removed from money for a much longer time -- could it be that people will cheat even more ?\",\n","  'vi': 'Có thể nào với những thứ xa xôi như thế không phải là phiếu đổi tiền trong 1 giây , nó là thứ mà nhiều bước được tách khỏi tiền bạc trong 1 khoảng thời gian dài hơn- mọi người sẽ gian lận nhiều hơn ?'},\n"," {'en': 'And what happens to the social environment when people see other people behave around them ?',\n","  'vi': 'Và điều gì sẽ xảy ra với môi trường xã hội khi mọi người thấy những người khác cư xử như vậy xung quanh mình ?'},\n"," {'en': 'I think all of those forces worked in a very bad way in the stock market .',\n","  'vi': 'Tôi cho rằng tất cả các lực tác động đó hoạt động theo 1 cách xấu trên thị trường chứng khoán'},\n"," {'en': 'More generally , I want to tell you something about behavioral economics .',\n","  'vi': 'Khái quát hơn , tôi muốn nói với bạn về kinh tế học ứng xử .'},\n"," {'en': 'We have many intuitions in our life , and the point is that many of these intuitions are wrong .',\n","  'vi': 'Chúng ta trong cuộc đời có nhiều trực giác và vấn đề là nhiều trực giác đó là sai'},\n"," {'en': 'The question is , are we going to test those intuitions ?',\n","  'vi': 'Câu hỏi đặt ra là , chúng ta sẽ kiểm tra những trực giác đó chứ ?'},\n"," {'en': \"We can think about how we 're going to test this intuition in our private life , in our business life , and most particularly when it goes to policy , when we think about things like No Child Left Behind , when you create new stock markets , when you create other policies -- taxation , health care and so on .\",\n","  'vi': 'Chúng ta có thể nghĩ đến làm thế nào để kiểm tra trực giác này trong cuộc sống cá nhân mình , trong cuộc sống kinh doanh của chúng ta và nhất là khi nó liên quan đến chính sách , khi chúng ta nghĩ đến những thứ như Không Đứa Trẻ Nào Bị Bỏ Lại khi bạn xây dựng những thị trường chứng khoán mới , khi bạn xây dựng các chính sách khác thuế , chăm sóc sức khoẻ , ...'},\n"," {'en': 'And the difficulty of testing our intuition was the big lesson I learned when I went back to the nurses to talk to them .',\n","  'vi': 'Và khó khăn trong việc kiểm tra trực giác là bài học lớn cho tôi khi tôi trở lại gặp các y tá và nói chuyện với họ .'},\n"," {'en': 'So I went back to talk to them and tell them what I found out about removing bandages .',\n","  'vi': 'Tôi trở lại để nói với họ những gì tôi khám phá ra về việc tháo băng y tế'},\n"," {'en': 'And I learned two interesting things .',\n","  'vi': 'Và tôi học được 2 điều thú vị sau'},\n"," {'en': 'One was that my favorite nurse , Ettie , told me that I did not take her pain into consideration .',\n","  'vi': 'Một là cô y tá yêu thích của tôi , Ettie , đã nói với tôi rằng tôi không cân nhắc nỗi đau của cô'},\n"," {'en': 'She said , \" Of course , you know , it was very painful for you .',\n","  'vi': 'Cô nói , \" Dĩ nhiên , cháu biết đấy , cháu đã rất đau đớn .'},\n"," {'en': 'But think about me as a nurse , taking , removing the bandages of somebody I liked , and had to do it repeatedly over a long period of time .',\n","  'vi': 'Nhưng hãy nghĩ đến cô như 1 y tá tháo băng y tế cho 1 người cô yêu quý và phải làm thế liên tục trong 1 thời gian dài'},\n"," {'en': 'Creating so much torture was not something that was good for me , too . \"',\n","  'vi': 'Gây ra đau đơn như thế cũng làm cô rất buồn . \"'},\n"," {'en': 'And she said maybe part of the reason was it was difficult for her .',\n","  'vi': 'Và cô ấy nói , có thể đó là 1 phần lý do gây khó khăn cho cô .'},\n"," {'en': 'But it was actually more interesting than that , because she said , \" I did not think that your intuition was right .',\n","  'vi': 'Nhưng điều thực sự thú vị là vì cô ấy nói , \" Cô không nghĩ trực giác của cháu đã đúng'},\n"," {'en': 'I felt my intuition was correct . \"',\n","  'vi': 'Cô cảm thấy trực giác của cô là đúng . \"'},\n"," {'en': \"So , if you think about all of your intuitions , it 's very hard to believe that your intuition is wrong .\",\n","  'vi': 'Nếu bạn nghĩ đến tất cả trực giác của mình , rất khó để tin trực giác của mình là sai .'},\n"," {'en': 'And she said , \" Given the fact that I thought my intuition was right ... \" -- she thought her intuition was right -- it was very difficult for her to accept doing a difficult experiment to try and check whether she was wrong .',\n","  'vi': 'Và cô ấy nói , \" Giả sử trực giác của cô là đúng ... \" - cô ấy nghĩ trực giác của mình đúng rất khó cho cô ấy chấp nhận làm 1 thí nghiệm khó để thử và kiểm tra liệu cô ấy có sai không .'},\n"," {'en': \"But in fact , this is the situation we 're all in all the time .\",\n","  'vi': 'Nhưng thực ra , đây là tình huống chúng ta luôn rơi vào'},\n"," {'en': 'We have very strong intuitions about all kinds of things -- our own ability , how the economy works , how we should pay school teachers .',\n","  'vi': 'Chúng ta có những trực giác rất mạnh về mọi việc về khả năng của riêng chúng ta , về nền kình tế hoạt động ra sao hay chúng ta nên trả lương cho các giáo viên như thế nào'},\n"," {'en': \"But unless we start testing those intuitions , we 're not going to do better .\",\n","  'vi': 'Nhưng trừ phi chúng ta bắt đầu thử nghiệm các trực giác đó nếu không chúng ta sẽ không cải thiện tốt hơn .'},\n"," {'en': 'And just think about how better my life would have been if these nurses would have been willing to check their intuition , and how everything would have been better if we just start doing more systematic experimentation of our intuitions .',\n","  'vi': 'Và hãy nghĩ đến cuộc sống của tôi lẽ ra sẽ tốt hơn đến mức nào nếu các y tá đó sẵn sàng kiểm tra trực giác của họ và mọi thứ lẽ ra sẽ tốt hơn thế nào nếu chúng ta bắt tay vào làm thí nghiệm có hệ thống về trực giác của mình'},\n"," {'en': 'Thank you very much .', 'vi': 'Cảm ơn các bạn rất nhiều'},\n"," {'en': 'Jane McGonigal : Massively multi-player … thumb-wrestling ?',\n","  'vi': 'Jane McGonigal : Trò chơi với rất nhiều người ... vật ngón tay cái ?'},\n"," {'en': 'What happens when you get an entire audience to stand up and connect with one another ? Chaos , that \\'s what . At least , that \\'s what happened when Jane McGonigal tried to teach TED to play her favorite game . Then again , when the game is \" massively multiplayer thumb-wrestling , \" what else would you expect ?',\n","  'vi': 'Những gì xảy ra khi bạn khiến cho toàn bộ khán giả đứng lên và kết nối với nhau ? Hỗn loạn , đó là những gì ta có . Ít nhất , đó là những gì đã xảy ra khi Jane McGonigal cố gắng để hướng dẫn TED chơi trò chơi yêu thích của cô . Sau đó , một lần nữa , khi trận đấu vật ngón cái với rất nhiều người diễn ra , bạn còn trông chờ gì hơn thế ?'},\n"," {'en': 'Today I am going to teach you how to play my favorite game : massively multiplayer thumb-wrestling .',\n","  'vi': 'Hôm nay tôi sẽ chỉ cho các bạn làm thế nào để chơi trò chơi yêu thích của tôi : đấu vật bằng ngón cái với rất nhiều người chơi .'},\n"," {'en': \"It 's the only game in the world that I know of that allows you , the player , the opportunity to experience 10 positive emotions in 60 seconds or less .\",\n","  'vi': 'Nó là trò chơi duy nhất trên thế giới mà tôi biết sẽ cho phép bạn , người chơi , cơ hội để trải nghiệm 10 cảm xúc tích cực trong 60 giây hoặc ít hơn .'},\n"," {'en': 'This is true , so if you play this game with me today for just one single minute , you will get to feel joy , relief , love , surprise , pride , curiosity , excitement , awe and wonder , contentment , and creativity , all in the span of one minute .',\n","  'vi': 'Điều này là đúng , vì vậy nếu bạn chơi trò chơi này với tôi vào ngày hôm nay trong vòng duy nhất một phút thôi , bạn sẽ có thể cảm thấy niềm vui , nhẹ nhõm , tình yêu , bất ngờ , tự hào , tò mò , hứng thú , ngạc nhiên và băn khoăn , hài lòng , và sáng tạo , Tất cả trong vòng một phút .'},\n"," {'en': \"So this sounds pretty good , right ? Now you 're willing to play .\",\n","  'vi': 'Vì vậy điều này nghe khá thú vị , phải không ? Bây giờ bạn đã sẵn sàng để chơi .'},\n"," {'en': \"In order to teach you this game , I 'm going to need some volunteers to come up onstage really quickly , and we 're going to do a little hands-on demo .\",\n","  'vi': 'Để chỉ cho các bạn trò chơi này , Tôi sẽ cần một số tình nguyện viên nhanh chóng đi lên sân khấu , và chúng ta sẽ làm một bản demo nhỏ .'},\n"," {'en': \"While they 're coming up , I should let you know , this game was invented 10 years ago by an artists ' collective in Austria named Monochrom .\",\n","  'vi': 'Trong khi đợi họ đi lên , tôi sẽ cho bạn biết , trò chơi này được phát minh ra 10 năm về trước bởi một tập thể các nghệ sĩ ở Áo tên là Monochrom .'},\n"," {'en': 'So thank you , Monochrom .',\n","  'vi': 'Rất cảm ơn các bạn , Monochrom .'},\n"," {'en': 'Okay , so most people are familiar with traditional , two-person thumb-wrestling .',\n","  'vi': 'Rồi , thế nên hầu hết mọi người đều quen thuộc với trò chơi truyền thống đấu vật ngón cái dành cho hai người'},\n"," {'en': \"Sunni , let 's just remind them .\",\n","  'vi': 'Sunni , hãy nhắc nhớ họ .'},\n"," {'en': \"One , two , three , four , I declare a thumb war , and we wrestle , and of course Sunni beats me because she 's the best .\",\n","  'vi': 'Một , hai , ba , bốn , tôi tuyên bố chiến tranh ngón tay cái , và chúng ta vật lộn , và tất nhiên Sunni đánh bại tôi vì cô ấy chơi giỏi nhất .'},\n"," {'en': \"Now the first thing about massively multiplayer thumb-wrestling , we 're the gamer generation .\",\n","  'vi': 'Bây giờ điều đầu tiên về đấu vật ngón cái với nhiều người chơi- , chúng ta là thế hệ game thủ .'},\n"," {'en': 'There are a billion gamers on the planet now , so we need more of a challenge .',\n","  'vi': 'Có một tỷ game thủ trên hành tinh ngày nay , Vì vậy , chúng ta cần một thách thức .'},\n"," {'en': 'So the first thing we need is more thumbs .',\n","  'vi': 'Điều đầu tiên chúng ta cần là nhiều ngón cái hơn nữa .'},\n"," {'en': 'So Eric , come on over .', 'vi': 'Vì vậy , Eric , lại đây nào .'},\n"," {'en': 'So we could get three thumbs together , and Peter could join us .',\n","  'vi': 'Chúng ta có thể có ba ngón cái chơi chung với nhau , và Peter có thể tham gia với chúng ta .'},\n"," {'en': \"We could even have four thumbs together , and the way you win is you 're the first person to pin someone else 's thumb .\",\n","  'vi': 'Chúng ta thậm chí có thể chơi với bốn ngón và cách để bạn giành chiến thắng là bạn là người đầu tiên đè lên ngón cái của người khác .'},\n"," {'en': \"This is really important . You can 't , like , wait while they fight it out and then swoop in at the last minute .\",\n","  'vi': 'Điều này rất quan trọng . Bạn không thể , như , chờ đợi họ đánh nhau mệt rồi và sau đó nhảy vào ở phút cuối cùng .'},\n"," {'en': 'That is not how you win .',\n","  'vi': 'Đó là không cách để giành chiến thắng .'},\n"," {'en': 'Ah , who did that ? Eric you did that .',\n","  'vi': 'Ah , người nào đã làm được điều đó thế ? Eric bạn đã làm điều đó .'},\n"," {'en': 'So Eric would have won . He was the first person to pin my thumb .',\n","  'vi': 'Vì vậy , Eric sẽ chiến thắng . Anh ta là người đầu tiên đè ngón cái của tôi .'},\n"," {'en': \"Okay , so that 's the first rule , and we can see that three or four is kind of the typical number of thumbs in a node , but if you feel ambitious , you don 't have to hold back .\",\n","  'vi': 'Rồi , vậy đó là luật chơi đầu tiên , và chúng ta có thể thấy rằng ba hoặc bốn là số ngón cái điển hình trong một nút , nhưng nếu bạn cảm thấy tham vọng , bạn không cần phải kìm nén nó lại .'},\n"," {'en': 'We can really go for it .', 'vi': 'Chúng ta có thể thể hiện ra .'},\n"," {'en': 'So you can see up here .', 'vi': 'Vì vậy , bạn có thể thấy ở đây .'},\n"," {'en': 'Now the only other rule you need to remember is , gamer generation , we like a challenge .',\n","  'vi': 'Bây giờ chỉ một quy tắc khác bạn cần phải nhớ thêm là , thế hệ game thủ , chúng ta thích sự thách thức .'},\n"," {'en': \"I happen to notice you all have some thumbs you 're not using .\",\n","  'vi': 'Tôi đã nhận thấy rằng tất cả các bạn đều có ngón cái chưa được dùng đến .'},\n"," {'en': 'So I think we should kind of get some more involved .',\n","  'vi': 'Vì vậy tôi nghĩ rằng chúng ta nên cho thêm một vài ngón cái nữa tham gia'},\n"," {'en': 'And if we had just four people , we would do it just like this , and we would try and wrestle both thumbs at the same time .',\n","  'vi': 'Và nếu chúng ta đã có chỉ bốn người , chúng ta sẽ làm điều đó như thế này đây , và chúng ta sẽ cố gắng và vật lộn cả hai ngón cái cùng một lúc .'},\n"," {'en': 'Perfect .', 'vi': 'Hoàn hảo .'},\n"," {'en': 'Now , if we had more people in the room , instead of just wrestling in a closed node , we might reach out and try and grab some other people .',\n","  'vi': 'Bây giờ , nếu chúng ta đã có thêm nhiều người trong phòng , thay vì chỉ đấu vật trong một nút đóng , chúng ta có thể vươn ra và cố gắng vớ vào một số người khác .'},\n"," {'en': \"And in fact , that 's what we 're going to do right now .\",\n","  'vi': 'Và trên thực tế , đó là những gì chúng ta sẽ làm ngay bây giờ .'},\n"," {'en': \"We 're going to try and get all , something like , I don 't know , 1,500 thumbs in this room connected in a single node .\",\n","  'vi': 'Chúng ta sẽ thử và lấy hết , một cái gì đó giống như , Tôi không biết nữa , 1.500 ngón cái trong căn phòng này kết nối vào một nút duy nhất .'},\n"," {'en': \"And we have to connect both levels , so if you 're up there , you 're going to be reaching down and reaching up .\",\n","  'vi': 'Và chúng ta phải kết nối cả hai cấp độ , Vì vậy , nếu bạn đang ở trên đó , bạn sẽ vươn lên và cúi xuống .'},\n"," {'en': \"Now — — before we get started -- This is great . You 're excited to play . — before we get started , can I have the slides back up here really quick , because if you get good at this game , I want you to know there are some advanced levels .\",\n","  'vi': 'ngay bây giờ- — trước khi chúng ta bắt đầu-- Điều này là rất tốt . Bạn đang hào hứng để chơi . — trước khi chúng ta bắt đầu , cho phép tôi lướt nhanh qua những slides trên kia , bởi vì nếu bạn tìm thấy hứng thú ở trò chơi này , Tôi muốn bạn biết thêm là có một số mức độ cao cấp nữa .'},\n"," {'en': 'So this is the kind of simple level , right ?',\n","  'vi': 'Vì vậy đây là mức độ đơn giản , phải không ?'},\n"," {'en': 'But there are advanced configurations .',\n","  'vi': 'Nhưng có những dạng nâng cao .'},\n"," {'en': 'This is called the Death Star Configuration .',\n","  'vi': 'Cái này được gọi là cấu hình sao chết .'},\n"," {'en': 'Any Star Wars fans ?',\n","  'vi': 'Có ai là người hâm mộ Star Wars không ?'},\n"," {'en': \"And this one 's called the Möbius Strip .\",\n","  'vi': 'Và cái này gọi là dải Möbius .'},\n"," {'en': 'Any science geeks , you get that one .',\n","  'vi': 'Có nhà khoa học mọt sách nào không , bạn có thể chọn cái này .'},\n"," {'en': 'This is the hardest level . This is the extreme .',\n","  'vi': 'Đây là mức độ khó khăn nhất . Đây là đỉnh của đỉnh .'},\n"," {'en': \"So we 'll stick with the normal one for now , and I 'm going to give you 30 seconds , every thumb into the node , connect the upper and the lower levels , you guys go on down there .\",\n","  'vi': 'bây giờ chúng ta sẽ chọn lấy mức bình thường , và tôi sẽ cho bạn 30 giây , mỗi ngón cái vào các nút , kết nối với phía trên và các cấp thấp hơn , Cậu đi xuống kia .'},\n"," {'en': 'Thirty seconds . Into the network . Make the node .',\n","  'vi': 'Ba mươi giây . Vào mạng lưới . Tạo thành các nút .'},\n"," {'en': \"Stand up ! It 's easier if you stand up .\",\n","  'vi': 'Đứng lên ! Sẽ dễ dàng hơn nếu bạn đứng lên .'},\n"," {'en': 'Everybody , up up up up up !',\n","  'vi': 'Tất cả mọi người , lên lên lên lên lên !'},\n"," {'en': 'Stand up , my friends .', 'vi': 'Đứng dậy , bạn bè của tôi .'},\n"," {'en': 'All right .', 'vi': 'Được rồi .'},\n"," {'en': \"Don 't start wrestling yet .\", 'vi': 'Khoan bắt đầu đấu vật nhé .'},\n"," {'en': 'If you have a free thumb , wave it around , make sure it gets connected .',\n","  'vi': 'Nếu bạn có một ngón cái rảnh rỗi , hãy vẫy nó lên , để đảm bảo rằng nó được kết nối .'},\n"," {'en': 'Okay . We need to do a last-minute thumb check .',\n","  'vi': 'Ok . Chúng ta cần phải làm một kiểm tra ở phút cuối .'},\n"," {'en': 'If you have a free thumb , wave it around to make sure .',\n","  'vi': 'Nếu bạn có một ngón cái rảnh rỗi , hãy vẫy nó lên nhé'},\n"," {'en': 'Grab that thumb !', 'vi': 'Chộp lấy ngón tay cái đó !'},\n"," {'en': 'Reach behind you . There you go .',\n","  'vi': 'Với ra phía sau bạn . Được rồi .'},\n"," {'en': 'Any other thumbs ?', 'vi': 'Có những ngón khác nữa không ?'},\n"," {'en': \"Okay , on the count of three , you 're going to go .\",\n","  'vi': 'Được rồi , đếm đến ba , chúng ta sẽ bắt đầu .'},\n"," {'en': 'Try to keep track . Grab , grab , grab it .',\n","  'vi': 'Cố gắng để theo dõi. chộp , chộp lấy nó .'},\n"," {'en': 'Okay ? One , two , three , go !', 'vi': 'Ok ? Một , hai , ba , đi !'},\n"," {'en': 'Did you win ? You got it ? You got it ? Excellent !',\n","  'vi': 'Bạn đã giành chiến thắng ? Bạn đã có nó chưa ? Có chưa ? Tuyệt vời !'},\n"," {'en': 'Well done . Thank you . Thank you very much .',\n","  'vi': 'Tốt . Cảm ơn bạn . Cảm ơn rất nhiều .'},\n"," {'en': 'All right .', 'vi': 'Được rồi .'},\n"," {'en': \"While you are basking in the glow of having won your first massively multiplayer thumb-wrestling game , let 's do a quick recap on the positive emotions .\",\n","  'vi': 'Trong khi bạn phơi phới dưới hào quang của thắng lợi đầu tiên của trò vật ngón cái với rất đông người , hãy làm điểm sơ lại những cảm xúc tích cực .'},\n"," {'en': 'So curiosity .', 'vi': 'Thật là tò mò .'},\n"," {'en': 'I said \" massively multiplayer thumb-wrestling . \"',\n","  'vi': 'Tôi nói \" vật ngón cái với rất đông người . \"'},\n"," {'en': 'You were like , \" What the hell is she talking about ? \"',\n","  'vi': 'Bạn đã như thể , \" Cô ta đang nói về cái quái gì thế ? \"'},\n"," {'en': 'So I provoked a little curiosity .',\n","  'vi': 'Vì vậy , tôi đã khơi gợi được một chút tò mò .'},\n"," {'en': 'Creativity : it took creativity to solve the problem of getting all the thumbs into the node .',\n","  'vi': 'Sáng tạo : phải sáng tạo để giải quyết vấn đề để nhóm tất cả các ngón tay cái vào các nút .'},\n"," {'en': \"I 'm reaching around and I 'm reaching up .\",\n","  'vi': 'Tôi vươn ra xung quanh và tôi vươn lên trước .'},\n"," {'en': 'So you used creativity . That was great .',\n","  'vi': 'Vì vậy , bạn đã sử dụng sáng tạo.Thật là tuyệt vời .'},\n"," {'en': 'How about surprise ? The actual feeling of trying to wrestle two thumbs at once is pretty surprising .',\n","  'vi': 'Còn về bất ngờ thì sao ? Cảm giác thực tế cố gắng để đấu vật với hai ngón cái cùng một lúc khá là đáng để ngạc nhiên .'},\n"," {'en': 'You heard that sound go up in the room .',\n","  'vi': 'Bạn đã nghe thấy âm thanh đó lan ra khắp phòng .'},\n"," {'en': \"We had excitement . As you started to wrestle , maybe you 're starting to win or this person 's , like , really into it , so you kind of get the excitement going .\",\n","  'vi': 'Chúng ta đã có sự phấn khích . Khi bạn bắt đầu vật lộn , có lẽ bạn đang bắt đầu giành chiến thắng hoặc người này , như thể là , thực sự hào hứng với nó , do đó , bạn có thêm nhiều hứng thú .'},\n"," {'en': 'We have relief . You got to stand up .',\n","  'vi': 'Chúng ta có sự nhẹ nhõm . Bạn phải đứng lên .'},\n"," {'en': \"You 've been sitting for awhile , so the physical relief , getting to shake it out .\",\n","  'vi': 'Bạn đã ngồi một lúc rồi , vì vậy đó là sự nhẹ nhõm về mặt vật lý , rũ bỏ mọi phiền muộn .'},\n"," {'en': 'We had joy . You were laughing , smiling . Look at your faces . This room is full of joy .',\n","  'vi': 'Chúng ta đã có niềm vui . Bạn đã cười to , cười mỉm . Nhìn vào mặt của bạn kìa . Căn phòng này đầy niềm vui .'},\n"," {'en': 'We had some contentment .',\n","  'vi': 'Chúng ta đã có một số sự hài lòng .'},\n"," {'en': \"I didn 't see anybody sending text messages or checking their email while we were playing , so you were totally content to be playing .\",\n","  'vi': 'Tôi không thấy bất cứ ai gửi tin nhắn hoặc kiểm tra email của họ trong khi chơi , Vì vậy , bạn đã hoàn toàn thoải mái khi chơi .'},\n"," {'en': 'The most important three emotions , awe and wonder , we had everybody connected physically for a minute .',\n","  'vi': 'Ba cảm xúc quan trọng nhất , ngạc nhiên và băn khoăn , chúng ta đã có tất cả mọi người kết nối thể chất trong một phút .'},\n"," {'en': 'When was the last time you were at TED and you got to connect physically with every single person in the room ?',\n","  'vi': 'Lần cuối cùng bạn ở TED là khi nào và bạn có kết nối cơ thể với mọi người trong phòng không ?'},\n"," {'en': \"And it 's truly awesome and wondrous .\",\n","  'vi': 'Và đó là thực sự tuyệt vời và tuyệt vời .'},\n"," {'en': 'And speaking of physical connection , you guys know I love the hormone oxytocin , you release oxytocin , you feel bonded to everyone in the room .',\n","  'vi': 'Và nói về kết nối cơ thể , các bạn biết tôi thích nội tiết tố oxytocin , bạn tiết ra oxytocin , bạn cảm thấy được kết nối với tất cả mọi người trong phòng .'},\n"," {'en': \"You guys know that the best way to release oxytocin quickly is to hold someone else 's hand for at least six seconds .\",\n","  'vi': 'Các bạn biết rằng cách tốt nhất để tiết ra oxytocin một cách nhanh chóng là nắm lấy bàn tay của người khác trong ít nhất là sáu giây .'},\n"," {'en': 'You guys were all holding hands for way more than six seconds , so we are all now biochemically primed to love each other . That is great .',\n","  'vi': 'Các bạn đã nắm tay trong hơn sáu giây rồi đấy , Vì vậy , tất cả chúng ta bây giờ đều tràn trề về mặt sinh hoá để yêu mến lẫn nhau . Điều đó thật tuyệt .'},\n"," {'en': 'And the last emotion of pride .',\n","  'vi': 'Và cảm xúc cuối cùng là tự hào .'},\n"," {'en': 'How many people are like me . Just admit it .',\n","  'vi': 'Bao nhiêu người đang như tôi . Hãy thừa nhận nó đi .'},\n"," {'en': 'You lost both your thumbs .',\n","  'vi': 'Bạn mất cả hai ngón cái của mình .'},\n"," {'en': \"It just didn 't work out for you .\",\n","  'vi': 'Nó chỉ là không làm việc cho bạn .'},\n"," {'en': \"That 's okay , because you learned a new skill today .\",\n","  'vi': 'Không sao , bởi vì bạn đã học được một kỹ năng mới vào ngày hôm nay .'},\n"," {'en': 'You learned , from scratch , a game you never knew before .',\n","  'vi': 'Bạn học được , từ đầu , một trò chơi mà bạn không bao giờ biết trước kia .'},\n"," {'en': 'Now you know how to play it . You can teach other people .',\n","  'vi': 'Bây giờ bạn biết làm thế nào để chơi nó rồi đấy . Bạn có thể chỉ cho những người khác .'},\n"," {'en': 'So congratulations .', 'vi': 'Xin chúc mừng'},\n"," {'en': 'How many of you won just won thumb ?',\n","  'vi': 'Bao nhiêu người trong số bạn đã giành chiến thắng ?'},\n"," {'en': 'All right . I have very good news for you .',\n","  'vi': 'Được rồi . Tôi có một tin tốt cho bạn .'},\n"," {'en': 'According to the official rules of massively multiplayer thumb-wrestling , this makes you a grandmaster of the game .',\n","  'vi': 'Theo các quy tắc chính thức của trò vật ngón cái với rất đông người này , Điều này làm bạn trở thành một đại kiện tướng của trò chơi .'},\n"," {'en': \"Because there aren 't that many people who know how to play , we have to kind of accelerate the program more than a game like chess .\",\n","  'vi': 'Vì không có nhiều người biết cách làm thế nào để chơi nó , chúng ta phải tăng tốc chương trình nhiều hơn một trò chơi thông thường như cờ vua .'},\n"," {'en': 'So congratulations , grandmasters .',\n","  'vi': 'Vì vậy , xin chúc mừng , các kiện tướng'},\n"," {'en': 'Win one thumb once , you will become a grandmaster .',\n","  'vi': 'Giành chiến thắng ngón cái một lần , bạn sẽ trở thành một đại kiện tướng .'},\n"," {'en': 'Did anybody win both their thumbs ?',\n","  'vi': 'Có ai đã giành chiến thắng cả hai ngón không ?'},\n"," {'en': 'Yes . Awesome . Okay .', 'vi': 'Có . Tuyệt vời . Ok .'},\n"," {'en': 'Get ready to update your Twitter or Facebook status .',\n","  'vi': 'Chuẩn bị sẵn sàng để cập nhật Twitter hay Facebook nhé .'},\n"," {'en': 'You guys , according to the rules , are legendary grandmasters , so congratulations .',\n","  'vi': 'Các bạn , theo các quy tắc của trò chơi , là những kiện tướng huyền thoại , xin chúc mừng'},\n"," {'en': 'I will just leave you with this tip , if you want to play again .',\n","  'vi': 'Tôi sẽ chỉ bạn một mánh khoé này , nếu bạn muốn chơi lại một lần nữa .'},\n"," {'en': \"The best way to become a legendary grandmaster , you 've got your two nodes going on .\",\n","  'vi': 'Cách tốt nhất để trở thành một đại kiện tướng huyền thoại , bạn đã có hai nút của mình .'},\n"," {'en': 'Pick off the one that looks easiest .',\n","  'vi': 'Chọn ra một cái trông có vẻ đơn giản nhất .'},\n"," {'en': \"They 're not paying attention . They look kind of weak .\",\n","  'vi': 'Họ không chú ý vào trò chơi . Họ trông có vẻ yếu .'},\n"," {'en': 'Focus on that one and do something crazy with this arm .',\n","  'vi': 'Tập trung vào cái đó và làm điều gì đó điên rồ với cánh tay này .'},\n"," {'en': 'As soon as you win , suddenly stop .',\n","  'vi': 'Ngay sau khi bạn giành chiến thắng , đột nhiên ngừng lại .'},\n"," {'en': 'Everybody is thrown off . You go in for the kill .',\n","  'vi': 'Tất cả mọi người sẽ hụt hẫng . Bạn bước vào cuộc chơi đầy khí thế .'},\n"," {'en': \"That 's how you become a legendary grandmaster of massively multiplayer thumb-wrestling .\",\n","  'vi': 'Đó là cách làm thế nào bạn trở thành một đại kiện tướng huyền thoại của trò chơi này .'},\n"," {'en': 'Thank you for letting me teach you my favorite game .',\n","  'vi': 'Cảm ơn các bạn đã cho phép tôi chỉ dẫn mọi người chơi trò chơi yêu thích của mình .'},\n"," {'en': 'Wooo !', 'vi': 'Wooo !'},\n"," {'en': 'Thank you .', 'vi': 'Cảm ơn các bạn .'},\n"," {'en': 'David Byrne : How architecture helped music evolve',\n","  'vi': 'David Byrne : Khi kiến trúc giúp âm nhạc thăng hoa'},\n"," {'en': 'As his career grew , David Byrne went from playing CBGB to Carnegie Hall . He asks : Does the venue make the music ? From outdoor drumming to Wagnerian operas to arena rock , he explores how context has pushed musical innovation .',\n","  'vi': 'Khi sự nghiệp của mình phát triển , David Byrne từ chơi nhạc trong quán CBGB để đến được biểu diễn ở Carnegie Hall . Ông đặt ra một câu hỏi : Địa điểm tổ chức có làm nên âm nhạc ? Từ tiếng trống ngoài trời cho tới những buổi nhạc kịch Wagner và rồi là sân khấu nhạc rock , ông tìm hiểu cách không gian đã giúp thúc đẩy sáng tạo âm nhạc .'},\n"," {'en': 'This is the venue where , as a young man , some of the music that I wrote was first performed .',\n","  'vi': 'Đây là nơi mà , khi còn trẻ , những sáng tác của tôi được lần đầu biểu diễn .'},\n"," {'en': 'It was , remarkably , a pretty good sounding room .',\n","  'vi': 'Đó là một căn phòng có chất lượng âm thanh tuyệt vời .'},\n"," {'en': 'With all the uneven walls and all the crap everywhere , it actually sounded pretty good .',\n","  'vi': 'Trông những bức tường thì lồi lõm và có vẻ vớ vẩn thật đấy , nhưng âm thanh thực sự là rất tốt .'},\n"," {'en': 'This is a song that was recorded there .',\n","  'vi': 'Đây là một bản nhạc được thu âm lại trong căn phòng này .'},\n"," {'en': 'This is not Talking Heads , in the picture anyway .',\n","  'vi': 'Trong bức hình này không phải là ban nhạc Talking Heads .'},\n"," {'en': '\" by Talking Heads ) So the nature of the room meant that words could be understood .',\n","  'vi': '\" trình bày bởi Talking Heads ) Vậy là tính chất của cái phòng đã giúp truyền tải ngôn từ tới người nghe .'},\n"," {'en': 'The lyrics of the songs could be pretty much understood .',\n","  'vi': 'Lời bài hát rất dễ hiểu .'},\n"," {'en': 'The sound system was kind of decent .',\n","  'vi': 'Hệ thống âm thanh rất tốt .'},\n"," {'en': \"And there wasn 't a lot of reverberation in the room .\",\n","  'vi': 'Không có nhiều phản âm trong căn phòng .'},\n"," {'en': 'So the rhythms could be pretty intact too , pretty concise .',\n","  'vi': 'Vậy nên nhịp điệu của bài nhạc được giữ lại khá trọn vẹn , rất ngắn gọn .'},\n"," {'en': 'Other places around the country had similar rooms .',\n","  'vi': 'Có nhiều căn phòng cũng tương tự trên đất nước này .'},\n"," {'en': \"This is Tootsie 's Orchid Lounge in Nashville .\",\n","  'vi': 'Đây là Orchid Lounge ở Tootsie ở Nashville .'},\n"," {'en': 'The music was in some ways different , but in structure and form , very much the same .',\n","  'vi': 'Âm nhạc trong căn phòng này có vài phần khác biệt , nhưng xét về cấu trúc và chỉnh thể , chúng khá giống nhau .'},\n"," {'en': 'The clientele behavior was very much the same too .',\n","  'vi': 'Hành xử của người nghe cũng khá giống .'},\n"," {'en': \"And so the bands at Tootsie 's or at CBGB 's had to play loud enough -- the volume had to be loud enough to overcome people falling down , shouting out and doing whatever else they were doing .\",\n","  'vi': \"Những ban nhạc biểu diễn ở Tootsie 's hay CBGB 's đều phải chơi với âm lượng đủ lớn -- sao cho có thể át được tiếng mọi người nhảy múa , gào thét hay làm bất cứ điều gì mà họ đang làm .\"},\n"," {'en': \"Since then , I 've played other places that are much nicer .\",\n","  'vi': 'Kể từ đó , tôi đã chơi nhạc ở nhiều nơi khác với chất lượng tốt hơn .'},\n"," {'en': \"I 've played the Disney Hall here and Carnegie Hall and places like that .\",\n","  'vi': 'Tôi đã chơi trong hội trường Disney và hội trường Carnegie và những nơi tương tự .'},\n"," {'en': \"And it 's been very exciting .\", 'vi': 'Tất cả đều rất thú vị .'},\n"," {'en': \"But I also noticed that sometimes the music that I had written , or was writing at the time , didn 't sound all that great in some of those halls .\",\n","  'vi': 'Nhưng tôi cũng để ý rằng đôi khi những sáng tác mà tôi đã viết , hay đang viết tại thời điểm đó , nghe chẳng hay ho đến vậy ở một vài hội trường nhất định .'},\n"," {'en': \"We managed , but sometimes those halls didn 't seem exactly suited to the music I was making or had made .\",\n","  'vi': 'Chúng tôi đã cố gắng hết sức , nhưng đôi khi những hội trường đó không thực sự phù hợp với loại âm nhạc mà tôi đang viết hay đã viết .'},\n"," {'en': 'So I asked myself : Do I write stuff for specific rooms ?',\n","  'vi': 'Vậy nên tôi tự hỏi bản thân mình Tôi có viết nhạc cho những phòng biểu diễn nhất định ?'},\n"," {'en': 'Do I have a place , a venue , in mind when I write ?',\n","  'vi': 'Trong đầu tôi liệu có một địa điểm , một không gian , cụ thể khi tôi viết nhạc ?'},\n"," {'en': 'Is that a kind of model for creativity ?',\n","  'vi': 'Có phải đó là một mô hình sáng tạo ?'},\n"," {'en': 'Do we all make things with a venue , a context , in mind ?',\n","  'vi': 'Có phải chúng ta sáng tạo nên mọi thứ với một địa điểm , một bối cảnh nhất định trong đầu ?'},\n"," {'en': 'Okay , Africa .', 'vi': 'Lấy ví dụ , châu Phi .'},\n"," {'en': 'Most of the popular music that we know now has a big part of its roots in West Africa .',\n","  'vi': 'Đa phần âm nhạc mà chúng ta biết ngày nay có cội nguồn từ Tây Phi .'},\n"," {'en': \"And the music there , I would say , the instruments , the intricate rhythms , the way it 's played , the setting , the context , it 's all perfect . It all works perfect .\",\n","  'vi': 'Và âm nhạc ở đó , tôi cho rằng , những nhạc cụ , và những nhịp điệu rắc rối , cái cách mà âm nhạc được chơi , bối cảnh , không gian , tất cả đều hoàn hảo . Tất cả phải phối hợp nhịp nhàng với nhau .'},\n"," {'en': 'The music works perfectly in that setting .',\n","  'vi': 'Và âm nhạc cất lên tuyệt hảo trong bối cảnh nhất định đó .'},\n"," {'en': \"There 's no big room to create reverberation and confuse the rhythms .\",\n","  'vi': 'Ở đó chẳng có căn phòng lớn nào để mà có sự dội lại âm thanh khiến nhịp điệu bị rối loạn .'},\n"," {'en': 'The instruments are loud enough that they can be heard without amplification , etc . , etc .',\n","  'vi': 'Nhạc cụ đủ vang để có thể nghe thấy được mà không cần khuếch đại âm thanh , vân vân .'},\n"," {'en': \"It 's no accident .\", 'vi': 'Đó chẳng phải là một sự tình cờ .'},\n"," {'en': \"It 's perfect for that particular context .\",\n","  'vi': 'Thứ âm thanh này hoàn hảo trong bối cảnh nhất định đó .'},\n"," {'en': 'And it would be a mess in a context like this . This is a gothic cathedral .',\n","  'vi': 'Và nó sẽ hỏng cả nếu đặt vào địa điểm như thế này . Đây là một nhà thờ kiểu gothic .'},\n"," {'en': 'In a gothic cathedral , this kind of music is perfect .',\n","  'vi': 'Trong một nhà thờ gothic , thứ âm nhạc này mới là hoàn hảo .'},\n"," {'en': \"It doesn 't change key , the notes are long , there 's almost no rhythm whatsoever , and the room flatters the music .\",\n","  'vi': 'Những nốt nhạc không đổi , kéo dài. gần như chẳng có nhịp điệu gì , và căn phòng giúp làm tôn lên âm nhạc .'},\n"," {'en': 'It actually improves it .',\n","  'vi': 'Và không gian ấy thực sự giúp cải thiện thật .'},\n"," {'en': 'This is the room that Bach wrote some of his music for . This is the organ .',\n","  'vi': 'Đây là căn phòng mà Bach viết một số bản nhạc . Đây là chiếc đàn organ .'},\n"," {'en': \"It 's not as big as a gothic cathedral , so he can write things that are a little bit more intricate .\",\n","  'vi': 'Nó không lớn như chiếc trong nhà thờ gothic , vậy nên Bach có thể viết nên thứ âm nhạc có phần phức tạp hơn .'},\n"," {'en': 'He can , very innovatively , actually change keys without risking huge dissonances .',\n","  'vi': 'Ông ấy có thể , một cách rất sáng tạo , thay đổi gam nhạc mà không mạo hiểm gây ra sự nhiễu âm .'},\n"," {'en': 'This is a little bit later .',\n","  'vi': 'Còn đây là vào thời đại ít lâu sau đó .'},\n"," {'en': 'This is the kind of rooms that Mozart wrote in .',\n","  'vi': 'Đây là kiểu căn phòng mà tại đó Mozart đã viết nhạc .'},\n"," {'en': \"I think we 're in like 1770 , somewhere around there .\",\n","  'vi': 'Tôi nghĩ rằng đó là vào khoảng năm 1770 .'},\n"," {'en': \"They 're smaller , even less reverberant , so he can write really frilly music that 's very intricate -- and it works .\",\n","  'vi': 'Những căn phòng như thế này nhỏ hẹp hơn , ít có sự dội âm hơn , thế nên Mozart có thể viết nên thứ âm nhạc khá rườm rà khá phức tạp - và nó thực sự rất tuyệt .'},\n"," {'en': 'It fits the room perfectly .',\n","  'vi': 'Nó phù hợp hoàn hảo với căn phòng .'},\n"," {'en': 'This is La Scala .', 'vi': 'Và đây là La Scala .'},\n"," {'en': \"It 's around the same time , I think it was built around 1776 .\",\n","  'vi': 'cũng gần vào thời kỳ này , tôi nghĩ nó được xây dựng vào khoảng năm 1776 .'},\n"," {'en': 'People in the audience in these opera houses , when they were built , they used to yell out to one another .',\n","  'vi': 'Khán giả trong những nhà hát này , vào thời điểm chúng được xây dựng , họ thường hò hét với nhau .'},\n"," {'en': \"They used to eat , drink and yell out to people on the stage , just like they do at CBGB 's and places like that .\",\n","  'vi': 'Họ ăn uống và gào thét với những người đang biểu diễn trên sàn diễn , cũng giống như những khán giả ở CBGB hay những nơi tương tự .'},\n"," {'en': 'If they liked an aria , they would holler and suggest that it be done again as an encore , not at the end of the show , but immediately .',\n","  'vi': 'Nếu họ thích một bản nhạc , họ sẽ kêu la và yêu cầu bản nhạc được chơi lại , không chờ tới cuối buổi biểu diễn , mà phải là ngay lập tức kia .'},\n"," {'en': 'And well , that was an opera experience .',\n","  'vi': 'Và thực ra đó là một trải nghiệm ở một buổi nhạc kịch .'},\n"," {'en': 'This is the opera house that Wagner built for himself .',\n","  'vi': 'Đây là nhà hát kịch mà Wagner đã tự xây cho chính mình .'},\n"," {'en': 'And the size of the room is not that big .',\n","  'vi': 'Kích cỡ của căn phòng không to tới mức này .'},\n"," {'en': \"It 's smaller than this .\", 'vi': 'Nó nhỏ hơn thế .'},\n"," {'en': 'But Wagner made an innovation .', 'vi': 'Nhưng Wagner đã cải tiến .'},\n"," {'en': 'He wanted a bigger band .',\n","  'vi': 'Ông ấy muốn có một ban nhạc lớn hơn .'},\n"," {'en': 'He wanted a little more bombast , so he increased the size of the orchestra pit so he could get more low-end instruments in there .',\n","  'vi': 'Ông ấy muốn có thêm sự hoành tráng , vậy nên ông ấy tăng kích cỡ của khu vực cho dàn nhạc để có thể đưa thêm vào những nhạc cụ khác .'},\n"," {'en': 'Okay .', 'vi': 'Vậy rồi ,'},\n"," {'en': 'This is Carnegie Hall .', 'vi': 'đây là hội trường Carnegie .'},\n"," {'en': 'Obviously , this kind of thing became popular .',\n","  'vi': 'Rõ ràng là , những căn phòng rộng lớn trở nên được ưa chuộng hơn .'},\n"," {'en': \"The halls got bigger . Carnegie Hall 's fair-sized .\",\n","  'vi': 'Những hội trường càng này càng được mở rộng . Kích cỡ của hội trường Carnegie khá vừa phải .'},\n"," {'en': \"It 's larger than some of the other symphony halls .\",\n","  'vi': 'Nó lớn hơn một vài hội trường nhạc giao hưởng .'},\n"," {'en': \"And they 're a lot more reverberant than La Scala .\",\n","  'vi': 'Và chúng gây nên nhiều dội âm hơn nhiều so với La Scala .'},\n"," {'en': 'Around the same , according to Alex Ross who writes for the New Yorker , this kind of rule came into effect that audiences had to be quiet -- no more eating , drinking and yelling at the stage , or gossiping with one another during the show .',\n","  'vi': 'Có kích cỡ tương tự , theo như Alex Ross , phóng viên cho tờ New Yorker , một điều luật không lời bắt đầu hình thành đó là khán giả phải giữ yên lặng -- không còn ăn , uống , hò hét ở sân khấu , hay tán gẫu với nhau trong suốt buổi biểu diễn .'},\n"," {'en': 'They had to be very quiet .',\n","  'vi': 'Khán giả phải thực sự yên tĩnh .'},\n"," {'en': 'So those two things combined meant that a different kind of music worked best in these kind of halls .',\n","  'vi': 'Hai thứ này kết hợp với nhau mang đến một thứ âm nhạc khác một thứ âm nhạc mới để phù hợp với kiểu hội trường này .'},\n"," {'en': \"It meant that there could be extreme dynamics , which there weren 't in some of these other kinds of music .\",\n","  'vi': 'Điều đó có nghĩa rằng giờ đây có thể tạo nên thứ âm nhạc , vốn không thể tồn tại trong những loại nhạc trước đó .'},\n"," {'en': 'Quiet parts could be heard that would have been drowned out by all the gossiping and shouting .',\n","  'vi': 'Những khoảng lặng có thể được lắng nghe mà đáng lẽ ra trước kia sẽ bị nhấn chìm bởi những lời tán gẫu và hò hét .'},\n"," {'en': 'But because of the reverberation in those rooms like Carnegie Hall , the music had to be maybe a little less rhythmic and a little more textural .',\n","  'vi': 'Thế nhưng bởi vì sự dội âm trong những căn phòng như hội trường Carnegie , âm nhạc luôn luôn phải có ít nhịp điệu hơn và có thêm kết cấu phức tạp .'},\n"," {'en': 'This is Mahler .', 'vi': 'Đây là Mahler .'},\n"," {'en': \"It looks like Bob Dylan , but it 's Mahler .\",\n","  'vi': 'Có thể bạn tưởng đó là Bob Dylan , nhưng thực ra là Mahler .'},\n"," {'en': \"That was Bob 's last record , yeah .\",\n","  'vi': 'Và đó là bản thu âm gần nhất của Bob , đúng vậy .'},\n"," {'en': 'Popular music , coming along at the same time .',\n","  'vi': 'Nhạc pop , xuất hiện cùng vào thời kỳ này .'},\n"," {'en': 'This is a jazz band .', 'vi': 'Đây là một ban nhạc jazz .'},\n"," {'en': 'According to Scott Joplin , the bands were playing on riverboats and clubs .',\n","  'vi': 'Theo như Scott Joplin , các ban nhạc chơi trên những chiếc thuyền và trong các câu lạc bộ .'},\n"," {'en': \"Again , it 's noisy . They 're playing for dancers .\",\n","  'vi': 'Đúng vậy , ồn ào lắm . Họ đang chơi nhạc cho người ta nhảy theo .'},\n"," {'en': \"There 's certain sections of the song -- the songs had different sections that the dancers really liked .\",\n","  'vi': 'Có những trường đoạn nhất định trong bản nhạc -- bản nhạc có nhiều phần khác nhau -- mà những người nhảy thực sự yêu thích .'},\n"," {'en': 'And they \\'d say , \" Play that part again . \"',\n","  'vi': 'Và họ sẽ nói , \" Hãy chơi lại đoạn nhạc đó đi . \"'},\n"," {'en': \"Well , there 's only so many times you can play the same section of a song over and over again for the dancers .\",\n","  'vi': 'Và đương nhiên , bạn chỉ có thể chơi đi chơi lại một đoạn nhạc cho những người trên sàn nhảy bằng ấy lần .'},\n"," {'en': 'So the bands started to improvise new melodies .',\n","  'vi': 'Vậy nên các ban nhạc bắt đầu sáng tác nên những giai đoạn mới .'},\n"," {'en': 'And a new form of music was born .',\n","  'vi': 'Và một loại hình âm nhạc mới ra đời .'},\n"," {'en': 'These are played mainly in small rooms .',\n","  'vi': 'Những bản nhạc như thế này được chơi trong những căn phòng nhỏ .'},\n"," {'en': 'People are dancing , shouting and drinking .',\n","  'vi': 'Mọi người nhảy múa , hò hét , uống rượu .'},\n"," {'en': 'So the music has to be loud enough to be heard above that .',\n","  'vi': 'Vậy nên âm nhạc phải đủ vang để có thể át những tiếng ồn đó .'},\n"," {'en': \"Same thing goes true for -- that 's the beginning of the century -- for the whole of 20th-century popular music , whether it 's rock or Latin music or whatever .\",\n","  'vi': 'Đó là đầu thế kỉ 20 , và điều tương tự cũng xảy ra với nền âm nhạc của cả thế kỷ 20 , bất kể đó là nhạc rock , nhạc Latin hay gì khác nữa .'},\n"," {'en': \"[ Live music ] doesn 't really change that much .\",\n","  'vi': '[ Nhạc sống ] không thay đổi nhiều tới mức đó .'},\n"," {'en': 'It changes about a third of the way into the 20th century , when this became one of the primary venues for music .',\n","  'vi': 'Nó thay đổi khi thế kỷ 20 đi được khoảng 1 / 3 chặng đường , khi những căn phòng nhỏ như thế này trở thành những địa điểm chính tổ chức âm nhạc'},\n"," {'en': 'And this was one way that the music got there .',\n","  'vi': 'Và đây là một cách khiến cho âm nhạc thay đổi được như vậy .'},\n"," {'en': 'Microphones enabled singers , in particular , and musicians and composers , to completely change the kind of music that they were writing .',\n","  'vi': 'Micrô giúp cho đặc biệt là ca sĩ cũng như nhạc công và nhạc sĩ , thay đổi hoàn toàn phong cách âm nhạc mà họ đang viết .'},\n"," {'en': 'So far , a lot of the stuff that was on the radio was live music , but singers , like Frank Sinatra , could use the mic and do things that they could never do without a microphone .',\n","  'vi': 'Cho tới nay , đa phần những thứ được phát trên đài là nhạc sống , nhưng những ca sĩ , như Frank Sinatra , có thể dùng micrô để làm những việc mà trước đó họ không thể làm nếu thiếu micrô .'},\n"," {'en': 'Other singers after him went even further .',\n","  'vi': 'Những ca sĩ khác sau đó còn tiến xa hơn .'},\n"," {'en': 'This is Chet Baker .', 'vi': 'Đây là Chet Baker .'},\n"," {'en': 'And this kind of thing would have been impossible without a microphone .',\n","  'vi': 'Và thứ âm nhạc này không thể thành hiện thực nếu không có micrô .'},\n"," {'en': 'It would have been impossible without recorded music as well .',\n","  'vi': 'Và nó cũng không thể thành hiện thực nếu không có công nghệ thu âm .'},\n"," {'en': \"And he 's singing right into your ear .\",\n","  'vi': 'Và anh ta hát ngay vào tai bạn .'},\n"," {'en': \"He 's whispering into your ears .\",\n","  'vi': 'Anh ta thì thầm vào tai bạn .'},\n"," {'en': 'The effect is just electric .',\n","  'vi': 'Hiệu ứng của nó là không ngờ .'},\n"," {'en': \"It 's like the guy is sitting next to you , whispering who knows what into your ear .\",\n","  'vi': 'Cứ như thể là chàng ca sĩ đang ngồi ngay cạnh bạn , thì thầm điều gì đó vào tai bạn .'},\n"," {'en': 'So at this point , music diverged .',\n","  'vi': 'Và thế là , tại thời điểm này , âm nhạc chia làm hai hướng .'},\n"," {'en': \"There 's live music , and there 's recorded music .\",\n","  'vi': 'Nhạc sống , và nhạc thu âm .'},\n"," {'en': 'And they no longer have to be exactly the same .',\n","  'vi': 'Và chúng không còn hoàn toàn giống nhau nữa .'},\n"," {'en': \"Now there 's venues like this , a discotheque , and there 's jukeboxes in bars , where you don 't even need to have a band .\",\n","  'vi': 'Thế là có những địa điểm như thế này , một vũ trường , hay là những máy hát tự động trong quán bar , nơi mà bạn chằng cần có ban nhạc sống .'},\n"," {'en': \"There doesn 't need to be any live performing musicians whatsoever , and the sound systems are good .\",\n","  'vi': 'Chẳng cần có bất kỳ một nhạc công nào cả , và hệ thống âm thanh thì đủ tốt .'},\n"," {'en': 'People began to make music specifically for discos and for those sound systems .',\n","  'vi': 'Mọi người bắt đầu tự viết nhạc đặc biệt là cho các vũ trường và các hệ thống âm thanh đó .'},\n"," {'en': 'And , as with jazz , the dancers liked certain sections more than they did others .',\n","  'vi': 'Và , như với nhạc jazz , những người nhảy yêu thích một vài đoạn nhạc nhất định hơn là những đoạn nhạc khác .'},\n"," {'en': 'So the early hip-hop guys would loop certain sections .',\n","  'vi': 'Vậy nên những ca sĩ nhạc hip hop thời kỳ đầu sẽ lặp đi lặp lại một số đoạn nhất định .'},\n"," {'en': 'The MC would improvise lyrics in the same way that the jazz players would improvise melodies .',\n","  'vi': 'MC sẽ ứng tấu lời bài hát theo cái cách tương tự với nhạc jazz khi họ ứng tấu nhạc điệu .'},\n"," {'en': 'And another new form of music was born .',\n","  'vi': 'Và một loại hình nhạc mới ra đời .'},\n"," {'en': 'Live performance , when it was incredibly successful , ended up in what is probably , acoustically , the worst sounding venues on the planet : sports stadiums , basketball arenas and hockey arenas .',\n","  'vi': 'Nhạc sống , khi mà nó cực kỳ thành công , rút cục lại rơi vào , có lẽ là , xét về mặt âm thanh , những không gian âm thanh tệ hại nhất trên hành tinh này : các khán đài thể thao , những trận bóng rổ và khúc côn cầu .'},\n"," {'en': 'Musicians who ended up there did the best they could .',\n","  'vi': 'Nhạc công thế là buộc phải cố gắng làm tốt nhất họ có thể .'},\n"," {'en': 'They wrote what is now called arena rock , which is medium-speed ballads .',\n","  'vi': 'Họ viết nên ca khúc mà giờ người ta gọi là nhạc rock trên vũ đài mà thực ra chính là các bản ballad tốc độ trung bình .'},\n"," {'en': \"They did the best they could given that this is what they 're writing for .\",\n","  'vi': 'Họ cố gắng hết sức bởi vì đây là nơi âm nhạc của họ sẽ được biểu diễn .'},\n"," {'en': 'The tempos are medium . It sounds big .',\n","  'vi': 'Tốc độ vừa phải . Âm lượng lớn .'},\n"," {'en': \"It 's more a social situation than a musical situation .\",\n","  'vi': 'Âm nhạc giờ đây được đặt trong một bối cảnh xã hội hơn là một bối cảnh âm điệu .'},\n"," {'en': \"And in some ways , the music that they 're writing for this place works perfectly .\",\n","  'vi': 'Và theo một vài cách nào đó , thứ âm nhạc mà họ viết cho những địa điểm như thế này lại vừa vặn phù hợp .'},\n"," {'en': \"So there 's more new venues .\",\n","  'vi': 'Vậy chúng ta thấy đó là ngày càng có những địa điểm mới cho âm nhạc .'},\n"," {'en': 'One of the new ones is the automobile .',\n","  'vi': 'Một trong những địa điểm đó là trong xe hơi .'},\n"," {'en': 'I grew up with a radio in a car .',\n","  'vi': 'Tôi lớn lên cái thời mà những chiếc xe ô tô đã có gắn đài .'},\n"," {'en': \"But now that 's evolved into something else .\",\n","  'vi': 'Thế nhưng giờ thứ âm nhạc đó đang phát triển thêm .'},\n"," {'en': 'The car is a whole venue .',\n","  'vi': 'Chiếc xe là một không gian hoàn toàn mới .'},\n"," {'en': 'The music that , I would say , is written for automobile sound systems works perfectly on it .',\n","  'vi': 'Thứ âm nhạc mà , tôi cho rằng , được viết cho hệ thống âm thanh trong xe ô tô thực sự rất hợp .'},\n"," {'en': 'It might not be what you want to listen to at home , but it works great in the car -- has a huge frequency spectrum , you know , big bass and high-end and the voice kind of stuck in the middle .',\n","  'vi': 'Đó có lẽ không phải là thứ nhạc bạn sẽ nghe khi ở nhà , nhưng nó trở nên hoàn hảo trong những chiếc xe -- nó có tần số cao , bạn biết đấy , bass lớn và chất giọng có vẻ như lơ lửng ở giữa .'},\n"," {'en': 'Automobile music , you can share with your friends .',\n","  'vi': 'Âm nhạc của xe hơi , bạn có thể chia sẻ với bạn bè .'},\n"," {'en': \"There 's one other kind of new venue , the private MP3 player .\",\n","  'vi': 'Có một địa điểm mới của âm nhạc nữa , đó là chiếc máy nghe nhạc cá nhân MP3 .'},\n"," {'en': 'Presumably , this is just for Christian music .',\n","  'vi': 'Có lẽ , nó chỉ dành cho nhạc Công giáo .'},\n"," {'en': \"And in some ways it 's like Carnegie Hall , or when the audience had to hush up , because you can now hear every single detail .\",\n","  'vi': 'Và xét trên một vài phương diện , nó giống như hội trường Carnegie , hay khi mà khán giả phải yên lặng , bởi vì giờ đây bạn có thể lắng nghe từng chi tiết nhỏ .'},\n"," {'en': \"In other ways , it 's more like the West African music because if the music in an MP3 player gets too quiet , you turn it up , and the next minute , your ears are blasted out by a louder passage .\",\n","  'vi': 'Nói theo cách khác , nó giống với âm nhạc Tây Phi bởi vì nếu âm thanh trong chiếc MP3 quá yên tĩnh , bạn tăng âm lượng lên , và chỉ trong một phút sau , tai của bạn bị nhập tràn bởi một trường đoạn ầm ĩ hơn nhiều .'},\n"," {'en': \"So that doesn 't really work .\",\n","  'vi': 'Thế nên âm nhạc không thể chạy theo cách đó .'},\n"," {'en': \"I think pop music , mainly , it 's written today , to some extent , is written for these kind of players , for this kind of personal experience where you can hear extreme detail , but the dynamic doesn 't change that much .\",\n","  'vi': 'Tôi nghĩ nhạc pop , hầu như , được viết ngày nay , ở một mức độ nào đó , được viết dành cho những loại máy nghe nhạc này , cho loại trải nghiệm cá nhân như thế này khi mà bạn có thể lắng nghe từng chi tiết nhỏ một , thế nhưng sự sống động không thay đổi quá nhiều .'},\n"," {'en': 'So I asked myself : Okay , is this a model for creation , this adaptation that we do ?',\n","  'vi': 'Vậy nên tôi tự hỏi bản thân : Thôi được , vậy thì có phải đây là một mô hình cho sự sáng tạo , có phải đây là một sự thích ứng của chúng ta ?'},\n"," {'en': 'And does it happen anywhere else ?',\n","  'vi': 'Và nó còn xảy ra ở đâu nữa ?'},\n"," {'en': 'Well , according to David Attenborough and some other people , birds do it too -- that the birds in the canopy , where the foliage is dense , their calls tend to be high-pitched , short and repetitive .',\n","  'vi': 'Theo David Attenborough và một vài người khác , loài chim cũng có sự thay đổi như vậy , loài chim ở dưới tán cây , nơi mà tán lá dày đặc , tiếng gọi của chúng có xu hướng có cao độ cao , ngắn và hay lặp đi lặp lại .'},\n"," {'en': \"And the birds on the floor tend to have lower pitched calls , so that they don 't get distorted when they bounce off the forest floor .\",\n","  'vi': 'Những chú chim ở gần mặt đất có tiếng hót trầm hơn , để âm thanh không bị bóp méo khi nó va chạm vào nền đất trong rừng .'},\n"," {'en': 'And birds like this Savannah sparrow , they tend to have a buzzing type call .',\n","  'vi': 'Những loài chim như chim sẻ Savannah , chúng có tiếng rì rầm , vù vù .'},\n"," {'en': 'And it turns out that a sound like this is the most energy efficient and practical way to transmit their call across the fields and savannahs .',\n","  'vi': 'Và hoá ra là âm thanh như vậy là cách tiết kiệm năng lượng và hiệu quả nhất để truyền tải tiếng gọi của chúng xuyên qua những cánh đồng và rặng savannahs .'},\n"," {'en': 'Other birds , like this tanager , have adapted within the same species .',\n","  'vi': 'Những loài chim khác , như loài tanager , cũng thích ứng ngay trong loài của chúng .'},\n"," {'en': 'The tananger on the East Coast of the United States , where the forests are a little denser , has one kind of call , and the tananger on the other side , on the west has a different kind of call .',\n","  'vi': 'Loài tanager ở bờ Đông nước Mỹ , khi rừng có phần rậm rạp hơn , có tiếng hót khác so với loài tananger ở phía bên kia , phía tây vậy là chúng rất khác nhau .'},\n"," {'en': 'So birds do it too .',\n","  'vi': 'Vậy là chim cũng có sự thay đổi như vậy .'},\n"," {'en': 'And I thought : Well , if this is a model for creation , if we make music , primarily the form at least , to fit these contexts , and if we make art to fit gallery walls or museum walls , and if we write software to fit existing operating systems , is that how it works ?',\n","  'vi': 'Và tôi nghĩ , Chà , vậy nếu đây là một mô hình sáng tạo , nếu chúng ta tạo nên âm nhạc , ít nhất là về mặt cấu trúc , để phù hợp với bối cảnh , và nếu ta sáng tạo ra nghệ thuật cho hợp với bức tường của những phòng triển lãm hay bảo tàng và nếu chúng ta viết các phầm mềm cho hợp với những hệ điều hành hiện tại , đó có phải là cách mọi thứ diễn ra ?'},\n"," {'en': \"Yeah . I think it 's evolutionary .\",\n","  'vi': 'Vâng . Tôi cho rằng đó là sự tiến bộ .'},\n"," {'en': \"It 's adaptive .\", 'vi': 'Đó là sự thích ứng .'},\n"," {'en': 'But the pleasure and the passion and the joy is still there .',\n","  'vi': 'Thế nhưng niềm vui thích , niềm đam mê và hạnh phúc vẫn tồn tại ở đó .'},\n"," {'en': 'This is a reverse view of things from the kind of traditional Romantic view .',\n","  'vi': 'Đây là một cách nhìn nhận sự việc hơi ngược so với cái nhin Lãng mạn thông thường .'},\n"," {'en': 'The Romantic view is that first comes the passion and then the outpouring of emotion , and then somehow it gets shaped into something .',\n","  'vi': 'Quan điểm Lãng mạn là đam mê là thứ đến đầu tiên và sau đó là sự dâng trào của cảm xúc , và cuối cùng hình thù mới được tạo nên .'},\n"," {'en': \"And I 'm saying , well , the passion 's still there , but the vessel that it 's going to be injected into and poured into , that is instinctively and intuitively created first .\",\n","  'vi': 'Và tôi thì đang nỏi rằng , vâng , sự đam mê vẫn có ở đó , nhưng chiếc bình kia cái thứ mà đam mê sẽ được tiêm vào , đổ vào đó , thực ra mới là thứ , một cách bản năng và vô thức , được tạo ra trước .'},\n"," {'en': 'We already know where that passion is going .',\n","  'vi': 'Chúng ta biết sẵn rằng đam mê đó sẽ đi về đâu .'},\n"," {'en': 'But this conflict of views is kind of interesting .',\n","  'vi': 'Nhưng sự đối nghịch trong quan điểm này khá thú vị .'},\n"," {'en': \"The writer , Thomas Frank , says that this might be a kind of explanation why some voters vote against their best interests , that voters , like a lot of us , assume , that if they hear something that sounds like it 's sincere , that it 's coming from the gut , that it 's passionate , that it 's more authentic .\",\n","  'vi': 'Nhà văn , Thomas Frank , nói rằng có lẽ đó là một cách giải thích tại sao một số cử tri đối nghịch với những lợi ích của họ , những cử tri , như rất nhiều người trong chúng ta , giả định rằng , nếu họ nghe thấy một thứ gì có vẻ thật thà , thứ gì đến từ ruột gan , nếu nó đầy nhiệt huyết , đam mê , thì tức là nó đáng tin cậy hơn .'},\n"," {'en': \"And they 'll vote for that .\",\n","  'vi': 'Và họ sẽ bầu cho những thứ như thế .'},\n"," {'en': 'So that , if somebody can fake sincerity , if they can fake passion , they stand a better chance which seems a little dangerous .',\n","  'vi': 'Vậy là , nếu ai đó có thể làm giả sự thành thật , nếu họ có thể làm giả đam mê , họ có cơ hội được chọn Điều này nghe thật nguy hiểm .'},\n"," {'en': \"I 'm saying the two , the passion , the joy , are not mutually exclusive .\",\n","  'vi': 'Ý của tôi là hai thứ , niềm đam mê , và sự yêu thích , không phải hoàn toàn tách biệt nhau .'},\n"," {'en': 'Maybe what the world needs now is for us to realize that we are like the birds .',\n","  'vi': 'Có lẽ điều mà thế giới cần lúc này đó là nhận ra chúng ta cũng như những loài chim .'},\n"," {'en': 'We adapt .', 'vi': 'Chúng ta thích ứng .'},\n"," {'en': 'We sing .', 'vi': 'Chúng ta hát .'},\n"," {'en': 'And like the birds , the joy is still there , even though we have changed what we do to fit the context .',\n","  'vi': 'Và như loài chim , niềm yêu thích vẫn ở đó , mặc dù chúng ta đã thay đổi cách cái cách mà chúng ta làm để phù hợp với hoàn cảnh .'},\n"," {'en': 'Thank you very much .', 'vi': 'Cảm ơn vì đã lắng nghe .'},\n"," {'en': 'Kevin Breel : Confessions of a depressed comic',\n","  'vi': 'Kevin Breel : Những thú nhận của một nghệ sĩ hài bị trầm cảm'},\n"," {'en': \"Kevin Breel didn 't look like a depressed kid : team captain , at every party , funny and confident . But he tells the story of the night he realized that -- to save his own life -- he needed to say four simple words .\",\n","  'vi': 'Kevin Breel trông không giống gì là một cậu trai trầm cảm : là trưởng đội thể thao , tham dự mọi tiệc tùng , khôi hài và tự tin . Nhưng khi cậu kể câu chuyện của một đêm nọ , khi cậu nhận ra rằng -- để cứu chính cuộc đời mình -- cậu cần nói được bốn từ đơn giản .'},\n"," {'en': \"For a long time in my life , I felt like I 'd been living two different lives .\",\n","  'vi': 'Gần như suốt cuộc đời của mình tôi cảm thấy mình đang sống hai cuộc sống khác nhau'},\n"," {'en': \"There 's the life that everyone sees , and then there 's the life that only I see .\",\n","  'vi': 'Có một cuộc sống mà mọi người nhìn thấy , và một cuộc sống khác chỉ có bản thân tôi thấy .'},\n"," {'en': 'And in the life that everyone sees , who I am is a friend , a son , a brother , a stand-up comedian and a teenager .',\n","  'vi': 'Và trong cuộc sống mà mọi người nhìn thấy , tôi là một người bạn , một người con trai , một người anh , một diễn viên châm biếm hài hước và là một thanh niên .'},\n"," {'en': \"That 's the life everyone sees .\",\n","  'vi': 'Đó là cuộc sống mà mọi người nhìn thấy .'},\n"," {'en': \"If you were to ask my friends and family to describe me , that 's what they would tell you .\",\n","  'vi': 'Nếu bạn yêu cầu bè bạn và gia đình tôi miêu tả tôi , đó sẽ là là những gì họ nói với bạn .'},\n"," {'en': \"And that 's a huge part of me . That is who I am .\",\n","  'vi': 'Và cuộc sống đó là một mảng lớn của tôi . Đó là chính tôi .'},\n"," {'en': \"And if you were to ask me to describe myself , I 'd probably say some of those same things .\",\n","  'vi': 'Và nếu bạn yêu cầu tôi tự miêu tả bản thân mình , chắc chắn tôi cũng sẽ nói những điều tương tự .'},\n"," {'en': \"And I wouldn 't be lying , but I wouldn 't totally be telling you the truth , either , because the truth is , that 's just the life everyone else sees .\",\n","  'vi': 'Và tôi không có nói dối , nhưng tôi cũng không hoàn toàn nói cho bạn toàn bộ sự thật bởi vì sự thật là , đó chỉ là phần cuộc sống mà mọi người thấy ,'},\n"," {'en': 'In the life that only I see , who I am , who I really am , is someone who struggles intensely with depression .',\n","  'vi': 'Trong cuộc sống chỉ có mình tôi thấy , bàn thân tôi , thực sự là bản thân tôi , là một người phải chống chọi kịch liệt với sự trầm cảm .'},\n"," {'en': 'I have for the last six years of my life , and I continue to every day .',\n","  'vi': 'mà tôi có trong suốt sáu năm trong cuộc đời mình , và tôi vẫn đang tiếp tục chống chọi mỗi ngày .'},\n"," {'en': \"Now , for someone who has never experienced depression or doesn 't really know what that means , that might surprise them to hear , because there 's this pretty popular misconception that depression is just being sad when something in your life goes wrong , when you break up with your girlfriend , when you lose a loved one , when you don 't get the job you wanted .\",\n","  'vi': 'Một số người chưa bao giờ trải qua cảm giác trầm cảm hay chưa thực sự biết trầm cảm là gì , họ thực sự sẽ ngạc nhiên , vì thường có quan niệm sai lầm khá phổ biến , rằng trầm cảm chỉ đơn thuần là cảm giác buồn chán khi điều gì đó trong cuộc sống có vấn đề , khi bạn chia tay với bạn gái , khi bạn mất đi người thân , khi bạn không tìm được công việc bạn mong muốn .'},\n"," {'en': \"But that 's sadness . That 's a natural thing .\",\n","  'vi': 'Nhưng đó chỉ đơn thuần là nỗi buồn chán . Đó là điều tự nhiên .'},\n"," {'en': \"That 's a natural human emotion .\",\n","  'vi': 'Đó là cảm xúc tự nhiên của con người .'},\n"," {'en': \"Real depression isn 't being sad when something in your life goes wrong .\",\n","  'vi': 'Trầm cảm thực sự không chỉ là buồn chán khi cuộc sống có điều không như ý .'},\n"," {'en': 'Real depression is being sad when everything in your life is going right .',\n","  'vi': 'Trầm cảm thực sự là chán nản khi tất cả mọi thứ trong cuộc sống bạn vẫn rất tốt .'},\n"," {'en': \"That 's real depression , and that 's what I suffer from .\",\n","  'vi': 'Đó mới là trầm cảm thực sự , và đó là cảm giác tôi đang chịu đựng .'},\n"," {'en': \"And to be totally honest , that 's hard for me to stand up here and say .\",\n","  'vi': 'Và thú thật từ đáy lòng , thật sự rất khó khăn đối với tôi khi đứng tại đây và diễn thuyết .'},\n"," {'en': \"It 's hard for me to talk about , and it seems to be hard for everyone to talk about , so much so that no one 's talking about it .\",\n","  'vi': 'Thực sự khó khăn khi tôi phải nói về sự trầm cảm của mình dường như ai cũng thấy khó khi nói về vấn đề này khó đến mức không ai muốn nói về nó .'},\n"," {'en': \"And no one 's talking about depression , but we need to be , because right now it 's a massive problem .\",\n","  'vi': 'Không ai muốn nói về trầm cảm , nhưng cần phải nói , bởi vì hiện tại đó là một vấn đề lớn .'},\n"," {'en': \"It 's a massive problem .\", 'vi': 'Đó là một vấn đề lớn .'},\n"," {'en': \"But we don 't see it on social media , right ?\",\n","  'vi': 'Nhưng ta không thấy nó trên truyền thông , đúng không ?'},\n"," {'en': \"We don 't see it on Facebook . We don 't see it on Twitter .\",\n","  'vi': 'Chúng ta không thấy nó trên Facebook . Chúng ta không thấy nó trên Twitter .'},\n"," {'en': \"We don 't see it on the news , because it 's not happy , it 's not fun , it 's not light .\",\n","  'vi': 'Chúng ta không thấy nó trên bản tin , bởi vì chữ trầm cảm không đem lại hạnh phúc chút nào nó không có gì vui , không tươi sáng'},\n"," {'en': \"And so because we don 't see it , we don 't see the severity of it .\",\n","  'vi': 'Và chính vì chúng ta không thấy nó , chúng ta không thấy được tính nghiêm trọng của vấn đề .'},\n"," {'en': \"But the severity of it and the seriousness of it is this : every 30 seconds , every 30 seconds , somewhere , someone in the world takes their own life because of depression , and it might be two blocks away , it might be two countries away , it might be two continents away , but it 's happening , and it 's happening every single day .\",\n","  'vi': 'Nhưng mức độ nghiêm trọng của nó và mức độ nghiêm túc của nó là thế này : cứ mỗi 30 giây , cứ mỗi 30 giây , ở một nơi nào đó , một người nào đó trên thế giới tự sát vì trầm cảm , và có thể chỉ cách đây hai dãy nhà , có thể cách đây hai quốc gia , có thể cách xa đến hai lục địa , nhưng nó đang diễn ra. và nó diễn ra mỗi ngày .'},\n"," {'en': 'And we have a tendency , as a society , to look at that and go , \" So what ? \"',\n","  'vi': 'Chúng ta hay có xu hướng , như là một xã hội , nhìn và quay đi \" Vậy thì sao nào ? \"'},\n"," {'en': 'So what ? We look at that , and we go , \" That \\'s your problem .',\n","  'vi': 'Vậy thì sao ? Chúng ta nhìn vào vấn đề đó và chúng ta bỏ đi : \" Đó là vấn đề của anh ! \"'},\n"," {'en': 'That \\'s their problem . \"', 'vi': 'Đó là vấn đề của họ . \"'},\n"," {'en': 'We say we \\'re sad and we say we \\'re sorry , but we also say , \" So what ? \"',\n","  'vi': 'Chúng ta nói chúng ta rất buồn và nói chúng ta rất làm tiếc , nhưng chúng ta cũng nói \" vậy thì sao nào ? \"'},\n"," {'en': \"Well , two years ago it was my problem , because I sat on the edge of my bed where I 'd sat a million times before and I was suicidal .\",\n","  'vi': 'Hai năm trước đó là vấn đề của bản thân tôi , bởi vì tôi đã ngồi ở bên giường của mình nơi tôi đã ngồi hàng triệu lần trước đó và tôi muốn tự sát .'},\n"," {'en': \"I was suicidal , and if you were to look at my life on the surface , you wouldn 't see a kid who was suicidal .\",\n","  'vi': 'Tôi đã muốn tự sát và nếu bạn nhìn cuộc sống của tôi chỉ ở bề nổi , ban không thể thấy đó là một đứa trẻ có ý định tự sát ,'},\n"," {'en': \"You 'd see a kid who was the captain of his basketball team , the drama and theater student of the year , the English student of the year , someone who was consistently on the honor roll and consistently at every party .\",\n","  'vi': 'Bạn chỉ thấy một đứa trẻ là một đội trưởng của đội bóng rổ , một học sinh trong đội kịch một học sinh giỏi tiếng anh của năm một người luôn ở vị trí danh dự và xuất hiện đều đặn ở mỗi buổi tiệc .'},\n"," {'en': \"So you would say I wasn 't depressed , you would say I wasn 't suicidal , but you would be wrong .\",\n","  'vi': 'Bạn có thể nói tôi đã không bị trầm cảm , bạn có thể nói tôi đã không có ý định tự sát , nhưng bạn đã lầm .'},\n"," {'en': 'You would be wrong . So I sat there that night beside a bottle of pills with a pen and paper in my hand and I thought about taking my own life and I came this close to doing it .',\n","  'vi': 'Bạn đã lầm . Vì thế tôi đã ngồi ở cạnh giường vào một buổi tối kế bên một lọ thuốc với một cây viết và tờ giấy trong tay và tôi đã nghĩ về việc tự sát và tôi thực sự đã suýt làm điều đó'},\n"," {'en': 'I came this close to doing it .',\n","  'vi': 'Tôi đến gần với cái chết như thế này'},\n"," {'en': \"And I didn 't , so that makes me one of the lucky ones , one of the people who gets to step out on the ledge and look down but not jump , one of the lucky ones who survives .\",\n","  'vi': 'và tôi đã không làm , điều đó biến tôi thành một trong những người may mắn , một trong nhưng người tránh xa được bờ vực và nhìn xuống nhưng không nhảy , một trong những người may mắn sống sót'},\n"," {'en': 'Well , I survived , and that just leaves me with my story , and my story is this : In four simple words , I suffer from depression .',\n","  'vi': 'Tôi đã sống sót , và nó để lại cho tôi câu chuyện của mình , và câu chuyện của tôi là đây : Chỉ vỏn vẹn mấy từ đơn giản : tôi bị chứng trầm cảm .'},\n"," {'en': 'I suffer from depression , and for a long time , I think , I was living two totally different lives , where one person was always afraid of the other .',\n","  'vi': 'tôi bị chứng trầm cảm , và trong một thời gian dài , tôi nghĩ , tôi đã sống hai cuộc sống hoàn toàn khác nhau , một con người luôn sợ hãi người khác ,'},\n"," {'en': \"I was afraid that people would see me for who I really was , that I wasn 't the perfect , popular kid in high school everyone thought I was , that beneath my smile , there was struggle , and beneath my light , there was dark , and beneath my big personality just hid even bigger pain .\",\n","  'vi': 'Tôi đã sợ rằng mọi người sẽ nhìn thấy tôi với bản chất của tôi , rằng tôi không hoàn hảo , không phải đứa trẻ nổi bật ở trường mà mọi người từng nghĩ , nó ẩn đằng sau nụ cười của tôi , đó là một sự đấu tranh , và ẩn chứa đằng sau hào quang của tôi , đó là bóng tối , và sau tính cách nổi trội của tôi còn ẩn chứ một vết thương lớn hơn .'},\n"," {'en': 'See , some people might fear girls not liking them back .',\n","  'vi': 'Một vài người lo sợ những cô gái không thích mình .'},\n"," {'en': 'Some people might fear sharks . Some people might fear death .',\n","  'vi': 'Một vài người sợ cá mập . Một vài người sự cái chết'},\n"," {'en': 'But for me , for a large part of my life , I feared myself .',\n","  'vi': 'Nhưng với tôi , với phần lớn cuộc sống của tôi , tôi sợ chính tôi ,'},\n"," {'en': 'I feared my truth , I feared my honesty , I feared my vulnerability , and that fear made me feel like I was forced into a corner , like I was forced into a corner and there was only one way out , and so I thought about that way every single day .',\n","  'vi': 'Tôi sợ sự thật của bản thân , tôi sợ sự thành thât của mình , tôi sợ phần yếu đuối của mình , và nỗi sợ đó khiến tôi cảm thấy như mình đang bị dồn vào chân tường , như thể tôi bị dồn vào chân tường và chỉ có một lối thoát , và vì thế tôi đã nghĩ về điều đó mỗi ngày .'},\n"," {'en': \"I thought about it every single day , and if I 'm being totally honest , standing here I 've thought about it again since , because that 's the sickness , that 's the struggle , that 's depression , and depression isn 't chicken pox .\",\n","  'vi': 'tôi đã nghĩ về nó mỗi ngày , và nếu nói cho thật trung thực , thì lúc này , đứng tại đây tôi lại nghĩ về nó lần nữa , bởi vì đó là một chứng bệnh , đó là cuộc đấu tranh , đó là sự trầm cảm , và trầm cảm không phải là bệnh thuỷ đậu .'},\n"," {'en': \"You don 't beat it once and it 's gone forever .\",\n","  'vi': 'bạn không đấu với nó một lần và nó ra đi mãi mãi .'},\n"," {'en': \"It 's something you live with . It 's something you live in .\",\n","  'vi': 'Bạn phải sống cùng nó , sống trong nó .'},\n"," {'en': \"It 's the roommate you can 't kick out . It 's the voice you can 't ignore .\",\n","  'vi': 'Nó ở ngay cạnh mà bạn không thể đuổi đi Nó là tiếng nói bạn không thể lảng tránh ,'},\n"," {'en': \"It 's the feelings you can 't seem to escape , the scariest part is that after a while , you become numb to it . It becomes normal for you , and what you really fear the most isn 't the suffering inside of you .\",\n","  'vi': 'Nó là cảm giác bạn không thể trốn tránh , phần đáng sợ nhất đó là sau một thời gian , bạn trở nên tê liệt với nó . Nó trở nên bình thường đối với bạn , và cái mà bạn sợ nhất không phải là sự chịu đựng bên trong bạn .'},\n"," {'en': \"It 's the stigma inside of others , it 's the shame , it 's the embarrassment , it 's the disapproving look on a friend 's face , it 's the whispers in the hallway that you 're weak , it 's the comments that you 're crazy .\",\n","  'vi': 'Đó là sự kỳ thị ở bên trong những người khác đó là sự xấu hổ , mặc cảm đó là những cái nhìn không chấp nhận bạn trên mặt bạn bè , đó lời thì thầm trong sảnh đường rằng bạn là kẻ yếu đuối , đó là những lời bình phẩm rằng bạn bị điên .'},\n"," {'en': \"That 's what keeps you from getting help .\",\n","  'vi': 'Đó là những thứ ngăn bạn nhận sự giúp đỡ .'},\n"," {'en': \"That 's what makes you hold it in and hide it .\",\n","  'vi': 'Đó là thứ khiến bạn tự giữ trầm cảm trong lòng và giấu nó đi .'},\n"," {'en': \"It 's the stigma . So you hold it in and you hide it , and you hold it in and you hide it , and even though it 's keeping you in bed every day and it 's making your life feel empty no matter how much you try and fill it , you hide it , because the stigma in our society around depression is very real .\",\n","  'vi': 'Đó là sự kỳ thị . Do đó bạn giữ và giấu trầm cảm trong lòng , Bạn giữ nó và bạn giấu nó đi. và mặc dù nó là thứ khiến bạn nằm trên giường mỗi ngày và nó khiến cuộc sống của bạn trống rỗng dù bạn cố gắng rất nhiều để làm đầy nó , bạn giấu , bởi vì sự kỳ thị trong xã hội đối với sự trầm cảm là có thật .'},\n"," {'en': \"It 's very real , and if you think that it isn 't , ask yourself this : Would you rather make your next Facebook status say you 're having a tough time getting out of bed because you hurt your back or you 're having a tough time getting out of bed every morning because you 're depressed ?\",\n","  'vi': 'Nó rất thật , và nếu bạn nghĩ rằng không phải thế , hãy tự hỏi bản thận điều này : Bạn có chịu ghi trên Facebook của mình rằng bạn khó khăn mãi mới ra khỏi giường bởi vì bạn bị đau lưng hay bạn thật vất vả và dai dẳng vực mình ra khỏi giường , sáng nào cũng vậy bởi vì bạn bị trầm cảm ?'},\n"," {'en': \"That 's the stigma , because unfortunately , we live in a world where if you break your arm , everyone runs over to sign your cast , but if you tell people you 're depressed , everyone runs the other way .\",\n","  'vi': 'Đó là sự kỳ thị , bởi vì thật không may , chúng ta sống trong thế giới mà nếu chẳng may bạn gãy tay , mọi người sẽ chạy lại quan tâm , Nhưng nếu bạn nói với mọi người rằng bạn bị trầm cảm , mọi người sẽ chạy theo hướng ngược lại .'},\n"," {'en': \"That 's the stigma .\", 'vi': 'Đó là sự kỳ thị .'},\n"," {'en': \"We are so , so , so accepting of any body part breaking down other than our brains . And that 's ignorance .\",\n","  'vi': 'Chúng ta thấy dễ chấp nhận vô cùng khi bất kỳ bộ phận cơ thể bị gãy Trừ bộ não ra . Đó là sự thiếu hiểu biết .'},\n"," {'en': \"That 's pure ignorance , and that ignorance has created a world that doesn 't understand depression , that doesn 't understand mental health .\",\n","  'vi': 'Là sự u mê đơn thuần . Và sự u mê đó tạo ra một thế giới không hiểu gì về sự trầm cảm , không hiểu gì về sức khoẻ tâm lý'},\n"," {'en': \"And that 's ironic to me , because depression is one of the best documented problems we have in the world , yet it 's one of the least discussed .\",\n","  'vi': 'và đó sự khôi hài với tôi , bởi vì trầm cảm là một trong những vấn đề nổi cộm chúng ta có trên thế giới tuy nhiên nó là một trong những thứ ít được bàn luận nhất .'},\n"," {'en': \"We just push it aside and put it in a corner and pretend it 's not there and hope it 'll fix itself .\",\n","  'vi': 'Chúng ta chỉ để nó qua một bên và để vào trong góc và giả vờ nó không có ở đó và hy vọng nó sẽ tự biến mất .'},\n"," {'en': \"Well , it won 't . It hasn 't , and it 's not going to , because that 's wishful thinking , and wishful thinking isn 't a game plan , it 's procrastination , and we can 't procrastinate on something this important .\",\n","  'vi': 'Nó chưa từng và sẽ không hề như thế , bởi vì đó chỉ là mong ước , và mong ước đâu phải là chơi phỏng đoán , đó là sự trì hoãn và chúng ta không thể trì hoãn một vấn đề quan trọng như vậy .'},\n"," {'en': 'The first step in solving any problem is recognizing there is one .',\n","  'vi': 'Bước đầu để giải quyết bất kỳ vấn đề nào là nhận ra rằng có một vấn đề đang ở đó .'},\n"," {'en': \"Well , we haven 't done that , so we can 't really expect to find an answer when we 're still afraid of the question .\",\n","  'vi': 'Chúng ta đã làm đâu , vậy nên chúng ta không thể mong chờ tìm ra được câu trả lời khi mình vẫn sợ câu hỏi .'},\n"," {'en': \"And I don 't know what the solution is .\",\n","  'vi': 'Và tôi chưa biết lời giải là gì .'},\n"," {'en': \"I wish I did , but I don 't -- but I think , I think it has to start here .\",\n","  'vi': 'Giá mà tôi biết được , nhưng tôi không -- nhưng tôi nghĩ , cần phải bắt đầu từ đây , bây giờ'},\n"," {'en': 'It has to start with me , it has to start with you , it has to start with the people who are suffering , the ones who are hidden in the shadows .',\n","  'vi': 'cần phải bắt đầu từ tôi , từ bạn bắt đầu với những người đang chống chọi khổ đau , những người giấu mình vào bóng tối'},\n"," {'en': 'We need to speak up and shatter the silence .',\n","  'vi': 'Chúng ta cần phải lên tiếng nói và phá tan sự im lặng .'},\n"," {'en': \"We need to be the ones who are brave for what we believe in , because if there 's one thing that I 've come to realize , if there 's one thing that I see as the biggest problem , it 's not in building a world where we eliminate the ignorance of others .\",\n","  'vi': 'Chúng ta cần là người can đảm cho những gì mình tin , bởi vì nếu có một thứ mà chúng ta phải nhìn nhận ra , nếu chỉ có một vấn đề mà tôi cho là to lớn nhất , thì nó không phải là xây dựng nên một thế giới nơi chúng ta loại bỏ đi sự u mê của người khác ,'},\n"," {'en': \"It 's in building a world where we teach the acceptance of ourselves , where we 're okay with who we are , because when we get honest , we see that we all struggle and we all suffer .\",\n","  'vi': 'mà là xây nên một thế giới để dạy nhau cách tự chấp nhận mình nơi chúng ta ok với chính bản thân . Vì khi chúng ta trở nên trung thực , chúng ta nhận thấy ai cũng phải chống chọi , phải đau khổ .'},\n"," {'en': \"Whether it 's with this , whether it 's with something else , we all know what it is to hurt .\",\n","  'vi': 'Ngay cả nếu có như vậy , hay là như thế nào khác , ta đều hiểu đau đớn là thế nào .'},\n"," {'en': 'We all know what it is to have pain in our heart , and we all know how important it is to heal .',\n","  'vi': 'Ta đều hiểu đau đớn ở trong lòng ra sao , và ta đều hiểu cần phải chữa lành khẩn thiết đến thế nào .'},\n"," {'en': \"But right now , depression is society 's deep cut that we 're content to put a Band-Aid over and pretend it 's not there .\",\n","  'vi': 'Vậy mà ngay bây giờ , trầm cảm là một vết cắt sâu của xã hội mà ta hài lòng che đậy bằng băng y tế rồi vờ như nó không tồn tại .'},\n"," {'en': \"Well , it is there . It is there , and you know what ? It 's okay .\",\n","  'vi': 'Nó tồn tại . Nó ở đó , và bạn biết không ? Không sao !'},\n"," {'en': \"Depression is okay . If you 're going through it , know that you 're okay .\",\n","  'vi': 'Trầm cảm cũng bình thường thôi . Nếu bạn đang trải qua nó , bạn cũng người bình thường thôi .'},\n"," {'en': \"And know that you 're sick , you 're not weak , and it 's an issue , not an identity , because when you get past the fear and the ridicule and the judgment and the stigma of others , you can see depression for what it really is , and that 's just a part of life , just a part of life , and as much as I hate , as much as I hate some of the places , some of the parts of my life depression has dragged me down to , in a lot of ways I 'm grateful for it .\",\n","  'vi': 'Và biết rằng bạn chỉ bị bệnh , bạn không hề yếu đuối nó là một vấn đề , đâu phải là căn tính của chính bạn , bởi vì khi bạn vượt qua được nỗi sợ hãi , sự chế nhạo sự đánh giá và sự kỳ thị của người khác , bạn sẽ thấy được trầm cảm thật sự là gì , và đó chỉ là một phần của cuộc sống đơn giản là một phần cuộc sống , phần tôi ghét nhiều lắm tôi ghét cay ghét đắng một vài chốn , một vài phần của cuộc sống trầm cảm này đã kéo tôi xuống trong đó lại có rất nhiều nẻo đường làm tôi biết ơn'},\n"," {'en': \"Because yeah , it 's put me in the valleys , but only to show me there 's peaks , and yeah it 's dragged me through the dark but only to remind me there is light .\",\n","  'vi': 'Ừ thì nó thả tôi ở những vực sâu nhưng chỉ là để cho tôi biết đâu là đỉnh cao , Ừ thì nó kéo tôi xuống vực tối nhưng chỉ là để nhắc cho tôi biết đâu là ánh sáng .'},\n"," {'en': 'My pain , more than anything in 19 years on this planet , has given me perspective , and my hurt , my hurt has forced me to have hope , have hope and to have faith , faith in myself , faith in others , faith that it can get better , that we can change this , that we can speak up and speak out and fight back against ignorance , fight back against intolerance , and more than anything , learn to love ourselves , learn to accept ourselves for who we are , the people we are , not the people the world wants us to be .',\n","  'vi': 'Nỗi khổ đau của tôi , hơn bất kỳ điều gì trong 19 năm trên hành tinh này đã cho tôi nhận thức , và nỗi đau , nỗi đau của tôi đã buộc tôi phải có hi vọng , có hi vọng và có lòng tin , lòng tin vào chính mình , lòng tin ở người khác , lòng tin rằng mọi thứ có thể tốt hơn , rằng chúng ta có thể thay đổi , rằng chúng ta có thể nói lên được rằng phải nói ra và đánh bại sự u mê thờ ơ , đánh bại lại sự không khoan dung , và hơn tất cả mọi thứ , học yêu lấy bản thân mình , học chấp nhận bản thân chúng ta như con người chúng ta đang là con người chúng ta đang là , không phải con người mà thế giới muốn ta trở thành'},\n"," {'en': \"Because the world I believe in is one where embracing your light doesn 't mean ignoring your dark .\",\n","  'vi': 'Bởi vì thế giới tôi tin là một thế giới mà việc hướng đến ánh sáng không có nghĩa là lờ quên đi nơi tăm tối của bạn'},\n"," {'en': \"The world I believe in is one where we 're measured by our ability to overcome adversities , not avoid them .\",\n","  'vi': 'Thế giới tôi tin vào là nơi mà chúng ta đã được đong lường bởi khả năng vượt qua thử thách , chứ không trốn chạy chúng .'},\n"," {'en': 'The world I believe in is one where I can look someone in the eye and say , \" I \\'m going through hell , \" and they can look back at me and go , \" Me too , \" and that \\'s okay , and it \\'s okay because depression is okay . We \\'re people .',\n","  'vi': 'Thế giới tôi tin là nơi tôi có thể nhìn vào mắt của một ai đó và nói rằng , \" Tôi đang ở trong địa ngục \" và rồi họ nhìn lại tôi và nói , \" Tôi cũng vậy thôi \" và điều này cũng chẳng sao . Nó không sao vì sự trầm cảm là bình thường thôi . Chúng ta là con người'},\n"," {'en': \"We 're people , and we struggle and we suffer and we bleed and we cry , and if you think that true strength means never showing any weakness , then I 'm here to tell you you 're wrong .\",\n","  'vi': 'Là con người , chúng ta chống chọi và khổ đau . Chúng ta rỉ máu và kêu khóc . Nếu bạn nghĩ sức mạnh thật sự có nghĩa là không bao giờ để lộ sự yếu hèn thì tôi ở đây để nói với bạn rằng : Bạn sai rồi !'},\n"," {'en': \"You 're wrong , because it 's the opposite .\",\n","  'vi': 'Bạn sai rồi , bởi vì nó hoàn toàn ngược lại .'},\n"," {'en': \"We 're people , and we have problems .\",\n","  'vi': 'Chúng ta là con người , và chúng ta có những vấn đề .'},\n"," {'en': \"We 're not perfect , and that 's okay .\",\n","  'vi': 'Chúng ta không hoàn hảo , và vậy thì cũng bình thường thôi .'},\n"," {'en': \"So we need to stop the ignorance , stop the intolerance , stop the stigma , and stop the silence , and we need to take away the taboos , take a look at the truth , and start talking , because the only way we 're going to beat a problem that people are battling alone is by standing strong together , by standing strong together .\",\n","  'vi': 'Vì vậy chúng ta nên dừng ngay sự u mê này lại , dừng sự thờ ơ , dừng sự kỳ thị chế nhạo , và dừng sự im lặng này , và phá bỏ những điều cấm kỵ , nhìn thẳng vào sự thật , và bắt đầu trò chuyện , bởi vì cách duy nhất để đánh bại một vấn đề mà cá nhân mỗi người phải tự mình chiến đấu đó là cùng mạnh mẽ vững vàng đứng lại gần nhau , cùng mạnh mẽ vững vàng đứng lại gần nhau .'},\n"," ...]"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["a = [sample['en'] for sample in data['translation']]\n","b = [sample['vi'] for sample in data['translation']]\n","c = max([len(i) for i in a])\n","d = max([len(i) for i in b])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P02qE8HPiy1s","executionInfo":{"status":"ok","timestamp":1730009654901,"user_tz":-420,"elapsed":2652,"user":{"displayName":"Minh Trần Khánh","userId":"16846330008114299858"}},"outputId":"e7e17f2b-9257-41fd-bfe5-d5b29661589a"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2610"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["d"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fzxT4CWQn835","executionInfo":{"status":"ok","timestamp":1730009880378,"user_tz":-420,"elapsed":321,"user":{"displayName":"Minh Trần Khánh","userId":"16846330008114299858"}},"outputId":"96696efe-4164-43e3-c54f-e500691457b6"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3198"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["\n","e = [sample['en'] for sample in data['translation'] if len(sample['en']) == 2610]\n","e"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TmzgVLSBnJsG","executionInfo":{"status":"ok","timestamp":1730009749998,"user_tz":-420,"elapsed":1485,"user":{"displayName":"Minh Trần Khánh","userId":"16846330008114299858"}},"outputId":"71682768-25a3-4539-f13f-81657717dd86"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"Thula Mama , Thula Mama , Thula Mama , Thula Mama . Through the mist of the tears in your eyes on my childhood memory , I know the truth in your smile , I know the truth in your smile , piercing through the gloom of my ignorance . Oh , there is a mama lying down sleeping you 're very ill and your heart crying . Wondering , wondering , wondering , wondering where is this world coming to . Is it right the children have to fend for themselves ? No , no , no , no , no. no . Is it right heaping trouble on an old lady 's head ? So unlucky faceless people . Thula Mama Mama , Thula Mama . Thula Mama Mama . Thula Mama , Thula Mama , Thula Mama Mama , Thula Mama Tomorrow it 's going to be better . Tomorrow it 's going to be better to climb , Mama . Thula Mama , Thula Mama . Am I to break into the song like the blues man or troubadour . And then from long distance in no blues club am I to sing , baby , baby , baby , baby , baby , baby , baby , baby , baby , baby , baby , baby . Should I now stop singing of love , now that my memory 's surrounded by blood ? Sister , why oh why do we at times mistake a pimple for a cancer ? So who are they who says , no more love poems now ? I want to sing a song of love for that woman who jumped the fences pregnant and still gave birth to a healthy child . Softly I walk into the sun rays of the smile that will ignite my love song , my song of life , my song of love , my song of life , my song of love , my song of life , my song of love , my song of life . Ooh , I 've not tried to run away from song , I hear a persistent voice , more powerful than the enemy bombs . The song that washed our lives and the rains of our blood . My song of love and my song of life , my song of love , my song of life , my song of love , my song of life , my song of love -- I want everybody to sing with me -- my song of life , my song of love , my song of life -- everybody sing with me -- my song of life , my song of love -- I can 't hear you -- my song of love , my song of life -- you can do better -- my song of life , my song of love -- keep singing , keep singing -- my song of love , my song of life , yes , my song of love -- you can do better than that -- my song of life , yes , my song of love , my song of life , my song of love -- keep singing , keep singing , keep singing -- my song of love . Oh yeah . My song of -- a love song , my song of life . Sing . A love song , my song of life . Sing . Love song , my song of life . Sing . Love song , my song of life . Sing . Love song , my song of life . Sing . Love song , my song of life . Love song , my song of life .\"]"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["# Load dataset"],"metadata":{"id":"OhhLF7vHw8_F"}},{"cell_type":"code","source":["class MMTDataset(Dataset):\n","  def __init__(self, cfg, data_type = \"Train\"):\n","    super().__init__()\n","    self.cfg = cfg\n","    self.data_type = data_type\n","    self.src_texts, self.tgt_texts = self.read_data()\n","    self.src_input_ids, self.src_attention_mask = self.texts_to_sequences(self.src_texts)\n","    self.tgt_input_ids, self.tgt_attention_mask, self.labels = self.texts_to_sequences(\n","        self.tgt_texts,\n","        is_src=False\n","    )\n","\n","  def read_data(self):\n","    data = load_dataset(\"Angelectronic/IWSLT15_English_Vietnamese\", split=\"train\")\n","    src_text = [sample[self.cfg.src_lang] for sample in data['translation']]\n","    tgt_text = [sample[self.cfg.tgt_lang] for sample in data['translation']]\n","    return src_text, tgt_text\n","\n","  def texts_to_sequences(self, texts, is_src = True):\n","    if is_src:\n","      src_inputs = self.cfg.src_tokenizer(\n","          texts,\n","          max_length=self.cfg.src_max_len,\n","          padding=\"max_length\",\n","          truncation=True,\n","          return_tensors=\"pt\",\n","      )\n","      return (\n","          src_inputs.input_ids,\n","          src_inputs.attention_mask\n","      )\n","    else:\n","      if self.cfg.add_special_token:\n","        texts = [\n","            \" \".join([\n","                self.cfg.tgt_tokenizer.bos_token,\n","                text,\n","                self.cfg.tgt_tokenizer.eos_token\n","            ])\n","            for text in texts\n","        ]\n","      tgt_inputs = self.cfg.tgt_tokenizer(\n","          texts,\n","          max_length=self.cfg.tgt_max_len,\n","          padding=\"max_length\",\n","          truncation=True,\n","          return_tensors=\"pt\",\n","      )\n","      labels = tgt_inputs.input_ids.numpy().tolist()\n","      labels =[[\n","          -100 if token_id == self.cfg.tgt_tokenizer.pad_token_id else token_id\n","          for token_id in label\n","      ] for label in labels]\n","      labels = torch.LongTensor(labels)\n","\n","      return (\n","          tgt_inputs.input_ids,\n","          tgt_inputs.attention_mask,\n","          labels\n","          )\n","\n","  def __getitem__(self, index):\n","    return {\n","        \"input_ids\": self.src_input_ids[index],\n","        \"attention_mask\": self.src_attention_mask[index],\n","        \"decoder_input_ids\": self.tgt_input_ids[index],\n","        \"decoder_attention_mask\": self.tgt_attention_mask[index],\n","        \"labels\": self.labels[index]\n","    }\n","  def __len__(self):\n","    return np.shape(self.src_input_ids)[0]\n"],"metadata":{"id":"l3QRTo9OYqI8","executionInfo":{"status":"ok","timestamp":1730023634983,"user_tz":-420,"elapsed":12,"user":{"displayName":"Minh Trần Khánh","userId":"16846330008114299858"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# Load tokenizer"],"metadata":{"id":"oF93YbA0xJY0"}},{"cell_type":"code","source":["def postprocess_text(preds, labels):\n","    preds = [pred.strip() for pred in preds]\n","    labels = [[label.strip()] for label in labels]\n","    return preds, labels\n","def load_tokenizer(model_name_or_path):\n","    if 'bert' in model_name_or_path.split('-'):\n","        return BertTokenizerFast.from_pretrained(model_name_or_path)\n","    elif 'gpt2' in model_name_or_path.split('-'):\n","        return GPT2TokenizerFast.from_pretrained(model_name_or_path)\n","    else:\n","        return AutoTokenizer.from_pretrained(model_name_or_path)"],"metadata":{"id":"MM_pHMWhxP_5","executionInfo":{"status":"ok","timestamp":1730023634983,"user_tz":-420,"elapsed":11,"user":{"displayName":"Minh Trần Khánh","userId":"16846330008114299858"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["class Train():\n","  def __init__(self, cfg):\n","    self.cfg = cfg\n","    print(\"Loading tokenizer...\")\n","    self.get_tokenizer()\n","    print(\"Loading dataset...\")\n","    self.train_dataset = MMTDataset(self.cfg, \"train\")\n","    self.eval_dataset = MMTDataset(self.cfg, \"validation\")\n","    print(\"Loading model...\")\n","    self.get_model()\n","    print(\"Loading Metric...\")\n","    self.bleu_metric = evaluate.load(\"sacrebleu\")\n","\n","    print(\"Check Save Model Path\")\n","    if not os.path.exists(self.cfg.ckpt_dir):\n","        os.mkdir(self.cfg.ckpt_dir)\n","\n","  def get_tokenizer(self):\n","    self.cfg.src_tokenizer = load_tokenizer(self.cfg.src_model_name)\n","    if \"bert\" in self.cfg.tgt_model_name.split('-'):\n","      self.cfg.tgt_tokenizer = load_tokenizer(self.cfg.tgt_model_name)\n","      self.cfg.add_special_token = False\n","      self.cfg.bos_token_id = self.cfg.tgt_tokenizer.cls_token_id\n","      self.cfg.eos_token_id = self.cfg.tgt_tokenizer.sep_token_id\n","      self.cfg.pad_token_id = self.cfg.tgt_tokenizer.pad_token_id\n","    else:\n","      self.cfg.tgt_tokenizer = load_tokenizer(self.cfg.tgt_model_name)\n","      self.cfg.add_special_token = True\n","      self.cfg.tgt_tokenizer.add_special_tokens(\n","          {\n","            \"bos_token\": \"[BOS]\",\n","            \"eos_token\": \"[EOS]\",\n","            \"pad_token\": \"[PAD]\"\n","          }\n","      )\n","      self.cfg.bos_token_id = self.cfg.tgt_tokenizer.bos_token_id\n","      self.cfg.eos_token_id = self.cfg.tgt_tokenizer.eos_token_id\n","      self.cfg.pad_token_id = self.cfg.tgt_tokenizer.pad_token_id\n","    self.cfg.tgt_tokenizer.save_pretrained(\n","            os.path.join(self.cfg.ckpt_dir, f\"{self.cfg.src_lang}_tokenizer_{cfg.src_model_name}\")\n","        )\n","    self.cfg.tgt_tokenizer.save_pretrained(\n","            os.path.join(self.cfg.ckpt_dir, f\"{self.cfg.tgt_lang}_tokenizer_{cfg.tgt_model_name}\")\n","        )\n","\n","\n","\n","  def get_model(self):\n","    self.model = EncoderDecoderModel.from_encoder_decoder_pretrained(\n","        self.cfg.src_model_name,\n","        self.cfg.tgt_model_name\n","    )\n","    self.model.decoder.resize_token_embeddings(\n","        len(self.cfg.tgt_tokenizer)\n","    )\n","    self.model.config.decoder_start_token_id = self.cfg.bos_token_id\n","    self.model.config.eos_token_id = self.cfg.eos_token_id\n","    self.model.config.pad_token_id = self.cfg.pad_token_id\n","    self.model.config.vocab_size = len(self.cfg.tgt_tokenizer)\n","    self.model.config.max_length = self.cfg.max_length_decoder\n","    self.model.config.min_length = self.cfg.min_length_decoder\n","    self.model.config.no_repeat_ngram_size = 3\n","    self.model.config.early_stopping = True\n","    self.model.config.length_penalty = 2.0\n","    self.model.config.num_beams = self.cfg.beam_size\n","\n","  def train(self):\n","    print(\"Training...\")\n","    if self.cfg.use_eval_steps:\n","        training_args = Seq2SeqTrainingArguments(\n","            predict_with_generate=True,\n","            evaluation_strategy=\"steps\",\n","            save_strategy='steps',\n","            save_steps=self.cfg.eval_steps,\n","            eval_steps=self.cfg.eval_steps,\n","            output_dir=self.cfg.ckpt_dir,\n","            per_device_train_batch_size=self.cfg.train_batch_size,\n","            per_device_eval_batch_size=self.cfg.eval_batch_size,\n","            learning_rate=self.cfg.learning_rate,\n","            weight_decay=0.005,\n","            num_train_epochs=self.cfg.num_train_epochs\n","        )\n","    else:\n","        training_args = Seq2SeqTrainingArguments(\n","            predict_with_generate=True,\n","            evaluation_strategy=\"epoch\",\n","            save_strategy='epoch',\n","            output_dir=self.cfg.ckpt_dir,\n","            per_device_train_batch_size=self.cfg.train_batch_size,\n","            per_device_eval_batch_size=self.cfg.eval_batch_size,\n","            learning_rate=self.cfg.learning_rate,\n","            weight_decay=0.005,\n","            num_train_epochs=self.cfg.num_train_epochs\n","        )\n","    data_collator = DataCollatorForSeq2Seq(\n","        self.cfg.tgt_tokenizer,\n","        model=self.model\n","    )\n","\n","    trainer = Seq2SeqTrainer(\n","        self.model,\n","        training_args,\n","        train_dataset=self.train_dataset,\n","        eval_dataset=self.eval_dataset,\n","        data_collator=data_collator,\n","        tokenizer=self.cfg.tgt_tokenizer,\n","        compute_metrics=self.compute_metrics\n","    )\n","\n","    trainer.train()\n","\n","  def compute_metrics(self, eval_preds):\n","      preds, labels = eval_preds\n","      if isinstance(preds, tuple):\n","          preds = preds[0]\n","      decoded_preds = self.cfg.tgt_tokenizer.batch_decode(preds, skip_special_tokens=True)\n","\n","      labels = np.where(labels != -100, labels, self.cfg.tgt_tokenizer.pad_token_id)\n","      decoded_labels = self.cfg.tgt_tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","      decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n","\n","      result = self.bleu_metric.compute(\n","          predictions=decoded_preds,\n","          references=decoded_labels\n","      )\n","\n","      result = {\"bleu_score\": result[\"score\"]}\n","\n","      prediction_lens = [np.count_nonzero(pred != self.cfg.tgt_tokenizer.pad_token_id) for pred in preds]\n","      result[\"gen_len\"] = np.mean(prediction_lens)\n","      result = {k: round(v, 4) for k, v in result.items()}\n","\n","      return result\n"],"metadata":{"id":"yeJyxsmVxX0t","executionInfo":{"status":"ok","timestamp":1730023634983,"user_tz":-420,"elapsed":11,"user":{"displayName":"Minh Trần Khánh","userId":"16846330008114299858"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class BaseConfig:\n","    def __init__(self, **kwargs):\n","        for k, v in kwargs.items():\n","            setattr(self, k, v)\n","\n","class NMTConfig(BaseConfig):\n","    src_lang = 'en'\n","    tgt_lang = 'vi'\n","    src_max_len = 100\n","    tgt_max_len = 100\n","\n","    src_model_name = \"bert-base-multilingual-cased\"\n","    tgt_model_name = \"bert-base-multilingual-cased\"\n","\n","    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","    learning_rate = 3e-5\n","    train_batch_size = 32\n","    eval_batch_size = 32\n","    num_train_epochs = 5\n","    ckpt_dir = src_model_name + '_to_' + tgt_model_name\n","    use_eval_steps = True\n","    eval_steps = 5000\n","\n","    max_length_decoder = 100\n","    min_length_decoder = 25\n","    beam_size = 3\n","\n","cfg = NMTConfig()"],"metadata":{"id":"ok1MOyEg9I4V","executionInfo":{"status":"ok","timestamp":1730023634984,"user_tz":-420,"elapsed":11,"user":{"displayName":"Minh Trần Khánh","userId":"16846330008114299858"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["manager = Train(cfg)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["8095e0fa7f8f4c14af5eefb49f618acf","bbf916b0ee5b41f6a3be56e023967f02","eda606a1a2d6448d90c838bc86d23c69","35f75e517d7c4c769a9b56304c603375","617e8c9117d64bf2990e16751859fd64","3e8022ecfc6a42919ccb5ad15f545bb9","cf598c772c5a4b6396e606ec1af46082","b1b5e98c4dbd4d72a426e8bc9596866e","3170dd542fd54bc082db93021796b6cf","b0fdd523ff6d4b908616c905093399ea","7d1afb2837824ce3b38dc2002d756a2a","4eff76ae8f3c4cabb37bea9e4ede2e40","3b7f91a17a1c47a39c36c74fec6a966d","d2f771513fcd4880b29c5eba64e7897a","d484e8a9f6d04d788ee4b9d979eace07","30cabe8677da4250af735a8e906fbd59","7d70483f5b3a4a6e8736aa4dad33400f","aa5e743c167449078113ab15658d3d95","108f65623f32448c92f9d0ccd6c74add","df532d99bc064c76bac956a7f782b8fd","53ddc57cc9364cec9e0de216e337db84","3659b8ff47fa48249971e340a75491ab","3900c7f30daf4b9ab4928cab90a0d2a3","fc0eb443d9624163b4af4029fb76305c","2b5615b3242c4d88a2a0d5e397fdc017","287e61a0331b4d3994d3750b2a9d761f","1234a2774b304f72b25fbbd42215e3b9","fd705daad95e428fb4708f9f290df72e","d31186feff3a4545b61a19bf37f704fa","c5bc98ac56ba44a6983190b6c8dbc161","8c04ce69b05e454ca235a060c27b183a","19d38e066b8843e2867125e00fce38dc","7bcea95a5c1b42189336c05599c73dc6","73ccdfc42f6747e29ab7653f778ddbec","d45633ac3ca34bcb90caee3cb2155ce4","b04d334395c94eee99d3f132a496c700","fa8dc7fb583a46fdbc24b11e2b34c4fb","d62a1b588c35475ab1bfe793f0f872b6","c3439c4865ec46dea77408e5afa6c175","cdbce26b182e4cf593eedfaeb374b970","c091aad7154846cc9b4b4ad659edfbb5","7c0a1573d4a947c8bdb311ae953e8b10","d65df435da7545f7a4feccabd63dd47c","c68e3a0012f441fb914f6145828c02ea","498999c6957b4d54a7ee84007db6185a","1e0b158a5629411ab3966ef6d1a6733e","9e2dc71c135e49cb8a57413e32a6bf3a","fc37a2b36b9242158198fc733a49ccc3","62da5cd4e5b84e878a41eedd4d4af0a9","c0203fd7c6864357afe14b8747bdc924","600319cb7c9a40f0ac6aeb9d4b8dc2b9","e455cd09597c443ea6fdc592b9d2288f","15844cd1cc40408e9c59a5abbe5f686a","ddf34ad02aa54ada9c19f16a7a28bf01","38b9826e89b544e9b2321597a0e7472f","39f93114ee204b54b3ba1403d3f36205","482f09a1c0ff421ca3285a287f4f0620","51f0c5b105644111ac9a8ad090af193c","2f8c1e3044d5425fa4ab4ccfa6f6816e","f0e3b42ead6c4326accfcdc537d24a09","64a02e18edb84f778341352a90fabfaa","f6cd2314bbf447f0a8fe0d34d7b863d0","dd599f0b28c94b0381e86399fd804d9d","f6f98cd412ba4f36a71825328dda7916","5d0a3c79d4e1486cbc2b7467e1364516","aee3230f58134abbad3b8b1c06bb323c","080f875fab7d466f9cc56e3a7fc43f1b","e5ca9db4da234792acdf787457051ee0","1265a269743441afae2db6f0daff34a0","e3d512de63be4a28af2654a5157f62f5","7cc92e4e4015423c906cb27cc51684cd","f0401f7cd4bb45789b5c32817c861505","1c09b5dfb423492fb19ba515d8538c09","79137b8f6dc84450b01fc97396d48e61","d3642c5eb17d4687845ef4700ec5b2eb","cfa4c31da7ec4253abf0372634a79612","b6deb1489f644affaa003d74b8e78534","f83a12dcc37445178aedbcf91df90b91","042b015891474e0786f5347d4cb6c7eb","81afe53a078c4cf4b7edd590295f7d40","f072d4fbd28c4b25bf6668de6e06e201","1bc53ca0f82e405db1af8942077a3000","acb7d4191c324bbbafc98ea7f18eaea0","fb0b7b046c6349dcb1591114a8ecaf72","f139795bc44b46a39333af47570597fd","f181afed89ba4c7897813074f898b9b6","49bd5303a9154ac98d34481c8cd30e39","f18356d0bf9e43f2b13f54b7a2e17607","4dcaeeb4c5e74b8a8e7f008a7c2af06d","de94271a61a343afb18d343f3f287887","9121d8bccd3642a98e23247d9dec5fca","07f34c8ee15d439db05b0b84b5d1244d","9a6b7f1dcf5b40d293d34c944a15be9d","9e9915734aba4ea4835877bafb51f848","2a67385347714c8ea56c0b8c4b0cd0b7","1374f87762c543e9b0380b514eb5cbb5","1c834547f55542c0ac39d47db3b57a21","eb48a97adde14be4992a4ff5968afce2","121a1c7c978f4ed3b55101a17d7cdc98","383b1c09355840e5ad736775e2abb84b","a9b63a14b52340789086e51e9cea53f7","62c9656b93b546a7a97772bb95141446","7c6c2f0b71024528891b245aed613186","2a759d64a51147a7b4949c72c59a424c","facf8493faf6473c8ee330ef5118a974","420d19fa137b458c89ba935fa706d2e3","83aceb8947a249e0809fbd21c0e6a26f","a5ed6d0b31fa473b95f4fa58fb4d19ad","9d1e3fb4e6294d19a1a5b046ad2abb80","8608618bf7364b8799042f48bcbe589b","ab9a88cd38014e64b51ca99498639b0c","439b02baffdb4c0e8d48b5e6e4543a06","f5b9c0177988409182a7098b7420361b","db309b776a764680a191200dd99169bb","1856af12e82446c6b8e324690ec8d050","a333b2f92cca418bb4ed6f0f8b73fd2a","be26728bd76044e6a3b9d8ab61ad55d3","f1537385a2834f0ab18fe23028c987c1","53d1dfeb65aa4feb9b101acd3e580415","32fda8ea160c4b8a9dc10878b60fa88e","ba0f01720230486bb16bdfcfea575d44"]},"id":"ACK2AH6-9eJz","executionInfo":{"status":"ok","timestamp":1730023741230,"user_tz":-420,"elapsed":106256,"user":{"displayName":"Minh Trần Khánh","userId":"16846330008114299858"}},"outputId":"dd2371cf-c054-458a-8097-8a1c4ecaab99"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading tokenizer...\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8095e0fa7f8f4c14af5eefb49f618acf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4eff76ae8f3c4cabb37bea9e4ede2e40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3900c7f30daf4b9ab4928cab90a0d2a3"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/3f076fdb1ab68d5b2880cb87a0886f315b8146f8/vocab.txt\n","loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/3f076fdb1ab68d5b2880cb87a0886f315b8146f8/tokenizer.json\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at None\n","loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/3f076fdb1ab68d5b2880cb87a0886f315b8146f8/tokenizer_config.json\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73ccdfc42f6747e29ab7653f778ddbec"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/3f076fdb1ab68d5b2880cb87a0886f315b8146f8/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-multilingual-cased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"directionality\": \"bidi\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.44.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 119547\n","}\n","\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/3f076fdb1ab68d5b2880cb87a0886f315b8146f8/vocab.txt\n","loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/3f076fdb1ab68d5b2880cb87a0886f315b8146f8/tokenizer.json\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at None\n","loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/3f076fdb1ab68d5b2880cb87a0886f315b8146f8/tokenizer_config.json\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/3f076fdb1ab68d5b2880cb87a0886f315b8146f8/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-multilingual-cased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"directionality\": \"bidi\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.44.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 119547\n","}\n","\n","tokenizer config file saved in bert-base-multilingual-cased_to_bert-base-multilingual-cased/en_tokenizer_bert-base-multilingual-cased/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased_to_bert-base-multilingual-cased/en_tokenizer_bert-base-multilingual-cased/special_tokens_map.json\n","tokenizer config file saved in bert-base-multilingual-cased_to_bert-base-multilingual-cased/vi_tokenizer_bert-base-multilingual-cased/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased_to_bert-base-multilingual-cased/vi_tokenizer_bert-base-multilingual-cased/special_tokens_map.json\n"]},{"output_type":"stream","name":"stdout","text":["Loading dataset...\n"]},{"output_type":"display_data","data":{"text/plain":["README.md:   0%|          | 0.00/538 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"498999c6957b4d54a7ee84007db6185a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["(…)-00000-of-00001-32a2d2de76910062.parquet:   0%|          | 0.00/18.4M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39f93114ee204b54b3ba1403d3f36205"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["(…)-00000-of-00001-90850d7d3fd03986.parquet:   0%|          | 0.00/188k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"080f875fab7d466f9cc56e3a7fc43f1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split:   0%|          | 0/133166 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f83a12dcc37445178aedbcf91df90b91"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating test split:   0%|          | 0/1268 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4dcaeeb4c5e74b8a8e7f008a7c2af06d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Loading model...\n"]},{"output_type":"stream","name":"stderr","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/3f076fdb1ab68d5b2880cb87a0886f315b8146f8/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-multilingual-cased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"directionality\": \"bidi\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.44.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 119547\n","}\n","\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"383b1c09355840e5ad736775e2abb84b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/3f076fdb1ab68d5b2880cb87a0886f315b8146f8/model.safetensors\n","A pretrained model of type `BertModel` contains parameters that have been renamed internally (a few are listed below but more are present in the model):\n","* `bert.embeddings.LayerNorm.gamma` -> `bert.embeddings.LayerNorm.weight`\n","* `bert.encoder.layer.0.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.0.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.1.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.1.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.10.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.10.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.11.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.11.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.2.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.2.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.3.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.3.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.4.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.4.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.5.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.5.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.6.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.6.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.7.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.7.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.8.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.8.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.9.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.9.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `cls.predictions.transform.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.embeddings.LayerNorm.beta` -> `bert.embeddings.LayerNorm.bias`\n","* `bert.encoder.layer.0.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.0.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.1.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.1.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.10.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.10.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.11.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.11.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.2.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.2.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.3.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.3.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.4.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.4.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.5.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.5.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.6.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.6.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.7.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.7.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.8.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.8.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.9.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.9.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `cls.predictions.transform.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","If you are using a model from the Hub, consider submitting a PR to adjust these weights and help future users.\n","Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of BertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/3f076fdb1ab68d5b2880cb87a0886f315b8146f8/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-multilingual-cased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"directionality\": \"bidi\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.44.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 119547\n","}\n","\n","Initializing bert-base-multilingual-cased as a decoder model. Cross attention layers are added to bert-base-multilingual-cased and randomly initialized if bert-base-multilingual-cased's architecture allows for cross attention layers.\n","loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/3f076fdb1ab68d5b2880cb87a0886f315b8146f8/model.safetensors\n","Generate config GenerationConfig {\n","  \"pad_token_id\": 0\n","}\n","\n","A pretrained model of type `BertLMHeadModel` contains parameters that have been renamed internally (a few are listed below but more are present in the model):\n","* `bert.embeddings.LayerNorm.gamma` -> `bert.embeddings.LayerNorm.weight`\n","* `bert.encoder.layer.0.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.0.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.1.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.1.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.10.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.10.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.11.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.11.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.2.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.2.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.3.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.3.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.4.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.4.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.5.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.5.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.6.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.6.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.7.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.7.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.8.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.8.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.9.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.9.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `cls.predictions.transform.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.embeddings.LayerNorm.beta` -> `bert.embeddings.LayerNorm.bias`\n","* `bert.encoder.layer.0.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.0.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.1.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.1.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.10.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.10.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.11.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.11.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.2.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.2.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.3.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.3.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.4.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.4.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.5.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.5.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.6.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.6.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.7.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.7.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.8.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.8.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.9.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.9.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `cls.predictions.transform.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","If you are using a model from the Hub, consider submitting a PR to adjust these weights and help future users.\n","Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertLMHeadModel: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertLMHeadModel were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.value.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Generation config file not found, using a generation config created from the model config.\n","Set `config.is_decoder=True` and `config.add_cross_attention=True` for decoder_config\n","Generate config GenerationConfig {}\n","\n","You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 119547. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"]},{"output_type":"stream","name":"stdout","text":["Loading Metric...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab9a88cd38014e64b51ca99498639b0c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Check Save Model Path\n"]}]},{"cell_type":"code","source":["manager.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"nkrWwlF19jR_","executionInfo":{"status":"error","timestamp":1730035747937,"user_tz":-420,"elapsed":12006719,"user":{"displayName":"Minh Trần Khánh","userId":"16846330008114299858"}},"outputId":"17264cf6-c247-4381-efbc-191377678f57"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]},{"output_type":"stream","name":"stdout","text":["Training...\n"]},{"output_type":"stream","name":"stderr","text":["***** Running training *****\n","  Num examples = 133,166\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 20,810\n","  Number of trainable parameters = 384,194,811\n","/usr/local/lib/python3.10/dist-packages/transformers/data/data_collator.py:656: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n","  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n","/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='5001' max='20810' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 5001/20810 1:11:29 < 3:46:04, 1.17 it/s, Epoch 1.20/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu Score</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>5000</td>\n","      <td>2.087800</td>\n","      <td>1.856562</td>\n","      <td>20.323700</td>\n","      <td>34.015400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","***** Running Evaluation *****\n","  Num examples = 133166\n","  Batch size = 32\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:615: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:634: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:615: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:634: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n","  warnings.warn(\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 101,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 102,\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 100,\n","  \"min_length\": 25,\n","  \"no_repeat_ngram_size\": 3,\n","  \"pad_token_id\": 0\n","}\n","\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1375: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n","  warnings.warn(\n","Saving model checkpoint to bert-base-multilingual-cased_to_bert-base-multilingual-cased/checkpoint-5000\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 100, 'min_length': 25, 'early_stopping': True, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3}\n","Configuration saved in bert-base-multilingual-cased_to_bert-base-multilingual-cased/checkpoint-5000/config.json\n"]},{"output_type":"error","ename":"ValueError","evalue":"The generation config instance is invalid -- `.validate()` throws warnings and/or exceptions. Fix these issues to save the configuration.\n\nThrown during validation:\n[UserWarning('`num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.'), UserWarning('`num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.')]","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py\u001b[0m in \u001b[0;36msave_pretrained\u001b[0;34m(self, save_directory, config_file_name, push_to_hub, **kwargs)\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaught_warnings\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcaught_warnings\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: [UserWarning('`num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.'), UserWarning('`num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.')]","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-7cba7b8c48c8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-5-92af17dbc9f8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m     )\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1936\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1937\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1938\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1939\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1940\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2354\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2356\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2357\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2358\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_substep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2806\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2807\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2808\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   2884\u001b[0m         \u001b[0mrun_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_output_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2885\u001b[0m         \u001b[0moutput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2886\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_internal_call\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2888\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_only_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(self, output_dir, _internal_call)\u001b[0m\n\u001b[1;32m   3452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3453\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3454\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3456\u001b[0m         \u001b[0;31m# Push to the Hub when `save_model` is called by the user.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self, output_dir, state_dict)\u001b[0m\n\u001b[1;32m   3523\u001b[0m                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWEIGHTS_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3524\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3525\u001b[0;31m             self.model.save_pretrained(\n\u001b[0m\u001b[1;32m   3526\u001b[0m                 \u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_serialization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_safetensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3527\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36msave_pretrained\u001b[0;34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, token, save_peft_format, **kwargs)\u001b[0m\n\u001b[1;32m   2591\u001b[0m                             \u001b[0;34m\"exception in v4.41.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m                         )\n\u001b[0;32m-> 2593\u001b[0;31m                 \u001b[0mmodel_to_save\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2595\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_hf_peft_config_loaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py\u001b[0m in \u001b[0;36msave_pretrained\u001b[0;34m(self, save_directory, config_file_name, push_to_hub, **kwargs)\u001b[0m\n\u001b[1;32m    771\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcaught_warnings\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    774\u001b[0m                 \u001b[0;34m\"The generation config instance is invalid -- `.validate()` throws warnings and/or exceptions. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m                 \u001b[0;34m\"Fix these issues to save the configuration.\\n\\nThrown during validation:\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: The generation config instance is invalid -- `.validate()` throws warnings and/or exceptions. Fix these issues to save the configuration.\n\nThrown during validation:\n[UserWarning('`num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.'), UserWarning('`num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.')]"]}]},{"cell_type":"markdown","source":["# Test and save model"],"metadata":{"id":"MGHFcYVvNUe6"}},{"cell_type":"code","source":["from transformers import GenerationConfig\n","\n","# Define a custom generation configuration\n","generation_config = GenerationConfig(\n","    num_beams=3,\n","    early_stopping=True,\n","    length_penalty=2.0\n",")\n","\n","# Assign the custom configuration to the model\n","manager.model.generation_config = generation_config\n","\n","# Save the model with the updated configuration\n","manager.model.save_pretrained(\"/content/drive/MyDrive/Code/NLP/Machine Translate/Model/\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UZsiUIUsVism","executionInfo":{"status":"ok","timestamp":1730038914024,"user_tz":-420,"elapsed":11110,"user":{"displayName":"Minh Trần Khánh","userId":"16846330008114299858"}},"outputId":"54f4e535-782c-412b-b3aa-74bf54d1bb39"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 3, 'length_penalty': 2.0}\n","Configuration saved in /content/drive/MyDrive/Code/NLP/Machine Translate/Model/config.json\n","Configuration saved in /content/drive/MyDrive/Code/NLP/Machine Translate/Model/generation_config.json\n","Model weights saved in /content/drive/MyDrive/Code/NLP/Machine Translate/Model/model.safetensors\n"]}]},{"cell_type":"code","source":["link_model = \"/content/drive/MyDrive/Code/NLP/Machine Translate/Model\"\n","link_en_tokenizer = \"/content/bert-base-multilingual-cased_to_bert-base-multilingual-cased/en_tokenizer_bert-base-multilingual-cased\"\n","link_vi_tokenizer = \"/content/bert-base-multilingual-cased_to_bert-base-multilingual-cased/vi_tokenizer_bert-base-multilingual-cased\"\n","model_1 = EncoderDecoderModel.from_pretrained(link_model)\n","en_tokenizer = BertTokenizer.from_pretrained(link_en_tokenizer)\n","vi_tokenizer = BertTokenizer.from_pretrained(link_vi_tokenizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1m0pT8OSWq3D","executionInfo":{"status":"ok","timestamp":1730039062219,"user_tz":-420,"elapsed":9353,"user":{"displayName":"Minh Trần Khánh","userId":"16846330008114299858"}},"outputId":"7c0fe556-7698-43ab-9909-78a6fad2860e"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file /content/drive/MyDrive/Code/NLP/Machine Translate/Model/config.json\n","Model config EncoderDecoderConfig {\n","  \"architectures\": [\n","    \"EncoderDecoderModel\"\n","  ],\n","  \"decoder\": {\n","    \"_name_or_path\": \"bert-base-multilingual-cased\",\n","    \"add_cross_attention\": true,\n","    \"architectures\": [\n","      \"BertForMaskedLM\"\n","    ],\n","    \"attention_probs_dropout_prob\": 0.1,\n","    \"bad_words_ids\": null,\n","    \"begin_suppress_tokens\": null,\n","    \"bos_token_id\": null,\n","    \"chunk_size_feed_forward\": 0,\n","    \"classifier_dropout\": null,\n","    \"cross_attention_hidden_size\": null,\n","    \"decoder_start_token_id\": null,\n","    \"directionality\": \"bidi\",\n","    \"diversity_penalty\": 0.0,\n","    \"do_sample\": false,\n","    \"early_stopping\": false,\n","    \"encoder_no_repeat_ngram_size\": 0,\n","    \"eos_token_id\": null,\n","    \"exponential_decay_length_penalty\": null,\n","    \"finetuning_task\": null,\n","    \"forced_bos_token_id\": null,\n","    \"forced_eos_token_id\": null,\n","    \"hidden_act\": \"gelu\",\n","    \"hidden_dropout_prob\": 0.1,\n","    \"hidden_size\": 768,\n","    \"id2label\": {\n","      \"0\": \"LABEL_0\",\n","      \"1\": \"LABEL_1\"\n","    },\n","    \"initializer_range\": 0.02,\n","    \"intermediate_size\": 3072,\n","    \"is_decoder\": true,\n","    \"is_encoder_decoder\": false,\n","    \"label2id\": {\n","      \"LABEL_0\": 0,\n","      \"LABEL_1\": 1\n","    },\n","    \"layer_norm_eps\": 1e-12,\n","    \"length_penalty\": 1.0,\n","    \"max_length\": 20,\n","    \"max_position_embeddings\": 512,\n","    \"min_length\": 0,\n","    \"model_type\": \"bert\",\n","    \"no_repeat_ngram_size\": 0,\n","    \"num_attention_heads\": 12,\n","    \"num_beam_groups\": 1,\n","    \"num_beams\": 1,\n","    \"num_hidden_layers\": 12,\n","    \"num_return_sequences\": 1,\n","    \"output_attentions\": false,\n","    \"output_hidden_states\": false,\n","    \"output_scores\": false,\n","    \"pad_token_id\": 0,\n","    \"pooler_fc_size\": 768,\n","    \"pooler_num_attention_heads\": 12,\n","    \"pooler_num_fc_layers\": 3,\n","    \"pooler_size_per_head\": 128,\n","    \"pooler_type\": \"first_token_transform\",\n","    \"position_embedding_type\": \"absolute\",\n","    \"prefix\": null,\n","    \"problem_type\": null,\n","    \"pruned_heads\": {},\n","    \"remove_invalid_values\": false,\n","    \"repetition_penalty\": 1.0,\n","    \"return_dict\": true,\n","    \"return_dict_in_generate\": false,\n","    \"sep_token_id\": null,\n","    \"suppress_tokens\": null,\n","    \"task_specific_params\": null,\n","    \"temperature\": 1.0,\n","    \"tf_legacy_loss\": false,\n","    \"tie_encoder_decoder\": false,\n","    \"tie_word_embeddings\": true,\n","    \"tokenizer_class\": null,\n","    \"top_k\": 50,\n","    \"top_p\": 1.0,\n","    \"torch_dtype\": null,\n","    \"torchscript\": false,\n","    \"type_vocab_size\": 2,\n","    \"typical_p\": 1.0,\n","    \"use_bfloat16\": false,\n","    \"use_cache\": true,\n","    \"vocab_size\": 119547\n","  },\n","  \"decoder_start_token_id\": 101,\n","  \"early_stopping\": true,\n","  \"encoder\": {\n","    \"_name_or_path\": \"bert-base-multilingual-cased\",\n","    \"add_cross_attention\": false,\n","    \"architectures\": [\n","      \"BertForMaskedLM\"\n","    ],\n","    \"attention_probs_dropout_prob\": 0.1,\n","    \"bad_words_ids\": null,\n","    \"begin_suppress_tokens\": null,\n","    \"bos_token_id\": null,\n","    \"chunk_size_feed_forward\": 0,\n","    \"classifier_dropout\": null,\n","    \"cross_attention_hidden_size\": null,\n","    \"decoder_start_token_id\": null,\n","    \"directionality\": \"bidi\",\n","    \"diversity_penalty\": 0.0,\n","    \"do_sample\": false,\n","    \"early_stopping\": false,\n","    \"encoder_no_repeat_ngram_size\": 0,\n","    \"eos_token_id\": null,\n","    \"exponential_decay_length_penalty\": null,\n","    \"finetuning_task\": null,\n","    \"forced_bos_token_id\": null,\n","    \"forced_eos_token_id\": null,\n","    \"hidden_act\": \"gelu\",\n","    \"hidden_dropout_prob\": 0.1,\n","    \"hidden_size\": 768,\n","    \"id2label\": {\n","      \"0\": \"LABEL_0\",\n","      \"1\": \"LABEL_1\"\n","    },\n","    \"initializer_range\": 0.02,\n","    \"intermediate_size\": 3072,\n","    \"is_decoder\": false,\n","    \"is_encoder_decoder\": false,\n","    \"label2id\": {\n","      \"LABEL_0\": 0,\n","      \"LABEL_1\": 1\n","    },\n","    \"layer_norm_eps\": 1e-12,\n","    \"length_penalty\": 1.0,\n","    \"max_length\": 20,\n","    \"max_position_embeddings\": 512,\n","    \"min_length\": 0,\n","    \"model_type\": \"bert\",\n","    \"no_repeat_ngram_size\": 0,\n","    \"num_attention_heads\": 12,\n","    \"num_beam_groups\": 1,\n","    \"num_beams\": 1,\n","    \"num_hidden_layers\": 12,\n","    \"num_return_sequences\": 1,\n","    \"output_attentions\": false,\n","    \"output_hidden_states\": false,\n","    \"output_scores\": false,\n","    \"pad_token_id\": 0,\n","    \"pooler_fc_size\": 768,\n","    \"pooler_num_attention_heads\": 12,\n","    \"pooler_num_fc_layers\": 3,\n","    \"pooler_size_per_head\": 128,\n","    \"pooler_type\": \"first_token_transform\",\n","    \"position_embedding_type\": \"absolute\",\n","    \"prefix\": null,\n","    \"problem_type\": null,\n","    \"pruned_heads\": {},\n","    \"remove_invalid_values\": false,\n","    \"repetition_penalty\": 1.0,\n","    \"return_dict\": true,\n","    \"return_dict_in_generate\": false,\n","    \"sep_token_id\": null,\n","    \"suppress_tokens\": null,\n","    \"task_specific_params\": null,\n","    \"temperature\": 1.0,\n","    \"tf_legacy_loss\": false,\n","    \"tie_encoder_decoder\": false,\n","    \"tie_word_embeddings\": true,\n","    \"tokenizer_class\": null,\n","    \"top_k\": 50,\n","    \"top_p\": 1.0,\n","    \"torch_dtype\": null,\n","    \"torchscript\": false,\n","    \"type_vocab_size\": 2,\n","    \"typical_p\": 1.0,\n","    \"use_bfloat16\": false,\n","    \"use_cache\": true,\n","    \"vocab_size\": 119547\n","  },\n","  \"eos_token_id\": 102,\n","  \"is_encoder_decoder\": true,\n","  \"length_penalty\": 2.0,\n","  \"model_type\": \"encoder-decoder\",\n","  \"num_beams\": 3,\n","  \"pad_token_id\": 0,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.44.2\",\n","  \"vocab_size\": 119547\n","}\n","\n","loading weights file /content/drive/MyDrive/Code/NLP/Machine Translate/Model/model.safetensors\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 101,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 102,\n","  \"length_penalty\": 2.0,\n","  \"num_beams\": 3,\n","  \"pad_token_id\": 0\n","}\n","\n","Generate config GenerationConfig {\n","  \"pad_token_id\": 0\n","}\n","\n","All model checkpoint weights were used when initializing EncoderDecoderModel.\n","\n","All the weights of EncoderDecoderModel were initialized from the model checkpoint at /content/drive/MyDrive/Code/NLP/Machine Translate/Model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use EncoderDecoderModel for predictions without further training.\n","loading configuration file /content/drive/MyDrive/Code/NLP/Machine Translate/Model/generation_config.json\n","Generate config GenerationConfig {\n","  \"early_stopping\": true,\n","  \"length_penalty\": 2.0,\n","  \"num_beams\": 3\n","}\n","\n","loading file vocab.txt\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n","loading file tokenizer.json\n","loading file vocab.txt\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n","loading file tokenizer.json\n"]}]},{"cell_type":"code","source":["sentence = \"Hello, how are you?\"\n","\n","inputs = en_tokenizer(sentence, return_tensors=\"pt\")\n","\n","with torch.no_grad():\n","    outputs = model_1.generate(\n","        inputs[\"input_ids\"],\n","        max_length=40,\n","        num_beams=3,\n","        early_stopping=True,\n","        decoder_start_token_id=model_1.config.decoder_start_token_id\n","    )\n","    translated_sentence = vi_tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","print(\"Câu gốc:\", sentence)\n","print(\"Câu dịch:\", translated_sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2kHpWGleXSvA","executionInfo":{"status":"ok","timestamp":1730039378983,"user_tz":-420,"elapsed":2645,"user":{"displayName":"Minh Trần Khánh","userId":"16846330008114299858"}},"outputId":"93cb1298-c279-4f8d-fe29-d2fda674a00c"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Câu gốc: Hello, how are you?\n","Câu dịch: Xin chào, cô ấy như thế nào? Xin cháu như thế nào? Xin cháu như thế nào? Xin như thế nào?\n"]}]},{"cell_type":"code","source":["# Đường dẫn lưu cho các tokenizer\n","en_tokenizer_save_path = \"/content/drive/MyDrive/Code/NLP/Machine Translate/tokenizer_en\"\n","vi_tokenizer_save_path = \"/content/drive/MyDrive/Code/NLP/Machine Translate/tokenizer_vi\"\n","\n","# Lưu tokenizer tiếng Anh\n","en_tokenizer.save_pretrained(en_tokenizer_save_path)\n","\n","# Lưu tokenizer tiếng Việt\n","vi_tokenizer.save_pretrained(vi_tokenizer_save_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hqOtAHW2Xm_D","executionInfo":{"status":"ok","timestamp":1730039632647,"user_tz":-420,"elapsed":539,"user":{"displayName":"Minh Trần Khánh","userId":"16846330008114299858"}},"outputId":"754c0888-d8af-4b71-b287-4b33dd00d9ae"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stderr","text":["tokenizer config file saved in /content/drive/MyDrive/Code/NLP/Machine Translate/tokenizer_en/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/Code/NLP/Machine Translate/tokenizer_en/special_tokens_map.json\n","tokenizer config file saved in /content/drive/MyDrive/Code/NLP/Machine Translate/tokenizer_vi/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/Code/NLP/Machine Translate/tokenizer_vi/special_tokens_map.json\n"]},{"output_type":"execute_result","data":{"text/plain":["('/content/drive/MyDrive/Code/NLP/Machine Translate/tokenizer_vi/tokenizer_config.json',\n"," '/content/drive/MyDrive/Code/NLP/Machine Translate/tokenizer_vi/special_tokens_map.json',\n"," '/content/drive/MyDrive/Code/NLP/Machine Translate/tokenizer_vi/vocab.txt',\n"," '/content/drive/MyDrive/Code/NLP/Machine Translate/tokenizer_vi/added_tokens.json')"]},"metadata":{},"execution_count":36}]}]}